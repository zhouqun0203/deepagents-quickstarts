{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fecc3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c897bc9",
   "metadata": {},
   "source": [
    "# Deepagent for Research\n",
    "\n",
    "We will use the `deepagents` package to create a research agent. When using the `deepagents` package, it's important to: \n",
    "\n",
    "1. Understand the native tools available\n",
    "2. Supply task-specific tools\n",
    "3. Supply task-specific instructions\n",
    "4. Supply task-specific sub-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14c09e",
   "metadata": {},
   "source": [
    "## Task-Specific Tools \n",
    "\n",
    "You can see an overview of the native tools in the [deepagents package README](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#model) as well as the [quickstarts README](https://github.com/langchain-ai/deepagents-quickstarts). We'll extend this with two task-specific tools. \n",
    "\n",
    "### Search Tool \n",
    "\n",
    "We'll supply a simple search tool that uses Tavily to search for relevant URLs, then fetches the full webpage content. \n",
    "\n",
    "### Think Tool \n",
    "\n",
    "We'll supply a [think tool](https://www.anthropic.com/engineering/claude-think-tool), which is a useful way to help audit agent decision making. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9163556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_agent.tools import tavily_search, think_tool\n",
    "tools = [tavily_search, think_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3ee5b",
   "metadata": {},
   "source": [
    "## Task-Specific Instructions\n",
    " \n",
    "Next, let's define task specific instructions using [a few prompting techniques for agents](https://youtu.be/XSZP9GhhuAc?si=zowpViL-2j-vI9hA):\n",
    "\n",
    "### 1. Think Like The Agent\n",
    "What instructions would you give a new work colleague?\n",
    "- **Read the question carefully** - What specific information does the user need?\n",
    "- **Start with broader searches** - Use broad, comprehensive queries first\n",
    "- **After each search, pause and assess** - Do I have enough to answer? What's still missing?\n",
    "- **Execute narrower searches as you gather information** - Fill in the gaps.\n",
    "\n",
    "### 2. Concrete Heuristics (Prevent \"Spin-Out\" on excessive tool calls)\n",
    "Use **Hard Limits** to prevent the research agent from calling tools excessively:\n",
    "- **Stop when you can answer confidently** - Don't keep searching for perfection.\n",
    "- **Give it budgets** - Use 2-3 search tool calls for simple queries. Use up to 5 for complex queries.\n",
    "- **Limit** - Always stop after 5 search tool calls if you cannot find the right source(s).\n",
    "\n",
    "### 3. Show your thinking\n",
    "After each search tool calling, use [`think_tool` to analyze the results](https://www.anthropic.com/engineering/claude-think-tool):\n",
    "- What key information did I find? \n",
    "- What's missing?\n",
    "- Do I have enough to answer the question comprehensively?\n",
    "- Should I search more or provide my answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4487f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_prompt, format_messages\n",
    "from research_agent.prompts import (\n",
    "    RESEARCHER_INSTRUCTIONS,\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS,\n",
    "    SUBAGENT_DELEGATION_INSTRUCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5eb7a89-8a26-4fb4-ba77-b05180f2c67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You are a research assistant conducting research on the user's input topic. For context, today's date is       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  {date}.                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Task&gt;</span>                                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Your job is to use tools to gather information about the user's input topic.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can use any of the research tools provided to you to find resources that can help answer the research      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  question.                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Task&gt;</span>                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Available Research Tools&gt;</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to two specific research tools:                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **tavily_search**: For conducting web searches to gather information                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **think_tool**: For reflection and strategic planning during research                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Available Research Tools&gt;</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Instructions&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Think like a human researcher with limited time. Follow these steps:                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Read the question carefully** - What specific information does the user need?                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Start with broader searches** - Use broad, comprehensive queries first                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Instructions&gt;</span>                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Hard Limits&gt;</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Tool Call Budgets** (Prevent excessive searching):                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Simple queries**: Use 2-3 search tool calls maximum                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Complex queries**: Use up to 5 search tool calls maximum                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Stop Immediately When**:                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You can answer the user's question comprehensively                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You have 3+ relevant examples/sources for the question                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Your last 2 searches returned similar information                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Hard Limits&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Show Your Thinking&gt;</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  After each search tool call, use think_tool to analyze the results:                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What key information did I find?                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What's missing?                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Do I have enough to answer the question comprehensively?                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Should I search more or provide my answer?                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Show Your Thinking&gt;</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Final Response Format&gt;</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  When providing your final answer, use numbered citations and include a Sources section:                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Sources section**: End with a numbered list of all sources                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Example format:                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  can improve performance by 40% [2].                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources</span>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [1] Context Engineering Guide: https://example.com/context-guide                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [2] AI Performance Study: https://example.com/study                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This allows readers to verify information and explore topics further.                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Final Response Format&gt;</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You are a research assistant conducting research on the user's input topic. For context, today's date is       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  {date}.                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Task>\u001b[0m                                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Your job is to use tools to gather information about the user's input topic.                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can use any of the research tools provided to you to find resources that can help answer the research      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  question.                                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Task>\u001b[0m                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Available Research Tools>\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to two specific research tools:                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **tavily_search**: For conducting web searches to gather information                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **think_tool**: For reflection and strategic planning during research                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Available Research Tools>\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Instructions>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Think like a human researcher with limited time. Follow these steps:                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Read the question carefully** - What specific information does the user need?                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Start with broader searches** - Use broad, comprehensive queries first                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Instructions>\u001b[0m                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Hard Limits>\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Tool Call Budgets** (Prevent excessive searching):                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Simple queries**: Use 2-3 search tool calls maximum                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Complex queries**: Use up to 5 search tool calls maximum                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Stop Immediately When**:                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You can answer the user's question comprehensively                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You have 3+ relevant examples/sources for the question                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Your last 2 searches returned similar information                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Hard Limits>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Show Your Thinking>\u001b[0m                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  After each search tool call, use think_tool to analyze the results:                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What key information did I find?                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What's missing?                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Do I have enough to answer the question comprehensively?                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Should I search more or provide my answer?                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Show Your Thinking>\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Final Response Format>\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  When providing your final answer, use numbered citations and include a Sources section:                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Sources section**: End with a numbered list of all sources                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Example format:                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  can improve performance by 40% [2].                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources\u001b[0m                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [1] Context Engineering Guide: https://example.com/context-guide                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [2] AI Performance Study: https://example.com/study                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This allows readers to verify information and explore topics further.                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Final Response Format>\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prompt(RESEARCHER_INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab6e7e",
   "metadata": {},
   "source": [
    "## Task-Specific Sub-Agents\n",
    "\n",
    "You can specify [custom subagents](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#subagents) as a means of context isolation. \n",
    "\n",
    "Here's well define a sub-agent that can search the web for information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6570183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create research sub-agent\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS,\n",
    "    \"tools\": [tavily_search, think_tool],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef99f1d",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Now, we can look at all of our instructions together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e55b2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  # Research Workflow                                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Follow this workflow for all research requests:                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Save the request**: Use write_file() to save the user's research question to `/research_request.md`       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Plan**: Create a todo list with write_todos to break down the research into focused tasks                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **Research**: Delegate research tasks to sub-agents using the task() tool                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. **Write Report**: Write a comprehensive final report to `/final_report.md` (see Report Writing Guidelines   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  below)                                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. **Verify**: Read `/research_request.md` to confirm you've addressed all aspects of the original question    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Research Planning Guidelines</span>                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Batch similar research tasks into a single TODO to minimize overhead                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - For simple fact-finding questions, use 1 sub-agent                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - For comparisons or multi-faceted topics, delegate to multiple parallel sub-agents                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Each sub-agent should research one specific aspect and return findings                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Report Writing Guidelines</span>                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  When writing the final report to `/final_report.md`, follow these structure patterns:                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **For comparisons:**                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. Introduction                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. Overview of topic A                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. Overview of topic B                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. Detailed comparison                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. Conclusion                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **For lists/rankings:**                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Simply list items with details - no introduction needed:                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. Item 1 with explanation                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. Item 2 with explanation                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. Item 3 with explanation                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **For summaries/overviews:**                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. Overview of topic                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. Key concept 1                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. Key concept 2                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. Key concept 3                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. Conclusion                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **General guidelines:**                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Use clear section headings (<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## for sections, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### for subsections)</span>                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Write in paragraph form by default - be text-heavy, not just bullet points                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Do NOT use self-referential language (\"I found...\", \"I researched...\")                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Write as a professional report without meta-commentary                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Each section should be comprehensive and detailed                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Use bullet points only when listing is more appropriate than prose                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Citation Rules&gt;</span>                                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Use numbered citations throughout your report:                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Cite sources inline using [1], [2], [3] format                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Assign each unique URL a single citation number                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - End report with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources section listing each numbered source</span>                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Number sources sequentially without gaps (1,2,3,4...)                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Format: [1] Source Title: URL (each on separate line for proper list rendering)                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Example:                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    Some important finding [1]. Another key insight [2].                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    [1] AI Research Paper: https://example.com/paper                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    [2] Industry Analysis: https://example.com/analysis                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Citation Rules&gt;</span>                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  # Sub-Agent Research Coordination                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Your role is to coordinate research by delegating tasks from your TODO list to specialized research            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  sub-agents.                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Delegation Strategy</span>                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Simple queries** → 1 sub-agent:                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"List the top 10 coffee shops in San Francisco\"                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"What is quantum computing?\"                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Summarize the history of the internet\"                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Comparisons** → 1 sub-agent per element:                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Compare OpenAI vs Anthropic vs DeepMind AI safety approaches\" → 3 parallel sub-agents                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Compare Python vs JavaScript for web development\" → 2 parallel sub-agents                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Multi-faceted research** → 1 sub-agent per aspect:                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Research renewable energy: costs, environmental impact, adoption rates\" → 3 parallel sub-agents             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - \"Analyze the 2024 election: candidates, issues, polling\" → 3 parallel sub-agents                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Parallel Execution</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Use at most {max_concurrent_research_units} parallel sub-agents per iteration                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Make multiple task() calls in a single response to enable parallel execution                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Each sub-agent returns findings independently                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Research Limits</span>                                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Stop after {max_researcher_iterations} delegation rounds if you haven't found adequate sources               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Stop when you have sufficient information to answer comprehensively                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Bias towards focused research over exhaustive exploration                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You are a research assistant conducting research on the user's input topic. For context, today's date is       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  {date}.                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Task&gt;</span>                                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Your job is to use tools to gather information about the user's input topic.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can use any of the research tools provided to you to find resources that can help answer the research      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  question.                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Task&gt;</span>                                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Available Research Tools&gt;</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to two specific research tools:                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **tavily_search**: For conducting web searches to gather information                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **think_tool**: For reflection and strategic planning during research                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Available Research Tools&gt;</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Instructions&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Think like a human researcher with limited time. Follow these steps:                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Read the question carefully** - What specific information does the user need?                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Start with broader searches** - Use broad, comprehensive queries first                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Instructions&gt;</span>                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Hard Limits&gt;</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Tool Call Budgets** (Prevent excessive searching):                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Simple queries**: Use 2-3 search tool calls maximum                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Complex queries**: Use up to 5 search tool calls maximum                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  **Stop Immediately When**:                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You can answer the user's question comprehensively                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - You have 3+ relevant examples/sources for the question                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Your last 2 searches returned similar information                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Hard Limits&gt;</span>                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Show Your Thinking&gt;</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  After each search tool call, use think_tool to analyze the results:                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What key information did I find?                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - What's missing?                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Do I have enough to answer the question comprehensively?                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - Should I search more or provide my answer?                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Show Your Thinking&gt;</span>                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;Final Response Format&gt;</span>                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  When providing your final answer, use numbered citations and include a Sources section:                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Sources section**: End with a numbered list of all sources                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Example format:                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  can improve performance by 40% [2].                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Sources</span>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [1] Context Engineering Guide: https://example.com/context-guide                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [2] AI Performance Study: https://example.com/study                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This allows readers to verify information and explore topics further.                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;/Final Response Format&gt;</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  # Research Workflow                                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Follow this workflow for all research requests:                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Save the request**: Use write_file() to save the user's research question to `/research_request.md`       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Plan**: Create a todo list with write_todos to break down the research into focused tasks                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **Research**: Delegate research tasks to sub-agents using the task() tool                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. **Write Report**: Write a comprehensive final report to `/final_report.md` (see Report Writing Guidelines   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  below)                                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. **Verify**: Read `/research_request.md` to confirm you've addressed all aspects of the original question    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Research Planning Guidelines\u001b[0m                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Batch similar research tasks into a single TODO to minimize overhead                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - For simple fact-finding questions, use 1 sub-agent                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - For comparisons or multi-faceted topics, delegate to multiple parallel sub-agents                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Each sub-agent should research one specific aspect and return findings                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Report Writing Guidelines\u001b[0m                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  When writing the final report to `/final_report.md`, follow these structure patterns:                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **For comparisons:**                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. Introduction                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. Overview of topic A                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. Overview of topic B                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. Detailed comparison                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. Conclusion                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **For lists/rankings:**                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Simply list items with details - no introduction needed:                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. Item 1 with explanation                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. Item 2 with explanation                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. Item 3 with explanation                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **For summaries/overviews:**                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. Overview of topic                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. Key concept 1                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. Key concept 2                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. Key concept 3                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. Conclusion                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **General guidelines:**                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Use clear section headings (\u001b[1;35m## for sections, \u001b[0m\u001b[1;36m#\u001b[0m\u001b[1;36m## for subsections)\u001b[0m                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Write in paragraph form by default - be text-heavy, not just bullet points                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Do NOT use self-referential language (\"I found...\", \"I researched...\")                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Write as a professional report without meta-commentary                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Each section should be comprehensive and detailed                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Use bullet points only when listing is more appropriate than prose                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Citation Rules>\u001b[0m                                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Use numbered citations throughout your report:                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Cite sources inline using [1], [2], [3] format                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Assign each unique URL a single citation number                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - End report with \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources section listing each numbered source\u001b[0m                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Number sources sequentially without gaps (1,2,3,4...)                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Format: [1] Source Title: URL (each on separate line for proper list rendering)                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Example:                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    Some important finding [1]. Another key insight [2].                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    [1] AI Research Paper: https://example.com/paper                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    [2] Industry Analysis: https://example.com/analysis                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Citation Rules>\u001b[0m                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ================================================================================                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  # Sub-Agent Research Coordination                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Your role is to coordinate research by delegating tasks from your TODO list to specialized research            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  sub-agents.                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Delegation Strategy\u001b[0m                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Simple queries** → 1 sub-agent:                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"List the top 10 coffee shops in San Francisco\"                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"What is quantum computing?\"                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Summarize the history of the internet\"                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Comparisons** → 1 sub-agent per element:                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Compare OpenAI vs Anthropic vs DeepMind AI safety approaches\" → 3 parallel sub-agents                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Compare Python vs JavaScript for web development\" → 2 parallel sub-agents                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Multi-faceted research** → 1 sub-agent per aspect:                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Research renewable energy: costs, environmental impact, adoption rates\" → 3 parallel sub-agents             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - \"Analyze the 2024 election: candidates, issues, polling\" → 3 parallel sub-agents                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Parallel Execution\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Use at most {max_concurrent_research_units} parallel sub-agents per iteration                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Make multiple task() calls in a single response to enable parallel execution                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Each sub-agent returns findings independently                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Research Limits\u001b[0m                                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Stop after {max_researcher_iterations} delegation rounds if you haven't found adequate sources               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Stop when you have sufficient information to answer comprehensively                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Bias towards focused research over exhaustive exploration                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ================================================================================                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You are a research assistant conducting research on the user's input topic. For context, today's date is       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  {date}.                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Task>\u001b[0m                                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Your job is to use tools to gather information about the user's input topic.                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can use any of the research tools provided to you to find resources that can help answer the research      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  question.                                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You can call these tools in series or in parallel, your research is conducted in a tool-calling loop.          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Task>\u001b[0m                                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Available Research Tools>\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to two specific research tools:                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **tavily_search**: For conducting web searches to gather information                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **think_tool**: For reflection and strategic planning during research                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **CRITICAL: Use think_tool after each search to reflect on results and plan next steps**                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Available Research Tools>\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Instructions>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Think like a human researcher with limited time. Follow these steps:                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Read the question carefully** - What specific information does the user need?                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Start with broader searches** - Use broad, comprehensive queries first                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  4. **Execute narrower searches as you gather information** - Fill in the gaps                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  5. **Stop when you can answer confidently** - Don't keep searching for perfection                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Instructions>\u001b[0m                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Hard Limits>\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Tool Call Budgets** (Prevent excessive searching):                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Simple queries**: Use 2-3 search tool calls maximum                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Complex queries**: Use up to 5 search tool calls maximum                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - **Always stop**: After 5 search tool calls if you cannot find the right sources                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  **Stop Immediately When**:                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You can answer the user's question comprehensively                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - You have 3+ relevant examples/sources for the question                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Your last 2 searches returned similar information                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Hard Limits>\u001b[0m                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Show Your Thinking>\u001b[0m                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  After each search tool call, use think_tool to analyze the results:                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What key information did I find?                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - What's missing?                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Do I have enough to answer the question comprehensively?                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - Should I search more or provide my answer?                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Show Your Thinking>\u001b[0m                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m<Final Response Format>\u001b[0m                                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  When providing your final answer, use numbered citations and include a Sources section:                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Cite sources inline**: Use [1], [2], [3] format when referencing information                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Sources section**: End with a numbered list of all sources                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Example format:                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering is a critical technique for AI agents [1]. Studies show that proper context management     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  can improve performance by 40% [2].                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Sources\u001b[0m                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [1] Context Engineering Guide: https://example.com/context-guide                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [2] AI Performance Study: https://example.com/study                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This allows readers to verify information and explore topics further.                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;34m</Final Response Format>\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INSTRUCTIONS = (\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + SUBAGENT_DELEGATION_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + RESEARCHER_INSTRUCTIONS\n",
    ")\n",
    "\n",
    "show_prompt(INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e3639",
   "metadata": {},
   "source": [
    "### Create the agent\n",
    "\n",
    "Now, we create our deepagent with these components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62da8411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import Image, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from deepagents import create_deep_agent\n",
    "\n",
    "# Model \n",
    "model = init_chat_model(model=\"anthropic:claude-sonnet-4-5-20250929\", temperature=0.0)\n",
    "\n",
    "# Create the agent\n",
    "agent = create_deep_agent(\n",
    "      model=model,\n",
    "      tools=[tavily_search, think_tool], \n",
    "      system_prompt=INSTRUCTIONS,\n",
    "      subagents=[research_sub_agent],\n",
    "  )\n",
    "  \n",
    "# Show the agent\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "613634c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────── 🧑 Human ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> research context engineering approaches used to build AI agents                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m 🧑 Human \u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m research context engineering approaches used to build AI agents                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> I'll help you research context engineering approaches used to build AI agents. Let me start by saving your      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> request and planning the research.                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_file                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"/research_request.md\",                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"content\": \"# Research Request\\n\\nResearch context engineering approaches used to build AI agents\\n\\n##       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Date\\n2024-01-XX\\n\\n## Objective\\nInvestigate and document the various context engineering approaches,          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> techniques, and methodologies used in building AI agents.\\n\"                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_018SyxbFkLo785AzWmdTiMVo                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_todos                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"todos\": [                                                                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"in_progress\"                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research specific techniques and implementation methods\",                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"pending\"                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Write comprehensive final report to /final_report.md\",                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"pending\"                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Verify report addresses all aspects of the original request\",                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"pending\"                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     }                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   ]                                                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01RYfv2cZLJEss9hww2HEjbR                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m I'll help you research context engineering approaches used to build AI agents. Let me start by saving your      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m request and planning the research.                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_file                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"file_path\": \"/research_request.md\",                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"content\": \"# Research Request\\n\\nResearch context engineering approaches used to build AI agents\\n\\n##       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Date\\n2024-01-XX\\n\\n## Objective\\nInvestigate and document the various context engineering approaches,          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m techniques, and methodologies used in building AI agents.\\n\"                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_018SyxbFkLo785AzWmdTiMVo                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_todos                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"todos\": [                                                                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"in_progress\"                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research specific techniques and implementation methods\",                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"pending\"                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Write comprehensive final report to /final_report.md\",                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"pending\"                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Verify report addresses all aspects of the original request\",                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"pending\"                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     }                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   ]                                                                                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_01RYfv2cZLJEss9hww2HEjbR                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated file /research_request.md                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated file /research_request.md                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> agents', 'status': 'in_progress'}, {'content': 'Research specific techniques and implementation methods',       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'status': 'pending'}, {'content': 'Write comprehensive final report to /final_report.md', 'status': 'pending'}, <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> {'content': 'Verify report addresses all aspects of the original request', 'status': 'pending'}]                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m agents', 'status': 'in_progress'}, {'content': 'Research specific techniques and implementation methods',       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'status': 'pending'}, {'content': 'Write comprehensive final report to /final_report.md', 'status': 'pending'}, \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m {'content': 'Verify report addresses all aspects of the original request', 'status': 'pending'}]                \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Now let me delegate the research to specialized sub-agents to gather comprehensive information about context    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> engineering approaches for AI agents.                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: task                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"subagent_type\": \"research-agent\",                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"description\": \"Research context engineering fundamentals and core approaches for AI agents.\\n\\nYour task is  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> to conduct comprehensive research on context engineering approaches used to build AI agents. Focus on:\\n\\n1.    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> What is context engineering in the context of AI agents?\\n2. Why is context engineering important for AI        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> agents?\\n3. Core approaches and methodologies (e.g., prompt engineering, context windows, memory management,    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> retrieval-augmented generation)\\n4. Key techniques used in practice\\n5. Best practices and design               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> patterns\\n\\nUse web searches to find authoritative sources, technical articles, research papers, and industry   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> implementations. Gather specific examples and concrete techniques.\\n\\nReturn a detailed report with:\\n- Clear   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> explanations of context engineering concepts\\n- Specific approaches and techniques with descriptions\\n-         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Real-world examples and use cases\\n- All sources cited with URLs\\n\\nAim for 3-5 high-quality sources that cover <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> different aspects of context engineering for AI agents.\"                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01Kx17Te2k6xNyQ4mMNE1Ap8                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: task                                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"subagent_type\": \"research-agent\",                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"description\": \"Research advanced context engineering techniques and implementation strategies for AI         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> agents.\\n\\nYour task is to research specific implementation techniques and advanced strategies for context      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> engineering in AI agents. Focus on:\\n\\n1. Context window management and optimization\\n2. Long-term memory and   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> state management approaches\\n3. Context compression and summarization techniques\\n4. Multi-turn conversation    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context handling\\n5. Tool use and function calling context patterns\\n6. Context injection and retrieval         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> strategies\\n\\nUse web searches to find technical documentation, implementation guides, case studies, and        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> practical examples from AI companies and frameworks.\\n\\nReturn a detailed report with:\\n- Specific              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> implementation techniques with explanations\\n- Code patterns or architectural approaches where available\\n-     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Trade-offs and considerations for different approaches\\n- All sources cited with URLs\\n\\nAim for 3-5            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> high-quality sources focused on practical implementation.\"                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01FY49z5xRZZcS6Tk78kZdJY                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m Now let me delegate the research to specialized sub-agents to gather comprehensive information about context    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m engineering approaches for AI agents.                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: task                                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"subagent_type\": \"research-agent\",                                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"description\": \"Research context engineering fundamentals and core approaches for AI agents.\\n\\nYour task is  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m to conduct comprehensive research on context engineering approaches used to build AI agents. Focus on:\\n\\n1.    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m What is context engineering in the context of AI agents?\\n2. Why is context engineering important for AI        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m agents?\\n3. Core approaches and methodologies (e.g., prompt engineering, context windows, memory management,    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m retrieval-augmented generation)\\n4. Key techniques used in practice\\n5. Best practices and design               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m patterns\\n\\nUse web searches to find authoritative sources, technical articles, research papers, and industry   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m implementations. Gather specific examples and concrete techniques.\\n\\nReturn a detailed report with:\\n- Clear   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m explanations of context engineering concepts\\n- Specific approaches and techniques with descriptions\\n-         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Real-world examples and use cases\\n- All sources cited with URLs\\n\\nAim for 3-5 high-quality sources that cover \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m different aspects of context engineering for AI agents.\"                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_01Kx17Te2k6xNyQ4mMNE1Ap8                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: task                                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"subagent_type\": \"research-agent\",                                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"description\": \"Research advanced context engineering techniques and implementation strategies for AI         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m agents.\\n\\nYour task is to research specific implementation techniques and advanced strategies for context      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m engineering in AI agents. Focus on:\\n\\n1. Context window management and optimization\\n2. Long-term memory and   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m state management approaches\\n3. Context compression and summarization techniques\\n4. Multi-turn conversation    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context handling\\n5. Tool use and function calling context patterns\\n6. Context injection and retrieval         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m strategies\\n\\nUse web searches to find technical documentation, implementation guides, case studies, and        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m practical examples from AI companies and frameworks.\\n\\nReturn a detailed report with:\\n- Specific              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m implementation techniques with explanations\\n- Code patterns or architectural approaches where available\\n-     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Trade-offs and considerations for different approaches\\n- All sources cited with URLs\\n\\nAim for 3-5            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m high-quality sources focused on practical implementation.\"                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_01FY49z5xRZZcS6Tk78kZdJY                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Now I'll compile a comprehensive report on context engineering fundamentals and core approaches for AI agents   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> based on my research findings.                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Context Engineering for AI Agents: Comprehensive Research Report                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## Executive Summary                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering has emerged as a critical discipline in AI agent development, representing a fundamental    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> shift from simple prompt engineering to sophisticated system architecture. As Andrej Karpathy describes it,     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> context engineering is \"the delicate art and science of filling the context window with just the right          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> information for the next step\" [1]. This report explores the fundamentals, core approaches, key techniques, and <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> best practices for building effective AI agents through strategic context management.                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 1. What is Context Engineering?                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Definition and Evolution                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering is the discipline of strategically managing, curating, and controlling the information      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> provided to large language models (LLMs) [1][2]. It represents an evolution from **prompt engineering** (which  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> focuses on crafting instructions) to **context engineering** (which focuses on architecting the entire          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> information pipeline before the LLM call).                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> While prompt engineering concentrated on writing clever, concise instructions for simple tasks, context         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> engineering treats the entire pipeline as engineerable infrastructure [1]. This includes:                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Dynamic information gathering**: RAG systems, API calls, database queries                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Memory management**: Short-term conversation state and long-term knowledge                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Tool coordination**: Making external functions available when needed                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Output structuring**: Defining schemas and formats for consistent results                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### The Shift to Agentic AI                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Early AI development relied heavily on prompting methods like chain-of-thought, ReAct, and self-consistency for <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> complex tasks [1]. However, as applications evolved into AI agents with multi-step reasoning, long-running      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> conversations, and dynamic information retrieval, these approaches hit significant limitations. Context         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> engineering emerged as the solution to handle:                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Multi-step reasoning requiring tool use                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Long-running conversations with memory                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Dynamic information retrieval from databases                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Coordination between multiple AI systems                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 2. Why Context Engineering Matters                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Critical Impact Areas                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering directly impacts three fundamental aspects of AI agent systems [1][2]:                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **1. Performance and Reliability**                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Poor context management creates \"context rot\" where model quality degrades well before hitting technical      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> token limits                                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Research shows models perform optimally only in the first 50,000-100,000 tokens, even with million-token      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> context windows [2]                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Context failures manifest as hallucinations, inconsistent outputs, and task failures                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **2. Cost Efficiency**                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Every token sent to an LLM incurs inference costs                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Naive approaches that append all tool results can generate hundreds of thousands of tokens after just several <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> rounds                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Production systems without context engineering quickly become cost-prohibitive at scale [2]                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **3. User Experience**                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Processing 500,000 tokens takes significantly longer than 5,000 tokens                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Context engineering reduces latency and improves responsiveness                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Proper context management builds user trust by preventing unexpected behaviors                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Common Context Problems                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Poor context management creates four major failure modes [1]:                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Context poisoning**: Hallucinations contaminating future responses                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Context distraction**: Too much information overwhelming the model                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Context confusion**: Conflicting information causing errors                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Context clash**: Disagreeing sources leading to inconsistent outputs                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> As one researcher noted, \"Most agent failures are context failures\" - the system didn't provide adequate        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> information for success [1].                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 3. Types of Context in AI Agents                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Modern AI agents require multiple context types working together [1][3]:                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Static Context                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Prompts**: Core behavior rules and examples                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Tool definitions**: Available functions and their parameters                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Output schemas**: Response format requirements                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Configuration files**: Project-specific instructions (AGENTS.md, CLAUDE.md)                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Dynamic Context                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **User input**: The immediate task or question                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Chat history**: Short-term conversation memory                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Long-term memory**: Persistent preferences and past learnings                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Retrieved knowledge**: RAG results from databases or APIs                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Tool responses**: Feedback from executed functions                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Workflow state**: Information stored across agent steps                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Research on open-source projects found that AI configuration files commonly include: coding conventions (50     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> instances), contribution guidelines (48), architecture descriptions (47), build commands (40), and testing      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> instructions (32) [3].                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 4. Core Context Engineering Strategies                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Strategy 1: Writing Context (Memory Management)                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Writing context involves saving information outside the context window to preserve valuable token space [1].    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Scratchpads**: Temporary note-taking within a single session                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Anthropic's multi-agent researcher saves initial plans to \"Memory\" to prevent loss when context exceeds       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 200,000 tokens                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Implementation options include file-based tools or runtime state objects                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Long-Term Memories**: Information retained across multiple sessions                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **ChatGPT**: Auto-generates user preferences from conversations                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Cursor/Windsurf**: Learns coding patterns and project context                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Reflexion agents**: Create self-generated memories from task feedback                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This enables personalization and creates evolving experiences that improve over time [1].                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Strategy 2: Selecting Context (Intelligent Retrieval)                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Selecting context means pulling only relevant information into the context window [1][4].                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Targeted Retrieval**                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Fine-grained control over what information gets exposed to the LLM                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Selective exposure of specific parts from scratchpads or state objects                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Reduces noise and improves decision-making                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Memory Selection Types**                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Episodic memories**: Few-shot examples showing desired behavior                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Procedural memories**: Instructions stored in configuration files                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Semantic memories**: Facts relevant to current context (embeddings, RAG)                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Agentic RAG**: Applying RAG to tool descriptions                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Too many tools create \"model confusion\" about which to use                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - RAG-based tool selection improves accuracy by 3-fold according to recent research [1]                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Strategy 3: Compressing Context (Optimization)                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Compressing context retains only tokens required to perform a task [1][2].                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Context Summarization**                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Condenses information while preserving essential details                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Claude Code's \"auto-compact\" feature summarizes when context exceeds 95% capacity                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Applies at multiple levels: full trajectory, specific points, agent boundaries                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Some companies use fine-tuned models specifically for summarization                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Context Trimming**                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Uses filtering or \"pruning\" approaches                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Hard-coded heuristics: Removing older messages from lists                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Learned approaches: Trained context pruners for specific domains                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Offers immediate, predictable context reduction                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Strategy 4: Isolating Context (Structural Separation)                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Isolating context splits it across different components to reduce cognitive load [1][2].                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Multi-Agent Architectures**                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Splits context across sub-agents, each with their own context windows, tools, and instructions                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enables separation of concerns for specialized subtasks                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Expands total token capacity across the system                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Challenge: Can increase costs up to 15x more tokens than single-agent systems                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Sandboxes and Execution Environments**                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Isolates code execution from the LLM's context window                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Persists state across multiple responses                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Excels at handling token-heavy objects (images, audio files)                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Only selective results passed back to the LLM                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 5. Six Core Context Engineering Techniques                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Technique 1: Pruning                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Pruning systematically removes older, less relevant, or redundant information from the context window [2].      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Approaches**:                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Chronological pruning**: Remove oldest exchanges first (simplest approach)                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Heuristic-based pruning**: Drop confirmations and casual conversation while preserving instructions         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Priority-based pruning**: Assign importance scores to different message types                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Semantic pruning**: Analyze content and remove redundant or off-topic information                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Best Practices**:                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Trigger automatically at 80-95% of maximum token size                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Pair with summarization for maximum effectiveness                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Summarize before dropping content to preserve essential information                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Example**: After five tool calls, keep only the most recent 2-3 turns, summarize earlier results, and drop    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> raw outputs [2].                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Technique 2: Summarization                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Summarization compresses long message chains into concise summaries that preserve semantic relevance [2].       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Patterns**:                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Hierarchical summarization**: Break long contexts into chunks, summarize each, then summarize summaries     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Rolling summarization**: Update and re-compress summaries over time                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Trigger points**: Activate at 50% of available window or when starting new tasks                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Effective Summarization Instructions**:                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Preserve**: Open tasks, decisions made, important facts, unresolved issues                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Exclude**: Casual conversation, confirmations, intermediate steps, acted-upon information                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Real-World Example**: Claude Code continuously compresses historical context during extended coding sessions, <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> preserving current file state and recent operations while summarizing earlier changes [2].                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Technique 3: Offloading                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Offloading moves detailed data outside the context window into external memory systems [2].                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Storage Options**:                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Vector databases                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - File systems                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Structured databases                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Knowledge bases                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Pattern**:                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. Agent saves detailed outputs immediately after generation                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. Maintains references (IDs or summaries) in context                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. Queries external store when detailed information needed                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 4. Retrieves and includes relevant content in next prompt                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Example**: Processing 1,000 emails - store full content externally with IDs, keep only summaries in context,  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> retrieve specific emails on demand [2].                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Technique 4: Atomic Tools                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The atomic tool pattern provides general-purpose, single-responsibility tools instead of dozens of specialized  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools [2].                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Principles**:                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Follow Unix philosophy: do one thing well                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Each tool handles a specific, precisely defined task                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enable clean data flow between tools                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Reduce prompt bloat from extensive tool descriptions                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Benefits**:                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Reduces debugging complexity                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Improves maintainability                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enhances orchestration flexibility                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Minimizes system prompt token overhead                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Examples**: Replit, Cursor, and LangChain use separate \"read_file,\" \"analyze_code,\" and \"write_file\" tools    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> rather than combined \"analyze_and_fix_code\" tools [2].                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Technique 5: Context Isolation (Sub-Agents)                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context isolation uses sub-agent architectures for token-heavy or logically isolated subtasks [2].              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Architecture**:                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Main agent acts as orchestrator                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Spawns dedicated sub-agents for focused missions                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Each sub-agent receives fresh, minimal context                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Returns only condensed output to main agent                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Advantages**:                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Isolates complexity and prevents cross-task pollution                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enables parallelization of concurrent subtasks                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Supports specialization with different prompts or models                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Expands total system token capacity                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation**: LangGraph and similar frameworks provide built-in support for sub-agent lifecycle           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> management, context isolation, and result aggregation [2].                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Technique 6: Conservative Context Management                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Conservative management recognizes that technical maximum context doesn't equal optimal usage [2].              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Key Principles**:                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Start fresh frequently after completing major tasks                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Reset when reaching 50% of available window                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Use query-aware contextualization (include only relevant context)                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Break complex tasks into smaller subtasks with fresh context                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Strategic Positioning**:                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Place critical information at beginning and end of context                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Avoid \"lost in the middle\" phenomenon where buried information gets overlooked                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Monitor token counts in real-time                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Set automatic triggers at specific thresholds (40% warning, 60% action)                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 6. Retrieval-Augmented Generation (RAG) Techniques                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> RAG represents a central context engineering challenge, enabling agents to access external knowledge            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> dynamically [1][4].                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Core RAG Components                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Query Classification**                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Determine if retrieval is needed (some queries don't require external information)                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Binary classifier separates \"sufficient\" vs \"insufficient\" queries                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Saves costs by avoiding unnecessary retrieval [4]                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Chunking Strategy**                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Optimal chunk sizes: 256-512 tokens                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Small2big approach**: Start with small chunks for search, expand to larger chunks for generation            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Sliding windows**: Overlap tokens between chunks for context preservation [4]                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Metadata and Hybrid Search**                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Add titles, keywords, hypothetical questions to chunks                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Combine vector search (semantic matching) with BM25 (keyword search)                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Provides better balance than HyDE (which is more accurate but inefficient) [4]                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Embedding Models**                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Choose models appropriate for your domain                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - LLM-Embedder from FlagEmbedding offers good balance of performance and size                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Cohere provides strong commercial options [4]                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Reranking**                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Reorder retrieved documents by relevance                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **monoT5**: Best balance of performance and efficiency                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **RankLLaMA**: Best overall performance                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **TILDEv2**: Fastest option [4]                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Document Repacking**                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Arrange documents in ascending order of relevance (\"reverse\" method)                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Place relevant information at start or end for better LLM processing                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Optimizes information presentation after reranking [4]                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Summarization**                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Remove redundant or unnecessary information before LLM call                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Use tools like Recomp for extractive and abstractive compression                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Reduces costs but adds latency [4]                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Advanced RAG Patterns                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Agentic RAG**: Combines multiple retrieval strategies                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - AST parsing for code                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Grep searches for text                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Knowledge graphs for relationships                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - LLM-based re-ranking for semantic chunking [1]                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Multimodal Retrieval**                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Text-to-image: Query database for similar images                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Image-to-text: Match similar images to retrieve captions                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Ensures groundedness with real, verified information [4]                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 7. Real-World Implementations and Examples                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Production Systems                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Manus** (Production Agent Platform)                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Executes workflows requiring 50+ tool calls per run                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Employs aggressive pruning of tool outputs after acknowledgment                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Uses rolling summarization at workflow phase boundaries                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Offloads detailed results to structured storage                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Without context engineering, platform would be economically unviable [2]                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Claude Code** (Anthropic)                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Implements hierarchical summarization in tool call histories                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Auto-compact feature activates at 95% context capacity                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enables extended coding sessions without coherence loss                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Preserves current file state while summarizing earlier changes [1][2]                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **ChatGPT** (OpenAI)                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Auto-generates user preferences from conversations                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Maintains long-term memories across sessions                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Demonstrates both benefits and risks of context management (unexpected location injection example) [1]        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Cursor/Windsurf** (Development Tools)                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Learns coding patterns and project context over time                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Uses AGENTS.md or similar configuration files                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Provides context-aware code suggestions [1]                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### AI Configuration Files                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Research on 10,000 GitHub repositories found that 5% (466 repositories) had adopted AI configuration files [3]: <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Common Formats**:                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - AGENTS.md (tool-agnostic standard)                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - CLAUDE.md (Anthropic's Claude Code)                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - copilot-instructions.md (GitHub Copilot)                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - GEMINI.md (Google Gemini)                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Content Categories** (from empirical analysis):                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. Conventions/best practices (50 instances)                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. Contribution guidelines (48)                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. Architecture and project structure (47)                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 4. Build commands (40)                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 5. Project description (32)                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 6. Testing instructions (32)                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 7. Tech stack and dependencies (15)                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 8. Getting started and setup (11)                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Writing Styles** observed in configuration files [3]:                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Descriptive**: \"This project uses the Linux Kernel Style Guideline\"                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Prescriptive**: \"Use factories for all test data\"                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Prohibitive**: \"Never commit directly to the main branch\"                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Explanatory**: \"Avoid hard-coded waits to prevent timing issues\"                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Conditional**: \"If you need to use reflection, use ReflectionUtils APIs\"                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 8. Best Practices and Design Patterns                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Architectural Best Practices                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **1. Design for Context Engineering from the Start** [2]                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Build context tracking into agent architecture from first prototype                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Establish clear patterns for when pruning, summarization, and offloading occur                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Create abstractions that make context management decisions explicit and testable                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **2. Establish Clear Metrics** [2]                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Track token usage per interaction (average and peak)                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Measure model performance across different context sizes                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Monitor costs directly tied to context length                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Assess user experience metrics (latency, accuracy)                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **3. Implement Graceful Degradation** [2]                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Never crash or produce empty responses when hitting context limits                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Automatically trigger aggressive summarization or pruning                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Reset to clean state with summary of prior work                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Provide explanations when context limits force interruption                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **4. Combine Multiple Techniques** [1][2]                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Use pruning for routine cleanup                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Apply summarization for compressing important information                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Implement offloading for large data                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Deploy atomic tools for efficiency                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Utilize sub-agents for isolation                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Practice conservative management for reliability                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Testing and Validation                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Comprehensive Testing Scenarios** [2]:                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Evaluate with minimal context                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Test with moderate context                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Verify near-maximum context handling                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Confirm pruning and summarization preserve essential information                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Validate offloading and retrieval mechanisms                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Test edge cases where summarization might introduce errors                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Continuous Monitoring and Iteration** [2]:                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Analyze context usage patterns regularly                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Identify optimization opportunities                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - A/B test different pruning thresholds                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Experiment with summarization frequencies                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Evolve approach based on real-world usage data                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Documentation and Maintenance                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Explicit Documentation** [2]:                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Document why pruning occurs at specific thresholds                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Explain how summarization prompts were designed                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Clarify what information gets offloaded vs kept in context                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Prevent well-intentioned changes from breaking tuned systems                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Version Control for AI Configuration** [3]:                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Treat AI configuration files as maintained software artifacts                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Version, review, and quality-assure like source code                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Track evolution and co-evolution with source code                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enable team-wide consistency in AI behavior                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 9. Performance Gains and Impact                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Quantified Benefits                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Teams implementing proper context engineering report substantial improvements [2]:                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **10x reduction in token usage** through pruning and summarization alone                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **50-70% latency improvements** from keeping contexts lean and focused                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Similar magnitude cost reductions** making previously impractical workflows viable                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Dramatic accuracy and reliability improvements** when models work within effective context windows          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Economic Viability                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering transforms AI agent economics:                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Production systems like Manus would be economically unviable without it [2]                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Multi-agent systems can cost 15x more tokens than single-agent chat without proper management [1]             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Strategic context management makes complex, long-running workflows practical at scale                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 10. Future Directions and Research Opportunities                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Emerging Areas                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Automated Context Optimization** [3]                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Feedback loops that update configuration files based on observed results                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Automated testing of how content, structure, and style affect agent behavior                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Machine learning approaches to optimize context selection                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Co-Evolution Studies** [3]                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Research on co-evolution of source code and AI configuration files                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Similar to studies on source code and comment co-evolution                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Understanding how context requirements change with code                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Standardization Efforts** [3]                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Whether standard schemas could improve interoperability                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Centralized vs module-level configuration files                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Coordinating instructions for multiple agents                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Open Questions                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - How do tone and phrasing in configuration files influence agent adherence? [3]                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - What is the optimal balance between context comprehensiveness and focus?                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - How can we better measure and predict context rot?                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - What are the best practices for context management in multi-modal agents?                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## Conclusion                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering has evolved from an esoteric concern to a fundamental discipline in AI systems engineering. <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> As one researcher noted, \"context engineering is effectively the #1 job of engineers building AI agents\" [1].   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The difference between naive demos and magical products lies not in the underlying model, but in the quality of <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> context provided.                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Key Takeaways                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **Context engineering is system architecture**, not just prompt writing - it encompasses the entire          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> information pipeline before LLM calls                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **Multiple techniques work together** - successful systems combine pruning, summarization, offloading,       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> atomic tools, context isolation, and conservative management                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **Performance and cost are directly impacted** - proper context engineering delivers 10x token reductions,   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 50-70% latency improvements, and dramatic cost savings                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 4. **Real-world adoption is growing** - 5% of surveyed open-source projects have adopted AI configuration       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> files, with conventions still evolving [3]                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 5. **Best practices are emerging** - design for context management from the start, establish clear metrics,     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> test comprehensively, and document explicitly                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### Strategic Recommendations                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For teams building AI agents:                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Invest in context engineering infrastructure** early in development                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Treat AI configuration files as first-class software artifacts** requiring version control and maintenance  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Monitor context usage continuously** and optimize based on real data                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Combine multiple context engineering techniques** rather than relying on single approaches                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Test across different context scenarios** to ensure robustness                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The teams that master context engineering will build AI agents that don't merely work in demos but thrive in    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> production, delivering reliable, cost-effective, and exceptional user experiences.                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## Sources                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [1] **What is Context Engineering for AI Agents? - Adaline Labs**                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://labs.adaline.ai/p/what-is-context-engineering-for-ai                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Comprehensive overview of context engineering fundamentals, four core strategies (Writing, Selecting,           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Compressing, Isolating), and real-world examples including ChatGPT, Claude Code, and Cursor.                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [2] **Context Engineering: The Invisible Discipline Keeping AI Agents from Drowning in Their Own Memory - Juan  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> C Olamendy, Medium**                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowning <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> -in-their-own-memory-c0283ca6a954                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Detailed exploration of six core techniques (Pruning, Summarization, Offloading, Atomic Tools, Context          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Isolation, Conservative Management) with implementation details and best practices.                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [3] **Context Engineering for AI Agents in Open-Source Software - arXiv**                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://arxiv.org/html/2510.21413v1                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Academic research paper presenting empirical study of AI configuration files (AGENTS.md) in 10,000 GitHub       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> repositories, including adoption rates, content categories, and evolution patterns.                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [4] **Top RAG Techniques You Should Know (Wang et al., 2024) - Louis Bouchard**                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://www.louisbouchard.ai/top-rag-techniques/                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Comprehensive breakdown of RAG system components and best practices including query classification, chunking,   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> hybrid search, embedding models, reranking, and document repacking based on Wang et al.'s research.             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Now I'll compile a comprehensive report on context engineering fundamentals and core approaches for AI agents   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m based on my research findings.                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Context Engineering for AI Agents: Comprehensive Research Report                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## Executive Summary                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering has emerged as a critical discipline in AI agent development, representing a fundamental    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m shift from simple prompt engineering to sophisticated system architecture. As Andrej Karpathy describes it,     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m context engineering is \"the delicate art and science of filling the context window with just the right          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m information for the next step\" [1]. This report explores the fundamentals, core approaches, key techniques, and \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m best practices for building effective AI agents through strategic context management.                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 1. What is Context Engineering?                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Definition and Evolution                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering is the discipline of strategically managing, curating, and controlling the information      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m provided to large language models (LLMs) [1][2]. It represents an evolution from **prompt engineering** (which  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m focuses on crafting instructions) to **context engineering** (which focuses on architecting the entire          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m information pipeline before the LLM call).                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m While prompt engineering concentrated on writing clever, concise instructions for simple tasks, context         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m engineering treats the entire pipeline as engineerable infrastructure [1]. This includes:                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Dynamic information gathering**: RAG systems, API calls, database queries                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Memory management**: Short-term conversation state and long-term knowledge                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Tool coordination**: Making external functions available when needed                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Output structuring**: Defining schemas and formats for consistent results                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### The Shift to Agentic AI                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Early AI development relied heavily on prompting methods like chain-of-thought, ReAct, and self-consistency for \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m complex tasks [1]. However, as applications evolved into AI agents with multi-step reasoning, long-running      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m conversations, and dynamic information retrieval, these approaches hit significant limitations. Context         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m engineering emerged as the solution to handle:                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Multi-step reasoning requiring tool use                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Long-running conversations with memory                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Dynamic information retrieval from databases                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Coordination between multiple AI systems                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 2. Why Context Engineering Matters                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Critical Impact Areas                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering directly impacts three fundamental aspects of AI agent systems [1][2]:                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **1. Performance and Reliability**                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Poor context management creates \"context rot\" where model quality degrades well before hitting technical      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m token limits                                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Research shows models perform optimally only in the first 50,000-100,000 tokens, even with million-token      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m context windows [2]                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Context failures manifest as hallucinations, inconsistent outputs, and task failures                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **2. Cost Efficiency**                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Every token sent to an LLM incurs inference costs                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Naive approaches that append all tool results can generate hundreds of thousands of tokens after just several \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m rounds                                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Production systems without context engineering quickly become cost-prohibitive at scale [2]                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **3. User Experience**                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Processing 500,000 tokens takes significantly longer than 5,000 tokens                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Context engineering reduces latency and improves responsiveness                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Proper context management builds user trust by preventing unexpected behaviors                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Common Context Problems                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Poor context management creates four major failure modes [1]:                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Context poisoning**: Hallucinations contaminating future responses                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Context distraction**: Too much information overwhelming the model                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Context confusion**: Conflicting information causing errors                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Context clash**: Disagreeing sources leading to inconsistent outputs                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m As one researcher noted, \"Most agent failures are context failures\" - the system didn't provide adequate        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m information for success [1].                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 3. Types of Context in AI Agents                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Modern AI agents require multiple context types working together [1][3]:                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Static Context                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Prompts**: Core behavior rules and examples                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Tool definitions**: Available functions and their parameters                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Output schemas**: Response format requirements                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Configuration files**: Project-specific instructions (AGENTS.md, CLAUDE.md)                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Dynamic Context                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **User input**: The immediate task or question                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Chat history**: Short-term conversation memory                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Long-term memory**: Persistent preferences and past learnings                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Retrieved knowledge**: RAG results from databases or APIs                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Tool responses**: Feedback from executed functions                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Workflow state**: Information stored across agent steps                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Research on open-source projects found that AI configuration files commonly include: coding conventions (50     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m instances), contribution guidelines (48), architecture descriptions (47), build commands (40), and testing      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m instructions (32) [3].                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 4. Core Context Engineering Strategies                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Strategy 1: Writing Context (Memory Management)                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Writing context involves saving information outside the context window to preserve valuable token space [1].    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Scratchpads**: Temporary note-taking within a single session                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Anthropic's multi-agent researcher saves initial plans to \"Memory\" to prevent loss when context exceeds       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 200,000 tokens                                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Implementation options include file-based tools or runtime state objects                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Long-Term Memories**: Information retained across multiple sessions                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **ChatGPT**: Auto-generates user preferences from conversations                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Cursor/Windsurf**: Learns coding patterns and project context                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Reflexion agents**: Create self-generated memories from task feedback                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m This enables personalization and creates evolving experiences that improve over time [1].                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Strategy 2: Selecting Context (Intelligent Retrieval)                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Selecting context means pulling only relevant information into the context window [1][4].                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Targeted Retrieval**                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Fine-grained control over what information gets exposed to the LLM                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Selective exposure of specific parts from scratchpads or state objects                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Reduces noise and improves decision-making                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Memory Selection Types**                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Episodic memories**: Few-shot examples showing desired behavior                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Procedural memories**: Instructions stored in configuration files                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Semantic memories**: Facts relevant to current context (embeddings, RAG)                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Agentic RAG**: Applying RAG to tool descriptions                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Too many tools create \"model confusion\" about which to use                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - RAG-based tool selection improves accuracy by 3-fold according to recent research [1]                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Strategy 3: Compressing Context (Optimization)                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Compressing context retains only tokens required to perform a task [1][2].                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Context Summarization**                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Condenses information while preserving essential details                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Claude Code's \"auto-compact\" feature summarizes when context exceeds 95% capacity                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Applies at multiple levels: full trajectory, specific points, agent boundaries                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Some companies use fine-tuned models specifically for summarization                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Context Trimming**                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Uses filtering or \"pruning\" approaches                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Hard-coded heuristics: Removing older messages from lists                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Learned approaches: Trained context pruners for specific domains                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Offers immediate, predictable context reduction                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Strategy 4: Isolating Context (Structural Separation)                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Isolating context splits it across different components to reduce cognitive load [1][2].                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Multi-Agent Architectures**                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Splits context across sub-agents, each with their own context windows, tools, and instructions                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enables separation of concerns for specialized subtasks                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Expands total token capacity across the system                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Challenge: Can increase costs up to 15x more tokens than single-agent systems                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Sandboxes and Execution Environments**                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Isolates code execution from the LLM's context window                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Persists state across multiple responses                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Excels at handling token-heavy objects (images, audio files)                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Only selective results passed back to the LLM                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 5. Six Core Context Engineering Techniques                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Technique 1: Pruning                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Pruning systematically removes older, less relevant, or redundant information from the context window [2].      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Approaches**:                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Chronological pruning**: Remove oldest exchanges first (simplest approach)                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Heuristic-based pruning**: Drop confirmations and casual conversation while preserving instructions         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Priority-based pruning**: Assign importance scores to different message types                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Semantic pruning**: Analyze content and remove redundant or off-topic information                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Best Practices**:                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Trigger automatically at 80-95% of maximum token size                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Pair with summarization for maximum effectiveness                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Summarize before dropping content to preserve essential information                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Example**: After five tool calls, keep only the most recent 2-3 turns, summarize earlier results, and drop    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m raw outputs [2].                                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Technique 2: Summarization                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Summarization compresses long message chains into concise summaries that preserve semantic relevance [2].       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Patterns**:                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Hierarchical summarization**: Break long contexts into chunks, summarize each, then summarize summaries     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Rolling summarization**: Update and re-compress summaries over time                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Trigger points**: Activate at 50% of available window or when starting new tasks                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Effective Summarization Instructions**:                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Preserve**: Open tasks, decisions made, important facts, unresolved issues                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Exclude**: Casual conversation, confirmations, intermediate steps, acted-upon information                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Real-World Example**: Claude Code continuously compresses historical context during extended coding sessions, \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m preserving current file state and recent operations while summarizing earlier changes [2].                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Technique 3: Offloading                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Offloading moves detailed data outside the context window into external memory systems [2].                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Storage Options**:                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Vector databases                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - File systems                                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Structured databases                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Knowledge bases                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Pattern**:                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. Agent saves detailed outputs immediately after generation                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. Maintains references (IDs or summaries) in context                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. Queries external store when detailed information needed                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 4. Retrieves and includes relevant content in next prompt                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Example**: Processing 1,000 emails - store full content externally with IDs, keep only summaries in context,  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m retrieve specific emails on demand [2].                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Technique 4: Atomic Tools                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The atomic tool pattern provides general-purpose, single-responsibility tools instead of dozens of specialized  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools [2].                                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Principles**:                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Follow Unix philosophy: do one thing well                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Each tool handles a specific, precisely defined task                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enable clean data flow between tools                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Reduce prompt bloat from extensive tool descriptions                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Benefits**:                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Reduces debugging complexity                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Improves maintainability                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enhances orchestration flexibility                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Minimizes system prompt token overhead                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Examples**: Replit, Cursor, and LangChain use separate \"read_file,\" \"analyze_code,\" and \"write_file\" tools    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m rather than combined \"analyze_and_fix_code\" tools [2].                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Technique 5: Context Isolation (Sub-Agents)                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context isolation uses sub-agent architectures for token-heavy or logically isolated subtasks [2].              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Architecture**:                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Main agent acts as orchestrator                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Spawns dedicated sub-agents for focused missions                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Each sub-agent receives fresh, minimal context                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Returns only condensed output to main agent                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Advantages**:                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Isolates complexity and prevents cross-task pollution                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enables parallelization of concurrent subtasks                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Supports specialization with different prompts or models                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Expands total system token capacity                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation**: LangGraph and similar frameworks provide built-in support for sub-agent lifecycle           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m management, context isolation, and result aggregation [2].                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Technique 6: Conservative Context Management                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Conservative management recognizes that technical maximum context doesn't equal optimal usage [2].              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Key Principles**:                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Start fresh frequently after completing major tasks                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Reset when reaching 50% of available window                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Use query-aware contextualization (include only relevant context)                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Break complex tasks into smaller subtasks with fresh context                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Strategic Positioning**:                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Place critical information at beginning and end of context                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Avoid \"lost in the middle\" phenomenon where buried information gets overlooked                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Monitor token counts in real-time                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Set automatic triggers at specific thresholds (40% warning, 60% action)                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 6. Retrieval-Augmented Generation (RAG) Techniques                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m RAG represents a central context engineering challenge, enabling agents to access external knowledge            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m dynamically [1][4].                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Core RAG Components                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Query Classification**                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Determine if retrieval is needed (some queries don't require external information)                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Binary classifier separates \"sufficient\" vs \"insufficient\" queries                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Saves costs by avoiding unnecessary retrieval [4]                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Chunking Strategy**                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Optimal chunk sizes: 256-512 tokens                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Small2big approach**: Start with small chunks for search, expand to larger chunks for generation            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Sliding windows**: Overlap tokens between chunks for context preservation [4]                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Metadata and Hybrid Search**                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Add titles, keywords, hypothetical questions to chunks                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Combine vector search (semantic matching) with BM25 (keyword search)                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Provides better balance than HyDE (which is more accurate but inefficient) [4]                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Embedding Models**                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Choose models appropriate for your domain                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - LLM-Embedder from FlagEmbedding offers good balance of performance and size                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Cohere provides strong commercial options [4]                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Reranking**                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Reorder retrieved documents by relevance                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **monoT5**: Best balance of performance and efficiency                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **RankLLaMA**: Best overall performance                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **TILDEv2**: Fastest option [4]                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Document Repacking**                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Arrange documents in ascending order of relevance (\"reverse\" method)                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Place relevant information at start or end for better LLM processing                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Optimizes information presentation after reranking [4]                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Summarization**                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Remove redundant or unnecessary information before LLM call                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Use tools like Recomp for extractive and abstractive compression                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Reduces costs but adds latency [4]                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Advanced RAG Patterns                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Agentic RAG**: Combines multiple retrieval strategies                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - AST parsing for code                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Grep searches for text                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Knowledge graphs for relationships                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - LLM-based re-ranking for semantic chunking [1]                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Multimodal Retrieval**                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Text-to-image: Query database for similar images                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Image-to-text: Match similar images to retrieve captions                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Ensures groundedness with real, verified information [4]                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 7. Real-World Implementations and Examples                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Production Systems                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Manus** (Production Agent Platform)                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Executes workflows requiring 50+ tool calls per run                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Employs aggressive pruning of tool outputs after acknowledgment                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Uses rolling summarization at workflow phase boundaries                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Offloads detailed results to structured storage                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Without context engineering, platform would be economically unviable [2]                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Claude Code** (Anthropic)                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Implements hierarchical summarization in tool call histories                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Auto-compact feature activates at 95% context capacity                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enables extended coding sessions without coherence loss                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Preserves current file state while summarizing earlier changes [1][2]                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **ChatGPT** (OpenAI)                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Auto-generates user preferences from conversations                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Maintains long-term memories across sessions                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Demonstrates both benefits and risks of context management (unexpected location injection example) [1]        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Cursor/Windsurf** (Development Tools)                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Learns coding patterns and project context over time                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Uses AGENTS.md or similar configuration files                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Provides context-aware code suggestions [1]                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### AI Configuration Files                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Research on 10,000 GitHub repositories found that 5% (466 repositories) had adopted AI configuration files [3]: \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Common Formats**:                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - AGENTS.md (tool-agnostic standard)                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - CLAUDE.md (Anthropic's Claude Code)                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - copilot-instructions.md (GitHub Copilot)                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - GEMINI.md (Google Gemini)                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Content Categories** (from empirical analysis):                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. Conventions/best practices (50 instances)                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. Contribution guidelines (48)                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. Architecture and project structure (47)                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 4. Build commands (40)                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 5. Project description (32)                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 6. Testing instructions (32)                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 7. Tech stack and dependencies (15)                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 8. Getting started and setup (11)                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Writing Styles** observed in configuration files [3]:                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Descriptive**: \"This project uses the Linux Kernel Style Guideline\"                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Prescriptive**: \"Use factories for all test data\"                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Prohibitive**: \"Never commit directly to the main branch\"                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Explanatory**: \"Avoid hard-coded waits to prevent timing issues\"                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Conditional**: \"If you need to use reflection, use ReflectionUtils APIs\"                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 8. Best Practices and Design Patterns                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Architectural Best Practices                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **1. Design for Context Engineering from the Start** [2]                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Build context tracking into agent architecture from first prototype                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Establish clear patterns for when pruning, summarization, and offloading occur                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Create abstractions that make context management decisions explicit and testable                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **2. Establish Clear Metrics** [2]                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Track token usage per interaction (average and peak)                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Measure model performance across different context sizes                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Monitor costs directly tied to context length                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Assess user experience metrics (latency, accuracy)                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **3. Implement Graceful Degradation** [2]                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Never crash or produce empty responses when hitting context limits                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Automatically trigger aggressive summarization or pruning                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Reset to clean state with summary of prior work                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Provide explanations when context limits force interruption                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **4. Combine Multiple Techniques** [1][2]                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Use pruning for routine cleanup                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Apply summarization for compressing important information                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Implement offloading for large data                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Deploy atomic tools for efficiency                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Utilize sub-agents for isolation                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Practice conservative management for reliability                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Testing and Validation                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Comprehensive Testing Scenarios** [2]:                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Evaluate with minimal context                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Test with moderate context                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Verify near-maximum context handling                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Confirm pruning and summarization preserve essential information                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Validate offloading and retrieval mechanisms                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Test edge cases where summarization might introduce errors                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Continuous Monitoring and Iteration** [2]:                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Analyze context usage patterns regularly                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Identify optimization opportunities                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - A/B test different pruning thresholds                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Experiment with summarization frequencies                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Evolve approach based on real-world usage data                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Documentation and Maintenance                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Explicit Documentation** [2]:                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Document why pruning occurs at specific thresholds                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Explain how summarization prompts were designed                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Clarify what information gets offloaded vs kept in context                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Prevent well-intentioned changes from breaking tuned systems                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Version Control for AI Configuration** [3]:                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Treat AI configuration files as maintained software artifacts                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Version, review, and quality-assure like source code                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Track evolution and co-evolution with source code                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enable team-wide consistency in AI behavior                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 9. Performance Gains and Impact                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Quantified Benefits                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Teams implementing proper context engineering report substantial improvements [2]:                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **10x reduction in token usage** through pruning and summarization alone                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **50-70% latency improvements** from keeping contexts lean and focused                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Similar magnitude cost reductions** making previously impractical workflows viable                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Dramatic accuracy and reliability improvements** when models work within effective context windows          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Economic Viability                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering transforms AI agent economics:                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Production systems like Manus would be economically unviable without it [2]                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Multi-agent systems can cost 15x more tokens than single-agent chat without proper management [1]             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Strategic context management makes complex, long-running workflows practical at scale                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 10. Future Directions and Research Opportunities                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Emerging Areas                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Automated Context Optimization** [3]                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Feedback loops that update configuration files based on observed results                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Automated testing of how content, structure, and style affect agent behavior                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Machine learning approaches to optimize context selection                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Co-Evolution Studies** [3]                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Research on co-evolution of source code and AI configuration files                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Similar to studies on source code and comment co-evolution                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Understanding how context requirements change with code                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Standardization Efforts** [3]                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Whether standard schemas could improve interoperability                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Centralized vs module-level configuration files                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Coordinating instructions for multiple agents                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Open Questions                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - How do tone and phrasing in configuration files influence agent adherence? [3]                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - What is the optimal balance between context comprehensiveness and focus?                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - How can we better measure and predict context rot?                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - What are the best practices for context management in multi-modal agents?                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## Conclusion                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering has evolved from an esoteric concern to a fundamental discipline in AI systems engineering. \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m As one researcher noted, \"context engineering is effectively the #1 job of engineers building AI agents\" [1].   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The difference between naive demos and magical products lies not in the underlying model, but in the quality of \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m context provided.                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Key Takeaways                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **Context engineering is system architecture**, not just prompt writing - it encompasses the entire          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m information pipeline before LLM calls                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **Multiple techniques work together** - successful systems combine pruning, summarization, offloading,       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m atomic tools, context isolation, and conservative management                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **Performance and cost are directly impacted** - proper context engineering delivers 10x token reductions,   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 50-70% latency improvements, and dramatic cost savings                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 4. **Real-world adoption is growing** - 5% of surveyed open-source projects have adopted AI configuration       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m files, with conventions still evolving [3]                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 5. **Best practices are emerging** - design for context management from the start, establish clear metrics,     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m test comprehensively, and document explicitly                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### Strategic Recommendations                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For teams building AI agents:                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Invest in context engineering infrastructure** early in development                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Treat AI configuration files as first-class software artifacts** requiring version control and maintenance  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Monitor context usage continuously** and optimize based on real data                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Combine multiple context engineering techniques** rather than relying on single approaches                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Test across different context scenarios** to ensure robustness                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The teams that master context engineering will build AI agents that don't merely work in demos but thrive in    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m production, delivering reliable, cost-effective, and exceptional user experiences.                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## Sources                                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [1] **What is Context Engineering for AI Agents? - Adaline Labs**                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://labs.adaline.ai/p/what-is-context-engineering-for-ai                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Comprehensive overview of context engineering fundamentals, four core strategies (Writing, Selecting,           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Compressing, Isolating), and real-world examples including ChatGPT, Claude Code, and Cursor.                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [2] **Context Engineering: The Invisible Discipline Keeping AI Agents from Drowning in Their Own Memory - Juan  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m C Olamendy, Medium**                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowning \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m -in-their-own-memory-c0283ca6a954                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Detailed exploration of six core techniques (Pruning, Summarization, Offloading, Atomic Tools, Context          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Isolation, Conservative Management) with implementation details and best practices.                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [3] **Context Engineering for AI Agents in Open-Source Software - arXiv**                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://arxiv.org/html/2510.21413v1                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Academic research paper presenting empirical study of AI configuration files (AGENTS.md) in 10,000 GitHub       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m repositories, including adoption rates, content categories, and evolution patterns.                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [4] **Top RAG Techniques You Should Know (Wang et al., 2024) - Louis Bouchard**                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://www.louisbouchard.ai/top-rag-techniques/                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Comprehensive breakdown of RAG system components and best practices including query classification, chunking,   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m hybrid search, embedding models, reranking, and document repacking based on Wang et al.'s research.             \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Advanced Context Engineering Techniques for AI Agents: Implementation Guide                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## Executive Summary                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering has emerged as a critical discipline for building production-grade AI agents. As LLMs have  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> fixed context windows and suffer from performance degradation with long contexts (\"context rot\"), strategic     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> management of what information reaches the model determines system reliability, cost-efficiency, and accuracy.  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> This report synthesizes advanced implementation techniques, architectural patterns, and practical strategies    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from leading AI frameworks and production systems.                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 1. Context Window Management and Optimization                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 1.1 Understanding Context Limitations                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Modern LLMs advertise large context windows (up to 1 million tokens), but research shows that **effective       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> performance occurs within much smaller windows** - typically the first 50,000-100,000 tokens [2]. Beyond this   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> threshold, models experience:                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Context rot**: Degraded accuracy and instruction-following capability                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Lost in the middle phenomenon**: Information buried mid-context gets overlooked                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Increased latency**: Processing 500,000 tokens takes significantly longer than 5,000 tokens                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Higher costs**: Every token incurs inference costs that compound with repeated processing                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 1.2 Conservative Context Management Strategy                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Approach:**                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **Set aggressive thresholds**: Trigger context management at 40-60% of maximum window, not 80-90% [2]        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **Start fresh frequently**: Reset context after completing major tasks rather than accumulating indefinitely <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **Strategic positioning**: Place critical instructions at the beginning and end of prompts where models pay  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> most attention [2]                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 4. **Query-aware contextualization**: Dynamically adjust included context based on the specific task, not       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> comprehensive history [2]                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Code Pattern (Threshold Monitoring):**                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> def should_trigger_context_management(current_tokens, max_tokens):                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     \"\"\"Trigger at 50% to maintain optimal performance\"\"\"                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     threshold = max_tokens * 0.5                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     return current_tokens &gt;= threshold                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Monitor in real-time                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> if should_trigger_context_management(token_count, context_window_size):                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # Trigger summarization or pruning                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     await compress_context()                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Trade-offs:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Maintains optimal model performance                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Reduces costs and latency                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Requires more frequent context management operations                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ May lose some historical detail                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 2. Long-Term Memory and State Management                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 2.1 Multi-Tier Memory Architecture                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Production systems implement **hierarchical memory** with distinct short-term and long-term storage [2][3]:     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Architecture Components:**                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **Short-term memory (Active Context)**: Recent messages and current task context                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **Long-term memory (External Storage)**: Compressed historical information, facts, decisions                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **Working memory (External Databases)**: Tool outputs, intermediate results, large datasets                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 2.2 LlamaIndex Custom Memory Implementation                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> LlamaIndex provides a sophisticated approach to managing multi-turn conversations with custom memory blocks     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [3]:                                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Pattern:**                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> import tiktoken                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from llama_index.core.memory import Memory, BaseMemoryBlock                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from llama_index.core.llms import ChatMessage, TextBlock                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> class CondensedMemoryBlock(BaseMemoryBlock):                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     \"\"\"Custom memory block that condenses past messages while maintaining token limits\"\"\"                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     current_memory: List = Field(default_factory=list)                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     token_limit: int = Field(default=50000)                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     tokenizer: tiktoken.Encoding = tiktoken.encoding_for_model(\"gpt-4o\")                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     async def _aget(self, messages: Optional[List[ChatMessage]] = None, **kwargs) -&gt; str:                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Return condensed memory as a single string\"\"\"                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return \"\\n\".join(self.current_memory)                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     async def _aput(self, messages: List[ChatMessage]) -&gt; None:                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Push messages and maintain token limit\"\"\"                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         for message in messages:                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             text_contents = \"\\n\".join(                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 block.text for block in message.blocks                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 if isinstance(block, TextBlock)                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             )                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             memory_str = f\"&lt;message role={message.role}&gt;\\n{text_contents}\\n&lt;/message&gt;\"                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             self.current_memory.append(memory_str)                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Enforce token limit by removing oldest messages                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         message_length = sum(                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             len(self.tokenizer.encode(msg)) for msg in self.current_memory                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         )                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         while message_length &gt; self.token_limit:                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             self.current_memory = self.current_memory[1:]                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             message_length = sum(                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 len(self.tokenizer.encode(msg)) for msg in self.current_memory                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             )                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Configure memory with aggressive short-term limits                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> memory = Memory.from_defaults(                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     session_id=\"user-session-01\",                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     token_limit=60000,                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     token_flush_size=5000,                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     memory_blocks=[CondensedMemoryBlock(name=\"condensed_memory\")],                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # Force short-term memory to always flush to long-term                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     chat_history_token_ratio=0.0001,                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> )                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Key Features:**                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Automatic token counting and enforcement                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Configurable flush thresholds                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Seamless integration with agent workflows                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Prevents multi-turn confusion by limiting active context [3]                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 2.3 LangChain Conversational Memory                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> LangChain offers built-in memory management for maintaining conversation context [5]:                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from langchain.memory import ConversationBufferMemory                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Initialize memory for context retention                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> memory = ConversationBufferMemory(memory_key=\"chat_history\")                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Integrate with agent                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> agent = initialize_agent(                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     tools,                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     llm,                                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     agent=\"zero-shot-react-description\",                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     memory=memory,                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     verbose=True                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> )                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Memory automatically tracks conversation history                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> response = agent.run(\"What is the weather in Paris?\")                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> response = agent.run(\"Can you remind me what I just asked?\")                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Output: \"You just asked about the weather in Paris.\"                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Trade-offs:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Simple integration with minimal code                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Automatic context tracking                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Basic buffer approach may not scale to long conversations                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Requires additional compression strategies for production use                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 3. Context Compression and Summarization Techniques                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 3.1 Hierarchical Summarization                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Strategy** [2]:                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **Break context into logical chunks** (by task phase, time period, or topic)                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **Summarize each chunk independently** using the LLM itself                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **Optionally summarize the summaries** for deeply nested workflows                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 4. **Replace verbose content with compressed summaries** in subsequent prompts                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Trigger Points:**                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - When context reaches 50% of available window                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - At natural workflow boundaries (task completion, phase transitions)                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Before starting new major tasks                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Summarization Prompt Pattern:**                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> async def summarize_context(messages: List[ChatMessage], llm) -&gt; str:                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     \"\"\"Use LLM to compress conversation history\"\"\"                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     summarization_prompt = \"\"\"                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     Summarize the following conversation, preserving:                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     - Key facts and decisions made                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     - Open tasks and unresolved issues                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     - Important context for ongoing work                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     Exclude:                                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     - Casual conversation and confirmations                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     - Intermediate steps that led to decisions                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     - Information already acted upon                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     Conversation:                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     {conversation}                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     Provide a concise summary:                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     \"\"\"                                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     conversation_text = \"\\n\".join([                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         f\"{msg.role}: {msg.content}\" for msg in messages                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     ])                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     summary = await llm.acomplete(                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         summarization_prompt.format(conversation=conversation_text)                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     )                                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     return summary.text                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 3.2 Rolling Summarization                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Pattern**: Summaries themselves get updated and re-compressed over time [2]                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> class RollingSummarizer:                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def __init__(self, max_summary_tokens=5000):                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.current_summary = \"\"                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.max_tokens = max_summary_tokens                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     async def update_summary(self, new_messages: List[ChatMessage], llm):                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Append new information to existing summary\"\"\"                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # If summary is getting too large, re-compress it                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         if len(self.tokenizer.encode(self.current_summary)) &gt; self.max_tokens:                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             self.current_summary = await self._recompress_summary(llm)                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Append new information                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         new_content = \"\\n\".join()                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         update_prompt = f\"\"\"                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         Current summary: {self.current_summary}                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         New information: {new_content}                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         Update the summary to incorporate the new information while maintaining conciseness.                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.current_summary = await llm.acomplete(update_prompt)                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return self.current_summary                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Trade-offs:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Enables indefinite conversation length with bounded context                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Maintains semantic relevance over time                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Potential information loss in compression                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Computational overhead for summarization operations                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Requires careful tuning of what to preserve                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 4. Multi-Turn Conversation Context Handling                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 4.1 The Multi-Turn Confusion Problem                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Recent research shows LLM performance significantly degrades in multi-turn conversations [3]. Without proper    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> management, agents accumulate hundreds of thousands of tokens after just several rounds of tool calls.          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 4.2 Solution: Aggressive Context Flushing                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **LlamaIndex Pattern** [3]:                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Configure memory to prevent multi-turn accumulation                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> memory = Memory.from_defaults(                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     session_id=\"session-id\",                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     token_limit=60000,                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     token_flush_size=5000,                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     memory_blocks=,                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     insert_method=\"user\",                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # Critical: Set extremely low ratio to force immediate flushing                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     chat_history_token_ratio=0.0001,  # Effectively 0                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> )                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Result: Short-term memory always contains minimal turns                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # All history is condensed into long-term memory block                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Output Structure:**                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> MessageRole.USER                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> &lt;memory&gt;                                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   &lt;condensed_memory&gt;                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     &lt;message role=MessageRole.USER&gt;                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>       Hello! My name is Logan                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     &lt;/message&gt;                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     &lt;message role=MessageRole.ASSISTANT&gt;                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>       Hello! How can I help you?                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     &lt;/message&gt;                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     ...                                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>   &lt;/condensed_memory&gt;                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> &lt;/memory&gt;                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> What was my name again?                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 4.3 Context Injection Pattern                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The condensed memory is injected as a **single user message** containing all historical context, followed by    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> the current query [3]. This ensures:                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. The LLM sees complete history without token bloat                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. Recent context remains immediately accessible                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. Multi-turn confusion is eliminated                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Trade-offs:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Prevents context rot from long conversations                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Maintains coherence across extended sessions                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Reduces token costs dramatically                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Requires careful design of memory block structure                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ May lose fine-grained conversational nuance                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 5. Tool Use and Function Calling Context Patterns                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 5.1 The Atomic Tools Pattern                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Rather than binding many specialized tools (which bloats system prompts), provide **few general-purpose tools** <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> with clear, narrow scopes [2]:                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Design Principles:**                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Single responsibility**: Each tool does one thing well (Unix philosophy)                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Minimal ambiguity**: Clear input schemas and predictable outputs                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Composability**: Tools can be chained together                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Reduced prompt overhead**: Fewer tool descriptions in system prompt                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Example Implementation:**                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # ❌ BAD: Specialized, bloated tools                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools = [                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     analyze_and_fix_code_tool,                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     read_and_transform_data_tool,                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     search_and_summarize_tool,                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # ... 20+ more specialized tools                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ]                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # ✅ GOOD: Atomic, composable tools                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools = [                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     read_file_tool,      # Just reads files                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     write_file_tool,     # Just writes files                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     bash_tool,           # Executes shell commands                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     web_search_tool,     # Searches the web                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ]                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Real-World Examples:**                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Replit, Cursor, LangChain agents use highly atomic tool definitions [2]                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Instead of \"analyze_and_fix_code\", they provide separate \"read_file\", \"analyze_code\", \"write_file\" tools that <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> agents chain together                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 5.2 LangChain Function Calling Implementation                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Tool Definition Pattern** [5]:                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from langchain.tools import Tool                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Define atomic function                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> def get_weather(city: str) -&gt; str:                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     \"\"\"Fetches weather information for a given city.\"\"\"                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     response = requests.get(f\"https://api.weatherapi.com/v1/current.json?key={api_key}&amp;q={city}\")               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     data = response.json()                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     return f\"Weather in {city}: {data['current']['condition']['text']}, {data['current']['temp_c']}°C\"          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Wrap as tool with clear description                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> weather_tool = Tool(                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     name=\"get_weather\",                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     func=get_weather,                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     description=\"Fetches weather information for a given city.\"                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> )                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Initialize agent with tools                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from langchain.agents import initialize_agent                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from langchain.chat_models import ChatOpenAI                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> llm = ChatOpenAI(temperature=0)                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools =                                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> agent = initialize_agent(                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     tools,                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     llm,                                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     agent=\"zero-shot-react-description\",                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     verbose=True                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> )                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 5.3 Managing Tool Call Context                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Challenge**: Tool outputs can be massive and quickly fill context windows [2]                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Solution: Offloading Pattern**                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> class ToolOutputManager:                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def __init__(self, storage_backend):                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.storage = storage_backend                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.output_refs = {}                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     async def store_tool_output(self, tool_name: str, output: str) -&gt; str:                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Store large tool output externally, return reference ID\"\"\"                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         output_id = f\"{tool_name}_{uuid.uuid4()}\"                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         await self.storage.save(output_id, output)                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.output_refs = {                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"tool\": tool_name,                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"summary\": output[:200] + \"...\" if len(output) &gt; 200 else output,                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"size\": len(output)                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         }                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return output_id                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     async def retrieve_tool_output(self, output_id: str) -&gt; str:                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Retrieve full output when needed\"\"\"                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return await self.storage.load(output_id)                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def get_context_summary(self) -&gt; str:                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Return lightweight summary for context\"\"\"                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return \"\\n\".join([                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             f\"Tool: {ref['tool']}, ID: {id}, Summary: {ref['summary']}\"                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             for id, ref in self.output_refs.items()                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         ])                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Usage in Agent Loop:**                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # After tool execution                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tool_output = await execute_tool(tool_name, args)                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Store large output externally                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> output_id = await tool_manager.store_tool_output(tool_name, tool_output)                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Include only reference in context                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> context_message = f\"Tool {tool_name} executed. Output stored as {output_id}. Summary: {tool_output[:200]}...\"   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Agent can request full output if needed                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> if agent_needs_full_output:                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     full_output = await tool_manager.retrieve_tool_output(output_id)                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Trade-offs:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Dramatically reduces context consumption                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Enables agents to work with massive tool outputs                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Maintains access to full data when needed                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Adds complexity with external storage                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Requires careful management of references                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 6. Context Injection and Retrieval Strategies                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 6.1 Retrieval-Augmented Generation (RAG) Architecture                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> RAG enhances LLMs by incorporating real-time retrieval from external knowledge bases [4]:                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Core Components:**                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **Knowledge Store (Vector Database)**: Stores embeddings for semantic search                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **Application Layer**: Performs retrieval and integrates with LLM                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **LLM**: Generates responses using pre-trained knowledge + retrieved context                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **RAG Workflow** [4]:                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> User Query → Embedding → Vector Search → Retrieve Top-K Documents →                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Augment Prompt → LLM Generation → Response                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 6.2 Metadata-Enhanced Retrieval                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Metadata plays a crucial role in precise context retrieval [4]:                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Metadata Types:**                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **System Metadata**: Auto-generated (file names, dates, document IDs)                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **User-defined Metadata**: Custom attributes (categories, departments, authors)                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **Automatic Metadata**: AI-extracted structured data (titles, prices, entities)                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Pattern:**                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from llama_index.core import VectorStoreIndex, Document                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Create documents with rich metadata                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> documents = [                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     Document(                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         text=\"Q4 2024 revenue increased 25% year-over-year...\",                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         metadata={                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"document_type\": \"financial_report\",                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"quarter\": \"Q4\",                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"year\": 2024,                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"department\": \"finance\",                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"author\": \"CFO\",                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"date\": \"2024-01-15\"                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         }                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     ),                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # ... more documents                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ]                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Build index with metadata                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> index = VectorStoreIndex.from_documents(documents)                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Hybrid search: semantic + metadata filtering                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> filters = MetadataFilters(                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     filters=[                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         ExactMatchFilter(key=\"department\", value=\"finance\"),                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         ExactMatchFilter(key=\"year\", value=2024)                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     ]                                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> )                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> retriever = index.as_retriever(                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     similarity_top_k=5,                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     filters=filters                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> )                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> # Retrieve with both semantic similarity and metadata constraints                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> relevant_docs = retriever.retrieve(\"What was our Q4 revenue?\")                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Benefits** [4]:                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enhanced filtering for precise results                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Improved context relevance                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Better organization of large document collections                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Personalized responses based on user metadata                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Access control through metadata-based permissions                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 6.3 Dynamic Context Construction                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> AWS's Dynamic Context Construction technique focuses on **building context on-demand** rather than maintaining  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> large static contexts [1]:                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Key Principles:**                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **Just-in-time retrieval**: Fetch only what's needed for the current query                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **Relevance ranking**: Prioritize most relevant information                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **Context assembly**: Dynamically construct prompts from retrieved pieces                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 4. **Adaptive sizing**: Adjust context size based on query complexity                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Approach:**                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> class DynamicContextBuilder:                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def __init__(self, vector_store, max_context_tokens=8000):                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.vector_store = vector_store                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.max_tokens = max_context_tokens                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     async def build_context(self, query: str, metadata_filters: dict = None) -&gt; str:                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Dynamically construct context for query\"\"\"                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Retrieve relevant documents                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         results = await self.vector_store.similarity_search(                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             query=query,                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             k=20,  # Retrieve more than needed                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             filters=metadata_filters                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         )                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Rank by relevance score                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         ranked_results = sorted(results, key=lambda x: x.score, reverse=True)                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Build context within token budget                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         context_parts = []                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         current_tokens = 0                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         for doc in ranked_results:                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             doc_tokens = len(self.tokenizer.encode(doc.text))                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             if current_tokens + doc_tokens &lt;= self.max_tokens:                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 context_parts.append(doc.text)                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 current_tokens += doc_tokens                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             else:                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 # Try to fit a truncated version                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 remaining_tokens = self.max_tokens - current_tokens                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 if remaining_tokens &gt; 100:  # Minimum useful size                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                     truncated = self._truncate_to_tokens(doc.text, remaining_tokens)                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                     context_parts.append(truncated)                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 break                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return \"\\n\\n---\\n\\n\".join(context_parts)                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def _truncate_to_tokens(self, text: str, max_tokens: int) -&gt; str:                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Truncate text to fit token budget\"\"\"                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         tokens = self.tokenizer.encode(text)                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         if len(tokens) &lt;= max_tokens:                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             return text                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         truncated_tokens = tokens[:max_tokens]                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return self.tokenizer.decode(truncated_tokens) + \"...\"                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 6.4 Context Isolation with Sub-Agents                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> For complex workflows, spawn **dedicated sub-agents** for focused tasks [2]:                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Architecture:**                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Main Agent (Orchestrator)                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     ├── Sub-Agent 1: Dependency Analysis (isolated context)                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     ├── Sub-Agent 2: Code Generation (isolated context)                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     ├── Sub-Agent 3: Test Creation (isolated context)                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     └── Sub-Agent 4: Verification (isolated context)                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Implementation Pattern:**                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> class SubAgentOrchestrator:                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def __init__(self, main_llm):                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.main_llm = main_llm                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.sub_agents = {}                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     async def spawn_sub_agent(self, task_type: str, context: dict) -&gt; str:                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Create isolated sub-agent for specific task\"\"\"                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Create fresh context for sub-agent                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         sub_agent_prompt = self._build_sub_agent_prompt(task_type, context)                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Execute in isolation                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         result = await self.main_llm.acomplete(sub_agent_prompt)                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Return only summary to main agent                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         summary = self._summarize_result(result.text)                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return summary                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def _build_sub_agent_prompt(self, task_type: str, context: dict) -&gt; str:                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Build minimal, focused prompt for sub-agent\"\"\"                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         prompts = {                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"dependency_analysis\": \"\"\"                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 Analyze dependencies for the following code:                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 {code}                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 Return only: list of dependencies and their versions.                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"\"\",                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"code_generation\": \"\"\"                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 Generate code for: {specification}                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                 Return only: the code implementation.                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"\"\",                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             # ... more task-specific prompts                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         }                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return prompts.format(**context)                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def _summarize_result(self, result: str) -&gt; str:                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         \"\"\"Compress sub-agent output for main agent\"\"\"                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         # Return concise summary, not full output                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return f\"Task completed. Key findings: {result[:200]}...\"                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Benefits:**                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Isolates complexity, preventing cross-task context pollution                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Keeps each task's context window uncluttered                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Enables parallelization of independent subtasks                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Supports specialization (different prompts/models per task)                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Real-World Example**: Claude Code uses this pattern for complex refactoring [2]                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Trade-offs:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Clean context boundaries                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Scalable to arbitrary workflow complexity                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Prevents context pollution                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Requires careful orchestration logic                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Potential information loss between agent boundaries                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Added complexity in error handling                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 7. Production Best Practices and Trade-offs                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 7.1 Comprehensive Monitoring                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Key Metrics to Track** [2]:                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> class ContextMetrics:                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def __init__(self):                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.metrics = {                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"token_usage_per_interaction\": [],                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"peak_token_usage\": 0,                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"average_context_size\": 0,                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"pruning_operations\": 0,                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"summarization_operations\": 0,                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"cost_per_interaction\": [],                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"response_latency\": [],                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"context_overflow_events\": 0                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         }                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def record_interaction(self, tokens: int, cost: float, latency: float):                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.metrics[\"token_usage_per_interaction\"].append(tokens)                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.metrics[\"cost_per_interaction\"].append(cost)                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.metrics[\"response_latency\"].append(latency)                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         self.metrics[\"peak_token_usage\"] = max(self.metrics[\"peak_token_usage\"], tokens)                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     def get_summary(self) -&gt; dict:                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return {                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"avg_tokens\": np.mean(self.metrics[\"token_usage_per_interaction\"]),                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"peak_tokens\": self.metrics[\"peak_token_usage\"],                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"avg_cost\": np.mean(self.metrics[\"cost_per_interaction\"]),                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"avg_latency\": np.mean(self.metrics[\"response_latency\"]),                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             \"total_pruning_ops\": self.metrics[\"pruning_operations\"]                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         }                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 7.2 Graceful Degradation                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Never crash on context overflow** [2]:                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```python                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> async def handle_context_overflow(context: str, max_tokens: int) -&gt; str:                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     \"\"\"Gracefully handle context that exceeds limits\"\"\"                                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     current_tokens = count_tokens(context)                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     if current_tokens &lt;= max_tokens:                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return context                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # Strategy 1: Aggressive summarization                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     try:                                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         summarized = await aggressive_summarize(context, target_tokens=max_tokens * 0.7)                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         if count_tokens(summarized) &lt;= max_tokens:                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>             return summarized                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     except Exception as e:                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         logger.error(f\"Summarization failed: {e}\")                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # Strategy 2: Prune oldest content                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     try:                                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         pruned = prune_to_fit(context, max_tokens)                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         return pruned                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     except Exception as e:                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>         logger.error(f\"Pruning failed: {e}\")                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     # Strategy 3: Reset with summary                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     summary = \"Previous context exceeded limits and was reset. Summary: \" + context[:500]                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>     return summary                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ```                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 7.3 Combined Technique Strategy                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Production systems use ALL techniques in combination** [2]:                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | Technique | When to Use | Primary Benefit |                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> |-----------|-------------|-----------------|                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Pruning** | Routine cleanup, acknowledged messages | Immediate token reduction |                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Summarization** | Important information, phase boundaries | Preserves semantic content |                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Offloading** | Large tool outputs, datasets | Enables working with massive data |                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Atomic Tools** | System design phase | Reduces prompt overhead |                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Sub-agents** | Complex workflows, isolated tasks | Prevents context pollution |                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> | **Conservative Management** | Always | Maintains optimal performance |                                        <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 7.4 Performance Gains from Context Engineering                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Reported Improvements** [2]:                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **10x reduction** in token usage through pruning and summarization                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **50-70% latency improvement** from lean contexts                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Similar cost reductions** making previously impractical workflows viable                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - **Dramatic accuracy improvements** when models work within effective windows                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### 7.5 Framework-Specific Recommendations                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **LlamaIndex:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Use custom `MemoryBlock` implementations for specialized needs [3]                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Set `chat_history_token_ratio` very low (0.0001) to force aggressive flushing [3]                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Leverage async APIs for better performance [3]                                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **LangChain:**                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Start with `ConversationBufferMemory` for simple cases [5]                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Upgrade to custom memory classes for production [5]                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Use `initialize_agent` with memory parameter for automatic tracking [5]                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **General:**                                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Design for context engineering from day one, not as an afterthought [2]                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Test across minimal, moderate, and near-maximum context scenarios [2]                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Document context management decisions explicitly for maintainers [2]                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - A/B test different thresholds and strategies with real usage data [2]                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## 8. Architectural Decision Framework                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ### When to Use Each Technique                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Pruning:**                                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Use for: Routine cleanup, acknowledged messages, completed steps                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Avoid for: Critical information, unresolved issues, active tasks                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Best for: Immediate token reduction with minimal overhead                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Summarization:**                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Use for: Important historical context, phase transitions, long conversations                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Avoid for: Real-time critical data, precise technical specifications                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Best for: Preserving semantic meaning while reducing tokens                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Offloading:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Use for: Large tool outputs, datasets, document collections                                                <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Avoid for: Frequently accessed small data, real-time context                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Best for: Working with data beyond context window limits                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Sub-agents:**                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Use for: Complex workflows, logically isolated tasks, parallel operations                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Avoid for: Simple linear tasks, tightly coupled operations                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Best for: Preventing context pollution in complex systems                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **RAG/Retrieval:**                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ✅ Use for: Large knowledge bases, dynamic information, domain-specific data                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - ❌ Avoid for: Small static datasets, frequently changing context                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> - Best for: Augmenting LLM knowledge with external information                                                  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## Conclusion                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Context engineering has evolved from an optimization technique to a **fundamental requirement** for production  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> AI agents. The techniques covered in this report - from aggressive pruning and hierarchical summarization to    <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> atomic tools and sub-agent isolation - represent battle-tested patterns from leading AI companies and           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> frameworks.                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> **Key Takeaways:**                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 1. **Context rot is real**: Models degrade well before hitting technical token limits                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 2. **Conservative management wins**: Trigger interventions at 40-60% capacity, not 80-90%                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 3. **Combine multiple techniques**: Production systems use all six approaches strategically                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 4. **Design from day one**: Context engineering must be architectural, not an afterthought                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 5. **Monitor continuously**: Track tokens, costs, latency, and accuracy metrics                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 6. **Framework support exists**: LlamaIndex and LangChain provide robust primitives                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The difference between AI systems that work in demos and those that thrive in production lies in mastering      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> these context engineering disciplines. Teams that implement these techniques will build agents that are faster, <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> more accurate, more reliable, and more cost-effective.                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ---                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> ## Sources                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [1] AWS Builder Center - Context Engineering: The Dynamic Context Construction Technique for AI Agents          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://builder.aws.com/content/3064TwnFXzSYe6r2EpN6Ye2Q2u1/context-engineering-the-dynamic-context-constructio <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> n-technique-for-ai-agents                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [2] Medium - Context Engineering: The Invisible Discipline Keeping AI Agents from Drowning in Their Own Memory  <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> (Juan C Olamendy)                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowning <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> -in-their-own-memory-c0283ca6a954                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [3] LlamaIndex Documentation - Reducing Multi-Turn Confusion with LlamaIndex Memory                             <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://developers.llamaindex.ai/python/examples/memory/custom_multi_turn_memory/                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [4] Vectorize Documentation - What is Retrieval-Augmented Generation (RAG)?                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://docs.vectorize.io/welcome/core-concepts/retrieval-augmented-generation/                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> [5] Cohorte Blog - A Comprehensive Guide to Using Function Calling with LangChain                               <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> https://www.cohorte.co/blog/a-comprehensive-guide-to-using-function-calling-with-langchain                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Advanced Context Engineering Techniques for AI Agents: Implementation Guide                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## Executive Summary                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering has emerged as a critical discipline for building production-grade AI agents. As LLMs have  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m fixed context windows and suffer from performance degradation with long contexts (\"context rot\"), strategic     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m management of what information reaches the model determines system reliability, cost-efficiency, and accuracy.  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m This report synthesizes advanced implementation techniques, architectural patterns, and practical strategies    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from leading AI frameworks and production systems.                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 1. Context Window Management and Optimization                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 1.1 Understanding Context Limitations                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Modern LLMs advertise large context windows (up to 1 million tokens), but research shows that **effective       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m performance occurs within much smaller windows** - typically the first 50,000-100,000 tokens [2]. Beyond this   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m threshold, models experience:                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Context rot**: Degraded accuracy and instruction-following capability                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Lost in the middle phenomenon**: Information buried mid-context gets overlooked                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Increased latency**: Processing 500,000 tokens takes significantly longer than 5,000 tokens                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Higher costs**: Every token incurs inference costs that compound with repeated processing                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 1.2 Conservative Context Management Strategy                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Approach:**                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **Set aggressive thresholds**: Trigger context management at 40-60% of maximum window, not 80-90% [2]        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **Start fresh frequently**: Reset context after completing major tasks rather than accumulating indefinitely \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **Strategic positioning**: Place critical instructions at the beginning and end of prompts where models pay  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m most attention [2]                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 4. **Query-aware contextualization**: Dynamically adjust included context based on the specific task, not       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m comprehensive history [2]                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Code Pattern (Threshold Monitoring):**                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m def should_trigger_context_management(current_tokens, max_tokens):                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     \"\"\"Trigger at 50% to maintain optimal performance\"\"\"                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     threshold = max_tokens * 0.5                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     return current_tokens >= threshold                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Monitor in real-time                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m if should_trigger_context_management(token_count, context_window_size):                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # Trigger summarization or pruning                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     await compress_context()                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Trade-offs:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Maintains optimal model performance                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Reduces costs and latency                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Requires more frequent context management operations                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ May lose some historical detail                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 2. Long-Term Memory and State Management                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 2.1 Multi-Tier Memory Architecture                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Production systems implement **hierarchical memory** with distinct short-term and long-term storage [2][3]:     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Architecture Components:**                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **Short-term memory (Active Context)**: Recent messages and current task context                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **Long-term memory (External Storage)**: Compressed historical information, facts, decisions                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **Working memory (External Databases)**: Tool outputs, intermediate results, large datasets                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 2.2 LlamaIndex Custom Memory Implementation                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m LlamaIndex provides a sophisticated approach to managing multi-turn conversations with custom memory blocks     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [3]:                                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Pattern:**                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m import tiktoken                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from llama_index.core.memory import Memory, BaseMemoryBlock                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from llama_index.core.llms import ChatMessage, TextBlock                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m class CondensedMemoryBlock(BaseMemoryBlock):                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     \"\"\"Custom memory block that condenses past messages while maintaining token limits\"\"\"                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     current_memory: List = Field(default_factory=list)                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     token_limit: int = Field(default=50000)                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     tokenizer: tiktoken.Encoding = tiktoken.encoding_for_model(\"gpt-4o\")                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     async def _aget(self, messages: Optional[List[ChatMessage]] = None, **kwargs) -> str:                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Return condensed memory as a single string\"\"\"                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return \"\\n\".join(self.current_memory)                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     async def _aput(self, messages: List[ChatMessage]) -> None:                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Push messages and maintain token limit\"\"\"                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         for message in messages:                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             text_contents = \"\\n\".join(                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 block.text for block in message.blocks                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 if isinstance(block, TextBlock)                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             )                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             memory_str = f\"<message role={message.role}>\\n{text_contents}\\n</message>\"                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             self.current_memory.append(memory_str)                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Enforce token limit by removing oldest messages                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         message_length = sum(                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             len(self.tokenizer.encode(msg)) for msg in self.current_memory                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         )                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         while message_length > self.token_limit:                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             self.current_memory = self.current_memory[1:]                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             message_length = sum(                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 len(self.tokenizer.encode(msg)) for msg in self.current_memory                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             )                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Configure memory with aggressive short-term limits                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m memory = Memory.from_defaults(                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     session_id=\"user-session-01\",                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     token_limit=60000,                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     token_flush_size=5000,                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     memory_blocks=[CondensedMemoryBlock(name=\"condensed_memory\")],                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # Force short-term memory to always flush to long-term                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     chat_history_token_ratio=0.0001,                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m )                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Key Features:**                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Automatic token counting and enforcement                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Configurable flush thresholds                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Seamless integration with agent workflows                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Prevents multi-turn confusion by limiting active context [3]                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 2.3 LangChain Conversational Memory                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m LangChain offers built-in memory management for maintaining conversation context [5]:                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from langchain.memory import ConversationBufferMemory                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Initialize memory for context retention                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m memory = ConversationBufferMemory(memory_key=\"chat_history\")                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Integrate with agent                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m agent = initialize_agent(                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     tools,                                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     llm,                                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     agent=\"zero-shot-react-description\",                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     memory=memory,                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     verbose=True                                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m )                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Memory automatically tracks conversation history                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m response = agent.run(\"What is the weather in Paris?\")                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m response = agent.run(\"Can you remind me what I just asked?\")                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Output: \"You just asked about the weather in Paris.\"                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Trade-offs:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Simple integration with minimal code                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Automatic context tracking                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Basic buffer approach may not scale to long conversations                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Requires additional compression strategies for production use                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 3. Context Compression and Summarization Techniques                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 3.1 Hierarchical Summarization                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Strategy** [2]:                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **Break context into logical chunks** (by task phase, time period, or topic)                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **Summarize each chunk independently** using the LLM itself                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **Optionally summarize the summaries** for deeply nested workflows                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 4. **Replace verbose content with compressed summaries** in subsequent prompts                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Trigger Points:**                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - When context reaches 50% of available window                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - At natural workflow boundaries (task completion, phase transitions)                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Before starting new major tasks                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Summarization Prompt Pattern:**                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m async def summarize_context(messages: List[ChatMessage], llm) -> str:                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     \"\"\"Use LLM to compress conversation history\"\"\"                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     summarization_prompt = \"\"\"                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     Summarize the following conversation, preserving:                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     - Key facts and decisions made                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     - Open tasks and unresolved issues                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     - Important context for ongoing work                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     Exclude:                                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     - Casual conversation and confirmations                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     - Intermediate steps that led to decisions                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     - Information already acted upon                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     Conversation:                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     {conversation}                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     Provide a concise summary:                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     \"\"\"                                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     conversation_text = \"\\n\".join([                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         f\"{msg.role}: {msg.content}\" for msg in messages                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     ])                                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     summary = await llm.acomplete(                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         summarization_prompt.format(conversation=conversation_text)                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     )                                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     return summary.text                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 3.2 Rolling Summarization                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Pattern**: Summaries themselves get updated and re-compressed over time [2]                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m class RollingSummarizer:                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def __init__(self, max_summary_tokens=5000):                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.current_summary = \"\"                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.max_tokens = max_summary_tokens                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     async def update_summary(self, new_messages: List[ChatMessage], llm):                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Append new information to existing summary\"\"\"                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # If summary is getting too large, re-compress it                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         if len(self.tokenizer.encode(self.current_summary)) > self.max_tokens:                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             self.current_summary = await self._recompress_summary(llm)                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Append new information                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         new_content = \"\\n\".join()                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         update_prompt = f\"\"\"                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         Current summary: {self.current_summary}                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         New information: {new_content}                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         Update the summary to incorporate the new information while maintaining conciseness.                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.current_summary = await llm.acomplete(update_prompt)                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return self.current_summary                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Trade-offs:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Enables indefinite conversation length with bounded context                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Maintains semantic relevance over time                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Potential information loss in compression                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Computational overhead for summarization operations                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Requires careful tuning of what to preserve                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 4. Multi-Turn Conversation Context Handling                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 4.1 The Multi-Turn Confusion Problem                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Recent research shows LLM performance significantly degrades in multi-turn conversations [3]. Without proper    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m management, agents accumulate hundreds of thousands of tokens after just several rounds of tool calls.          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 4.2 Solution: Aggressive Context Flushing                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **LlamaIndex Pattern** [3]:                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Configure memory to prevent multi-turn accumulation                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m memory = Memory.from_defaults(                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     session_id=\"session-id\",                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     token_limit=60000,                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     token_flush_size=5000,                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     memory_blocks=,                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     insert_method=\"user\",                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # Critical: Set extremely low ratio to force immediate flushing                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     chat_history_token_ratio=0.0001,  # Effectively 0                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m )                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Result: Short-term memory always contains minimal turns                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # All history is condensed into long-term memory block                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Output Structure:**                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m MessageRole.USER                                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m <memory>                                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   <condensed_memory>                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     <message role=MessageRole.USER>                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m       Hello! My name is Logan                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     </message>                                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     <message role=MessageRole.ASSISTANT>                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m       Hello! How can I help you?                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     </message>                                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     ...                                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m   </condensed_memory>                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m </memory>                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m What was my name again?                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 4.3 Context Injection Pattern                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The condensed memory is injected as a **single user message** containing all historical context, followed by    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m the current query [3]. This ensures:                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. The LLM sees complete history without token bloat                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. Recent context remains immediately accessible                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. Multi-turn confusion is eliminated                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Trade-offs:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Prevents context rot from long conversations                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Maintains coherence across extended sessions                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Reduces token costs dramatically                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Requires careful design of memory block structure                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ May lose fine-grained conversational nuance                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 5. Tool Use and Function Calling Context Patterns                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 5.1 The Atomic Tools Pattern                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Rather than binding many specialized tools (which bloats system prompts), provide **few general-purpose tools** \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m with clear, narrow scopes [2]:                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Design Principles:**                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Single responsibility**: Each tool does one thing well (Unix philosophy)                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Minimal ambiguity**: Clear input schemas and predictable outputs                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Composability**: Tools can be chained together                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Reduced prompt overhead**: Fewer tool descriptions in system prompt                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Example Implementation:**                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # ❌ BAD: Specialized, bloated tools                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools = [                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     analyze_and_fix_code_tool,                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     read_and_transform_data_tool,                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     search_and_summarize_tool,                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # ... 20+ more specialized tools                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ]                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # ✅ GOOD: Atomic, composable tools                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools = [                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     read_file_tool,      # Just reads files                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     write_file_tool,     # Just writes files                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     bash_tool,           # Executes shell commands                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     web_search_tool,     # Searches the web                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ]                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Real-World Examples:**                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Replit, Cursor, LangChain agents use highly atomic tool definitions [2]                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Instead of \"analyze_and_fix_code\", they provide separate \"read_file\", \"analyze_code\", \"write_file\" tools that \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m agents chain together                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 5.2 LangChain Function Calling Implementation                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Tool Definition Pattern** [5]:                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from langchain.tools import Tool                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Define atomic function                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m def get_weather(city: str) -> str:                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     \"\"\"Fetches weather information for a given city.\"\"\"                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     response = requests.get(f\"https://api.weatherapi.com/v1/current.json?key={api_key}&q={city}\")               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     data = response.json()                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     return f\"Weather in {city}: {data['current']['condition']['text']}, {data['current']['temp_c']}°C\"          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Wrap as tool with clear description                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m weather_tool = Tool(                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     name=\"get_weather\",                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     func=get_weather,                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     description=\"Fetches weather information for a given city.\"                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m )                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Initialize agent with tools                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from langchain.agents import initialize_agent                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from langchain.chat_models import ChatOpenAI                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m llm = ChatOpenAI(temperature=0)                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools =                                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m agent = initialize_agent(                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     tools,                                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     llm,                                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     agent=\"zero-shot-react-description\",                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     verbose=True                                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m )                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 5.3 Managing Tool Call Context                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Challenge**: Tool outputs can be massive and quickly fill context windows [2]                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Solution: Offloading Pattern**                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m class ToolOutputManager:                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def __init__(self, storage_backend):                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.storage = storage_backend                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.output_refs = {}                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     async def store_tool_output(self, tool_name: str, output: str) -> str:                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Store large tool output externally, return reference ID\"\"\"                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         output_id = f\"{tool_name}_{uuid.uuid4()}\"                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         await self.storage.save(output_id, output)                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.output_refs = {                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"tool\": tool_name,                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"summary\": output[:200] + \"...\" if len(output) > 200 else output,                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"size\": len(output)                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         }                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return output_id                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     async def retrieve_tool_output(self, output_id: str) -> str:                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Retrieve full output when needed\"\"\"                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return await self.storage.load(output_id)                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def get_context_summary(self) -> str:                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Return lightweight summary for context\"\"\"                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return \"\\n\".join([                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             f\"Tool: {ref['tool']}, ID: {id}, Summary: {ref['summary']}\"                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             for id, ref in self.output_refs.items()                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         ])                                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Usage in Agent Loop:**                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # After tool execution                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tool_output = await execute_tool(tool_name, args)                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Store large output externally                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m output_id = await tool_manager.store_tool_output(tool_name, tool_output)                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Include only reference in context                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m context_message = f\"Tool {tool_name} executed. Output stored as {output_id}. Summary: {tool_output[:200]}...\"   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Agent can request full output if needed                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m if agent_needs_full_output:                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     full_output = await tool_manager.retrieve_tool_output(output_id)                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Trade-offs:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Dramatically reduces context consumption                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Enables agents to work with massive tool outputs                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Maintains access to full data when needed                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Adds complexity with external storage                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Requires careful management of references                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 6. Context Injection and Retrieval Strategies                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 6.1 Retrieval-Augmented Generation (RAG) Architecture                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m RAG enhances LLMs by incorporating real-time retrieval from external knowledge bases [4]:                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Core Components:**                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **Knowledge Store (Vector Database)**: Stores embeddings for semantic search                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **Application Layer**: Performs retrieval and integrates with LLM                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **LLM**: Generates responses using pre-trained knowledge + retrieved context                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **RAG Workflow** [4]:                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m User Query → Embedding → Vector Search → Retrieve Top-K Documents →                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Augment Prompt → LLM Generation → Response                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 6.2 Metadata-Enhanced Retrieval                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Metadata plays a crucial role in precise context retrieval [4]:                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Metadata Types:**                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **System Metadata**: Auto-generated (file names, dates, document IDs)                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **User-defined Metadata**: Custom attributes (categories, departments, authors)                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **Automatic Metadata**: AI-extracted structured data (titles, prices, entities)                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Pattern:**                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from llama_index.core import VectorStoreIndex, Document                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Create documents with rich metadata                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m documents = [                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     Document(                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         text=\"Q4 2024 revenue increased 25% year-over-year...\",                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         metadata={                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"document_type\": \"financial_report\",                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"quarter\": \"Q4\",                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"year\": 2024,                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"department\": \"finance\",                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"author\": \"CFO\",                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"date\": \"2024-01-15\"                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         }                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     ),                                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # ... more documents                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ]                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Build index with metadata                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m index = VectorStoreIndex.from_documents(documents)                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Hybrid search: semantic + metadata filtering                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m filters = MetadataFilters(                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     filters=[                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         ExactMatchFilter(key=\"department\", value=\"finance\"),                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         ExactMatchFilter(key=\"year\", value=2024)                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     ]                                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m )                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m retriever = index.as_retriever(                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     similarity_top_k=5,                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     filters=filters                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m )                                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m # Retrieve with both semantic similarity and metadata constraints                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m relevant_docs = retriever.retrieve(\"What was our Q4 revenue?\")                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Benefits** [4]:                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enhanced filtering for precise results                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Improved context relevance                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Better organization of large document collections                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Personalized responses based on user metadata                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Access control through metadata-based permissions                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 6.3 Dynamic Context Construction                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m AWS's Dynamic Context Construction technique focuses on **building context on-demand** rather than maintaining  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m large static contexts [1]:                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Key Principles:**                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **Just-in-time retrieval**: Fetch only what's needed for the current query                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **Relevance ranking**: Prioritize most relevant information                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **Context assembly**: Dynamically construct prompts from retrieved pieces                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 4. **Adaptive sizing**: Adjust context size based on query complexity                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Approach:**                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m class DynamicContextBuilder:                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def __init__(self, vector_store, max_context_tokens=8000):                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.vector_store = vector_store                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.max_tokens = max_context_tokens                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     async def build_context(self, query: str, metadata_filters: dict = None) -> str:                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Dynamically construct context for query\"\"\"                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Retrieve relevant documents                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         results = await self.vector_store.similarity_search(                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             query=query,                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             k=20,  # Retrieve more than needed                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             filters=metadata_filters                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         )                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Rank by relevance score                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         ranked_results = sorted(results, key=lambda x: x.score, reverse=True)                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Build context within token budget                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         context_parts = []                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         current_tokens = 0                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         for doc in ranked_results:                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             doc_tokens = len(self.tokenizer.encode(doc.text))                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             if current_tokens + doc_tokens <= self.max_tokens:                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 context_parts.append(doc.text)                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 current_tokens += doc_tokens                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             else:                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 # Try to fit a truncated version                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 remaining_tokens = self.max_tokens - current_tokens                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 if remaining_tokens > 100:  # Minimum useful size                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                     truncated = self._truncate_to_tokens(doc.text, remaining_tokens)                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                     context_parts.append(truncated)                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 break                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return \"\\n\\n---\\n\\n\".join(context_parts)                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def _truncate_to_tokens(self, text: str, max_tokens: int) -> str:                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Truncate text to fit token budget\"\"\"                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         tokens = self.tokenizer.encode(text)                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         if len(tokens) <= max_tokens:                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             return text                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         truncated_tokens = tokens[:max_tokens]                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return self.tokenizer.decode(truncated_tokens) + \"...\"                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 6.4 Context Isolation with Sub-Agents                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m For complex workflows, spawn **dedicated sub-agents** for focused tasks [2]:                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Architecture:**                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Main Agent (Orchestrator)                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     ├── Sub-Agent 1: Dependency Analysis (isolated context)                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     ├── Sub-Agent 2: Code Generation (isolated context)                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     ├── Sub-Agent 3: Test Creation (isolated context)                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     └── Sub-Agent 4: Verification (isolated context)                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Implementation Pattern:**                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m class SubAgentOrchestrator:                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def __init__(self, main_llm):                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.main_llm = main_llm                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.sub_agents = {}                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     async def spawn_sub_agent(self, task_type: str, context: dict) -> str:                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Create isolated sub-agent for specific task\"\"\"                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Create fresh context for sub-agent                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         sub_agent_prompt = self._build_sub_agent_prompt(task_type, context)                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Execute in isolation                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         result = await self.main_llm.acomplete(sub_agent_prompt)                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Return only summary to main agent                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         summary = self._summarize_result(result.text)                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return summary                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def _build_sub_agent_prompt(self, task_type: str, context: dict) -> str:                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Build minimal, focused prompt for sub-agent\"\"\"                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         prompts = {                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"dependency_analysis\": \"\"\"                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 Analyze dependencies for the following code:                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 {code}                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 Return only: list of dependencies and their versions.                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"\"\",                                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"code_generation\": \"\"\"                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 Generate code for: {specification}                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                 Return only: the code implementation.                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"\"\",                                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             # ... more task-specific prompts                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         }                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return prompts.format(**context)                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def _summarize_result(self, result: str) -> str:                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         \"\"\"Compress sub-agent output for main agent\"\"\"                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         # Return concise summary, not full output                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return f\"Task completed. Key findings: {result[:200]}...\"                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Benefits:**                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Isolates complexity, preventing cross-task context pollution                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Keeps each task's context window uncluttered                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Enables parallelization of independent subtasks                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Supports specialization (different prompts/models per task)                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Real-World Example**: Claude Code uses this pattern for complex refactoring [2]                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Trade-offs:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Clean context boundaries                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Scalable to arbitrary workflow complexity                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Prevents context pollution                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Requires careful orchestration logic                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Potential information loss between agent boundaries                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Added complexity in error handling                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 7. Production Best Practices and Trade-offs                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 7.1 Comprehensive Monitoring                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Key Metrics to Track** [2]:                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m class ContextMetrics:                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def __init__(self):                                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.metrics = {                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"token_usage_per_interaction\": [],                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"peak_token_usage\": 0,                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"average_context_size\": 0,                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"pruning_operations\": 0,                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"summarization_operations\": 0,                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"cost_per_interaction\": [],                                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"response_latency\": [],                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"context_overflow_events\": 0                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         }                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def record_interaction(self, tokens: int, cost: float, latency: float):                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.metrics[\"token_usage_per_interaction\"].append(tokens)                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.metrics[\"cost_per_interaction\"].append(cost)                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.metrics[\"response_latency\"].append(latency)                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         self.metrics[\"peak_token_usage\"] = max(self.metrics[\"peak_token_usage\"], tokens)                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     def get_summary(self) -> dict:                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return {                                                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"avg_tokens\": np.mean(self.metrics[\"token_usage_per_interaction\"]),                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"peak_tokens\": self.metrics[\"peak_token_usage\"],                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"avg_cost\": np.mean(self.metrics[\"cost_per_interaction\"]),                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"avg_latency\": np.mean(self.metrics[\"response_latency\"]),                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             \"total_pruning_ops\": self.metrics[\"pruning_operations\"]                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         }                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 7.2 Graceful Degradation                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Never crash on context overflow** [2]:                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```python                                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m async def handle_context_overflow(context: str, max_tokens: int) -> str:                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     \"\"\"Gracefully handle context that exceeds limits\"\"\"                                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     current_tokens = count_tokens(context)                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     if current_tokens <= max_tokens:                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return context                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # Strategy 1: Aggressive summarization                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     try:                                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         summarized = await aggressive_summarize(context, target_tokens=max_tokens * 0.7)                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         if count_tokens(summarized) <= max_tokens:                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m             return summarized                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     except Exception as e:                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         logger.error(f\"Summarization failed: {e}\")                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # Strategy 2: Prune oldest content                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     try:                                                                                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         pruned = prune_to_fit(context, max_tokens)                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         return pruned                                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     except Exception as e:                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m         logger.error(f\"Pruning failed: {e}\")                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     # Strategy 3: Reset with summary                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     summary = \"Previous context exceeded limits and was reset. Summary: \" + context[:500]                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m     return summary                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ```                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 7.3 Combined Technique Strategy                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Production systems use ALL techniques in combination** [2]:                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | Technique | When to Use | Primary Benefit |                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m |-----------|-------------|-----------------|                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Pruning** | Routine cleanup, acknowledged messages | Immediate token reduction |                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Summarization** | Important information, phase boundaries | Preserves semantic content |                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Offloading** | Large tool outputs, datasets | Enables working with massive data |                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Atomic Tools** | System design phase | Reduces prompt overhead |                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Sub-agents** | Complex workflows, isolated tasks | Prevents context pollution |                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m | **Conservative Management** | Always | Maintains optimal performance |                                        \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 7.4 Performance Gains from Context Engineering                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Reported Improvements** [2]:                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **10x reduction** in token usage through pruning and summarization                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **50-70% latency improvement** from lean contexts                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Similar cost reductions** making previously impractical workflows viable                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - **Dramatic accuracy improvements** when models work within effective windows                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### 7.5 Framework-Specific Recommendations                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **LlamaIndex:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Use custom `MemoryBlock` implementations for specialized needs [3]                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Set `chat_history_token_ratio` very low (0.0001) to force aggressive flushing [3]                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Leverage async APIs for better performance [3]                                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **LangChain:**                                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Start with `ConversationBufferMemory` for simple cases [5]                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Upgrade to custom memory classes for production [5]                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Use `initialize_agent` with memory parameter for automatic tracking [5]                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **General:**                                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Design for context engineering from day one, not as an afterthought [2]                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Test across minimal, moderate, and near-maximum context scenarios [2]                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Document context management decisions explicitly for maintainers [2]                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - A/B test different thresholds and strategies with real usage data [2]                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## 8. Architectural Decision Framework                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ### When to Use Each Technique                                                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Pruning:**                                                                                                    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Use for: Routine cleanup, acknowledged messages, completed steps                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Avoid for: Critical information, unresolved issues, active tasks                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Best for: Immediate token reduction with minimal overhead                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Summarization:**                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Use for: Important historical context, phase transitions, long conversations                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Avoid for: Real-time critical data, precise technical specifications                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Best for: Preserving semantic meaning while reducing tokens                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Offloading:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Use for: Large tool outputs, datasets, document collections                                                \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Avoid for: Frequently accessed small data, real-time context                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Best for: Working with data beyond context window limits                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Sub-agents:**                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Use for: Complex workflows, logically isolated tasks, parallel operations                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Avoid for: Simple linear tasks, tightly coupled operations                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Best for: Preventing context pollution in complex systems                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **RAG/Retrieval:**                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ✅ Use for: Large knowledge bases, dynamic information, domain-specific data                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - ❌ Avoid for: Small static datasets, frequently changing context                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m - Best for: Augmenting LLM knowledge with external information                                                  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## Conclusion                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m Context engineering has evolved from an optimization technique to a **fundamental requirement** for production  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m AI agents. The techniques covered in this report - from aggressive pruning and hierarchical summarization to    \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m atomic tools and sub-agent isolation - represent battle-tested patterns from leading AI companies and           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m frameworks.                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m **Key Takeaways:**                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 1. **Context rot is real**: Models degrade well before hitting technical token limits                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 2. **Conservative management wins**: Trigger interventions at 40-60% capacity, not 80-90%                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 3. **Combine multiple techniques**: Production systems use all six approaches strategically                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 4. **Design from day one**: Context engineering must be architectural, not an afterthought                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 5. **Monitor continuously**: Track tokens, costs, latency, and accuracy metrics                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 6. **Framework support exists**: LlamaIndex and LangChain provide robust primitives                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m The difference between AI systems that work in demos and those that thrive in production lies in mastering      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m these context engineering disciplines. Teams that implement these techniques will build agents that are faster, \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m more accurate, more reliable, and more cost-effective.                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ---                                                                                                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m ## Sources                                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [1] AWS Builder Center - Context Engineering: The Dynamic Context Construction Technique for AI Agents          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://builder.aws.com/content/3064TwnFXzSYe6r2EpN6Ye2Q2u1/context-engineering-the-dynamic-context-constructio \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m n-technique-for-ai-agents                                                                                       \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [2] Medium - Context Engineering: The Invisible Discipline Keeping AI Agents from Drowning in Their Own Memory  \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m (Juan C Olamendy)                                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowning \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m -in-their-own-memory-c0283ca6a954                                                                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [3] LlamaIndex Documentation - Reducing Multi-Turn Confusion with LlamaIndex Memory                             \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://developers.llamaindex.ai/python/examples/memory/custom_multi_turn_memory/                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [4] Vectorize Documentation - What is Retrieval-Augmented Generation (RAG)?                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://docs.vectorize.io/welcome/core-concepts/retrieval-augmented-generation/                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m                                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m [5] Cohorte Blog - A Comprehensive Guide to Using Function Calling with LangChain                               \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m https://www.cohorte.co/blog/a-comprehensive-guide-to-using-function-calling-with-langchain                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_todos                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"todos\": [                                                                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research specific techniques and implementation methods\",                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Write comprehensive final report to /final_report.md\",                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"in_progress\"                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Verify report addresses all aspects of the original request\",                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"pending\"                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     }                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   ]                                                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01PLHiBjqThtMiawx2MA31Cb                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_todos                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"todos\": [                                                                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research specific techniques and implementation methods\",                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Write comprehensive final report to /final_report.md\",                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"in_progress\"                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Verify report addresses all aspects of the original request\",                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"pending\"                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     }                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   ]                                                                                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_01PLHiBjqThtMiawx2MA31Cb                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> agents', 'status': 'completed'}, {'content': 'Research specific techniques and implementation methods',         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'status': 'completed'}, {'content': 'Write comprehensive final report to /final_report.md', 'status':           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'in_progress'}, {'content': 'Verify report addresses all aspects of the original request', 'status':            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'pending'}]                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m agents', 'status': 'completed'}, {'content': 'Research specific techniques and implementation methods',         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'status': 'completed'}, {'content': 'Write comprehensive final report to /final_report.md', 'status':           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'in_progress'}, {'content': 'Verify report addresses all aspects of the original request', 'status':            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'pending'}]                                                                                                     \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Now let me compile the comprehensive research into a final report.                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_file                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"/final_report.md\",                                                                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"content\": \"# Context Engineering Approaches for Building AI Agents\\n\\n## Overview\\n\\nContext engineering has <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> emerged as a critical discipline in AI agent development, representing the strategic management, curation, and  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> control of information provided to large language models (LLMs). As Andrej Karpathy describes it, context       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> engineering is \\\"the delicate art and science of filling the context window with just the right information for <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> the next step\\\" [1]. This discipline has evolved from simple prompt engineering to sophisticated system         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> architecture that determines whether AI agents succeed or fail in production environments.\\n\\nContext           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> engineering directly impacts three fundamental aspects of AI systems: performance and reliability, cost         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> efficiency, and user experience [1][2]. Research shows that models perform optimally only in the first          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 50,000-100,000 tokens, even with million-token context windows, making strategic context management essential   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> rather than optional [2]. As one researcher noted, \\\"Most agent failures are context failures\\\" - the system    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> didn't provide adequate information for success [1].\\n\\n## What is Context Engineering?\\n\\nContext engineering  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> is the discipline of strategically managing, curating, and controlling the information provided to large        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> language models [1][2]. It represents an evolution from prompt engineering, which focuses on crafting           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> instructions, to context engineering, which focuses on architecting the entire information pipeline before the  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> LLM call.\\n\\nWhile prompt engineering concentrated on writing clever, concise instructions for simple tasks,    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context engineering treats the entire pipeline as engineerable infrastructure [1]. This includes dynamic        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information gathering through RAG systems and API calls, memory management for both short-term conversation     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> state and long-term knowledge, tool coordination to make external functions available when needed, and output   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> structuring to define schemas and formats for consistent results.\\n\\nEarly AI development relied heavily on     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> prompting methods like chain-of-thought, ReAct, and self-consistency for complex tasks [1]. However, as         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> applications evolved into AI agents with multi-step reasoning, long-running conversations, and dynamic          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information retrieval, these approaches hit significant limitations. Context engineering emerged as the         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> solution to handle multi-step reasoning requiring tool use, long-running conversations with memory, dynamic     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information retrieval from databases, and coordination between multiple AI systems.\\n\\n## Why Context           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Engineering Matters\\n\\nContext engineering has become essential because poor context management creates         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> \\\"context rot\\\" where model quality degrades well before hitting technical token limits [2]. Models experience  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> performance degradation, increased latency, and higher costs as context windows fill up. Processing 500,000     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> tokens takes significantly longer than 5,000 tokens, and every token sent to an LLM incurs inference costs that <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> compound with repeated processing.\\n\\nProduction systems without context engineering quickly become             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> cost-prohibitive at scale. Naive approaches that append all tool results can generate hundreds of thousands of  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> tokens after just several rounds [2]. Teams implementing proper context engineering report substantial          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> improvements: 10x reduction in token usage through pruning and summarization alone, 50-70% latency improvements <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> from keeping contexts lean and focused, similar magnitude cost reductions making previously impractical         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> workflows viable, and dramatic accuracy and reliability improvements when models work within effective context  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> windows [2].\\n\\nPoor context management creates four major failure modes [1]: context poisoning where           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> hallucinations contaminate future responses, context distraction where too much information overwhelms the      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> model, context confusion where conflicting information causes errors, and context clash where disagreeing       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> sources lead to inconsistent outputs.\\n\\n## Types of Context in AI Agents\\n\\nModern AI agents require multiple  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context types working together [1][3]. Static context includes prompts with core behavior rules and examples,   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> tool definitions specifying available functions and their parameters, output schemas defining response format   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> requirements, and configuration files containing project-specific instructions like AGENTS.md or CLAUDE.md      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> files.\\n\\nDynamic context encompasses user input representing the immediate task or question, chat history      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> providing short-term conversation memory, long-term memory storing persistent preferences and past learnings,   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> retrieved knowledge from RAG results from databases or APIs, tool responses providing feedback from executed    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> functions, and workflow state containing information stored across agent steps.\\n\\nResearch on open-source      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> projects found that AI configuration files commonly include coding conventions (50 instances), contribution     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> guidelines (48), architecture descriptions (47), build commands (40), and testing instructions (32) [3]. These  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> configuration files use different writing styles: descriptive (\\\"This project uses the Linux Kernel Style       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Guideline\\\"), prescriptive (\\\"Use factories for all test data\\\"), prohibitive (\\\"Never commit directly to the   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> main branch\\\"), explanatory (\\\"Avoid hard-coded waits to prevent timing issues\\\"), and conditional (\\\"If you    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> need to use reflection, use ReflectionUtils APIs\\\") [3].\\n\\n## Core Context Engineering Strategies\\n\\n###       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Strategy 1: Writing Context (Memory Management)\\n\\nWriting context involves saving information outside the      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context window to preserve valuable token space [1]. This strategy enables two key capabilities: scratchpads    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> for temporary note-taking within a single session, and long-term memories for information retained across       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> multiple sessions.\\n\\nScratchpads provide temporary storage during agent execution. Anthropic's multi-agent     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> researcher saves initial plans to \\\"Memory\\\" to prevent loss when context exceeds 200,000 tokens [1].           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Implementation options include file-based tools or runtime state objects that persist during a session but      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> don't carry over to future interactions.\\n\\nLong-term memories enable personalization and create evolving       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> experiences that improve over time. ChatGPT auto-generates user preferences from conversations, while Cursor    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and Windsurf learn coding patterns and project context [1]. Reflexion agents create self-generated memories     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> from task feedback, allowing them to improve performance on subsequent attempts.\\n\\n### Strategy 2: Selecting   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Context (Intelligent Retrieval)\\n\\nSelecting context means pulling only relevant information into the context   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> window [1][4]. This strategy provides fine-grained control over what information gets exposed to the LLM,       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> enabling selective exposure of specific parts from scratchpads or state objects to reduce noise and improve     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> decision-making.\\n\\nMemory selection operates across three types: episodic memories containing few-shot         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> examples showing desired behavior, procedural memories storing instructions in configuration files, and         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> semantic memories holding facts relevant to current context through embeddings and RAG [1].\\n\\nAgentic RAG      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> applies retrieval-augmented generation to tool descriptions themselves. Too many tools create \\\"model           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> confusion\\\" about which to use, but RAG-based tool selection improves accuracy by 3-fold according to recent    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> research [1]. This approach dynamically selects which tools to expose based on the current task, rather than    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> overwhelming the model with dozens of tool descriptions.\\n\\n### Strategy 3: Compressing Context                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> (Optimization)\\n\\nCompressing context retains only tokens required to perform a task [1][2]. This strategy      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> employs two primary techniques: context summarization and context trimming.\\n\\nContext summarization condenses  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information while preserving essential details. Claude Code's \\\"auto-compact\\\" feature summarizes when context  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> exceeds 95% capacity [1]. Summarization applies at multiple levels: full trajectory summarization,              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> summarization at specific points during execution, and summarization at agent boundaries in multi-agent         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> systems. Some companies use fine-tuned models specifically for summarization to ensure consistent               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> quality.\\n\\nContext trimming uses filtering or \\\"pruning\\\" approaches to remove content. Hard-coded heuristics  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> might remove older messages from lists, while learned approaches employ trained context pruners for specific    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> domains [1]. Trimming offers immediate, predictable context reduction without the computational overhead of     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> summarization, though it risks losing potentially valuable information.\\n\\n### Strategy 4: Isolating Context    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> (Structural Separation)\\n\\nIsolating context splits it across different components to reduce cognitive load     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [1][2]. This strategy manifests in two primary patterns: multi-agent architectures and                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> sandboxes.\\n\\nMulti-agent architectures split context across sub-agents, each with their own context windows,   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> tools, and instructions. This enables separation of concerns for specialized subtasks, expands total token      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> capacity across the system, and prevents context pollution between different workflow phases [1]. The challenge <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> is that multi-agent systems can increase costs up to 15x more tokens than single-agent systems without proper   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> management [1].\\n\\nSandboxes and execution environments isolate code execution from the LLM's context window.   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> They persist state across multiple responses and excel at handling token-heavy objects like images and audio    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> files [1]. Only selective results are passed back to the LLM, keeping the context window focused on high-level  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> reasoning rather than detailed execution artifacts.\\n\\n## Six Core Context Engineering Techniques\\n\\n###        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Technique 1: Pruning\\n\\nPruning systematically removes older, less relevant, or redundant information from the  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context window [2]. Implementation approaches include chronological pruning that removes oldest exchanges first <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> (the simplest approach), heuristic-based pruning that drops confirmations and casual conversation while         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> preserving instructions, priority-based pruning that assigns importance scores to different message types, and  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> semantic pruning that analyzes content to remove redundant or off-topic information.\\n\\nBest practices for      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> pruning include triggering automatically at 80-95% of maximum token size, pairing with summarization for        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> maximum effectiveness, and summarizing before dropping content to preserve essential information [2]. For       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> example, after five tool calls, keep only the most recent 2-3 turns, summarize earlier results, and drop raw    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> outputs.\\n\\n### Technique 2: Summarization\\n\\nSummarization compresses long message chains into concise         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> summaries that preserve semantic relevance [2]. Implementation patterns include hierarchical summarization that <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> breaks long contexts into chunks, summarizes each, then summarizes summaries; rolling summarization that        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> updates and re-compresses summaries over time; and trigger points that activate at 50% of available window or   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> when starting new tasks.\\n\\nEffective summarization instructions should preserve open tasks, decisions made,    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> important facts, and unresolved issues, while excluding casual conversation, confirmations, intermediate steps, <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and acted-upon information [2]. Claude Code continuously compresses historical context during extended coding   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> sessions, preserving current file state and recent operations while summarizing earlier changes [2].\\n\\n###     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Technique 3: Offloading\\n\\nOffloading moves detailed data outside the context window into external memory       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> systems [2]. Storage options include vector databases, file systems, structured databases, and knowledge bases. <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> The implementation pattern follows a clear sequence: the agent saves detailed outputs immediately after         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> generation, maintains references (IDs or summaries) in context, queries the external store when detailed        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information is needed, and retrieves and includes relevant content in the next prompt.\\n\\nFor example, when     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> processing 1,000 emails, store full content externally with IDs, keep only summaries in context, and retrieve   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> specific emails on demand [2]. This approach enables agents to work with datasets far larger than any context   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> window could accommodate.\\n\\n### Technique 4: Atomic Tools\\n\\nThe atomic tool pattern provides general-purpose, <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> single-responsibility tools instead of dozens of specialized tools [2]. Following the Unix philosophy of doing  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> one thing well, each tool handles a specific, precisely defined task, enabling clean data flow between tools    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and reducing prompt bloat from extensive tool descriptions.\\n\\nBenefits include reduced debugging complexity,   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> improved maintainability, enhanced orchestration flexibility, and minimized system prompt token overhead [2].   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Replit, Cursor, and LangChain use separate \\\"read_file,\\\" \\\"analyze_code,\\\" and \\\"write_file\\\" tools rather     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> than combined \\\"analyze_and_fix_code\\\" tools [2]. This atomic approach gives agents more flexibility in         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> composing operations while keeping individual tool descriptions concise.\\n\\n### Technique 5: Context Isolation  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> (Sub-Agents)\\n\\nContext isolation uses sub-agent architectures for token-heavy or logically isolated subtasks   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [2]. The main agent acts as orchestrator, spawning dedicated sub-agents for focused missions. Each sub-agent    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> receives fresh, minimal context and returns only condensed output to the main agent.\\n\\nAdvantages include      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> isolating complexity and preventing cross-task pollution, enabling parallelization of concurrent subtasks,      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> supporting specialization with different prompts or models, and expanding total system token capacity [2].      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> LangGraph and similar frameworks provide built-in support for sub-agent lifecycle management, context           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> isolation, and result aggregation.\\n\\n### Technique 6: Conservative Context Management\\n\\nConservative          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> management recognizes that technical maximum context doesn't equal optimal usage [2]. Key principles include    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> starting fresh frequently after completing major tasks, resetting when reaching 50% of available window, using  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> query-aware contextualization to include only relevant context, and breaking complex tasks into smaller         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> subtasks with fresh context.\\n\\nStrategic positioning places critical information at beginning and end of       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context to avoid the \\\"lost in the middle\\\" phenomenon where buried information gets overlooked [2]. Real-time  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> monitoring of token counts with automatic triggers at specific thresholds (40% warning, 60% action) ensures     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> proactive management before context degradation occurs.\\n\\n## Retrieval-Augmented Generation (RAG)              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Techniques\\n\\nRAG represents a central context engineering challenge, enabling agents to access external        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> knowledge dynamically [1][4]. The core RAG workflow follows this sequence: user query \\u2192 embedding \\u2192   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> vector search \\u2192 retrieve top-K documents \\u2192 augment prompt \\u2192 LLM generation \\u2192 response       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [4].\\n\\n### Query Classification and Chunking\\n\\nQuery classification determines if retrieval is needed, since  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> some queries don't require external information [4]. A binary classifier separates \\\"sufficient\\\" versus        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> \\\"insufficient\\\" queries, saving costs by avoiding unnecessary retrieval.\\n\\nOptimal chunk sizes range from     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 256-512 tokens [4]. The small2big approach starts with small chunks for search, then expands to larger chunks   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> for generation. Sliding windows overlap tokens between chunks for context preservation, ensuring important      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information isn't lost at chunk boundaries.\\n\\n### Metadata and Hybrid Search\\n\\nAdding titles, keywords, and   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> hypothetical questions to chunks improves retrieval accuracy [4]. Combining vector search (semantic matching)   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> with BM25 (keyword search) provides better balance than HyDE, which is more accurate but inefficient. This      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> hybrid approach captures both semantic similarity and exact keyword matches.\\n\\nEmbedding models should be      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> chosen appropriate for the domain. LLM-Embedder from FlagEmbedding offers good balance of performance and size, <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> while Cohere provides strong commercial options [4]. The choice of embedding model significantly impacts        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> retrieval quality and should be evaluated on domain-specific benchmarks.\\n\\n### Reranking and Document          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Repacking\\n\\nReranking reorders retrieved documents by relevance after initial retrieval [4]. monoT5 offers the <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> best balance of performance and efficiency, RankLLaMA provides best overall performance, and TILDEv2 is the     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> fastest option. Reranking significantly improves the quality of documents presented to the LLM.\\n\\nDocument     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> repacking arranges documents in ascending order of relevance using the \\\"reverse\\\" method, placing relevant     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information at start or end for better LLM processing [4]. This optimizes information presentation after        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> reranking, taking advantage of models' tendency to pay more attention to information at the beginning and end   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> of context.\\n\\n### Advanced RAG Patterns\\n\\nAgentic RAG combines multiple retrieval strategies: AST parsing for <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> code, grep searches for text, knowledge graphs for relationships, and LLM-based re-ranking for semantic         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> chunking [1]. This multi-strategy approach adapts retrieval methods to the type of information being            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> sought.\\n\\nMultimodal retrieval extends RAG beyond text. Text-to-image queries database for similar images,     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> while image-to-text matches similar images to retrieve captions [4]. This ensures groundedness with real,       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> verified information across different modalities.\\n\\nSummarization removes redundant or unnecessary information <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> before the LLM call. Tools like Recomp provide extractive and abstractive compression [4]. While this reduces   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> costs, it adds latency, so the trade-off must be evaluated based on application requirements.\\n\\n## Context     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Window Management and Optimization\\n\\nModern LLMs advertise large context windows (up to 1 million tokens), but <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> research shows that effective performance occurs within much smaller windows - typically the first              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 50,000-100,000 tokens [2]. Beyond this threshold, models experience context rot with degraded accuracy and      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> instruction-following capability, the \\\"lost in the middle\\\" phenomenon where information buried mid-context    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> gets overlooked, increased latency from processing massive contexts, and higher costs since every token incurs  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> inference costs that compound with repeated processing.\\n\\nConservative context management strategy sets        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> aggressive thresholds, triggering context management at 40-60% of maximum window rather than 80-90% [2].        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Starting fresh frequently after completing major tasks prevents accumulation of stale context. Strategic        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> positioning places critical instructions at the beginning and end of prompts where models pay most attention.   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Query-aware contextualization dynamically adjusts included context based on the specific task rather than       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> comprehensive history.\\n\\n## Long-Term Memory and State Management\\n\\nProduction systems implement hierarchical <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> memory with distinct short-term and long-term storage [2][3]. Short-term memory (active context) contains       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> recent messages and current task context. Long-term memory (external storage) holds compressed historical       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information, facts, and decisions. Working memory (external databases) stores tool outputs, intermediate        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> results, and large datasets.\\n\\nLlamaIndex provides sophisticated approaches to managing multi-turn             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> conversations with custom memory blocks [3]. Custom memory blocks can condense past messages while maintaining  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> token limits, automatically enforce token budgets by removing oldest messages, and integrate seamlessly with    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> agent workflows to prevent multi-turn confusion.\\n\\nThe multi-turn confusion problem shows that LLM performance <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> significantly degrades in multi-turn conversations without proper management [3]. Agents accumulate hundreds of <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> thousands of tokens after just several rounds of tool calls. The solution involves aggressive context flushing  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> where short-term memory always contains minimal turns and all history is condensed into long-term memory        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> blocks.\\n\\n## Tool Use and Function Calling Context Patterns\\n\\nThe atomic tools pattern provides few           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> general-purpose tools with clear, narrow scopes rather than many specialized tools that bloat system prompts    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [2]. Design principles include single responsibility where each tool does one thing well (Unix philosophy),     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> minimal ambiguity with clear input schemas and predictable outputs, composability allowing tools to be chained  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> together, and reduced prompt overhead from fewer tool descriptions in system prompt.\\n\\nReplit, Cursor, and     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> LangChain agents use highly atomic tool definitions [2]. Instead of \\\"analyze_and_fix_code\\\", they provide      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> separate \\\"read_file\\\", \\\"analyze_code\\\", and \\\"write_file\\\" tools that agents chain together. This gives       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> agents more flexibility while keeping individual tool descriptions concise.\\n\\nTool outputs can be massive and  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> quickly fill context windows [2]. The offloading pattern stores large tool outputs externally and returns       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> reference IDs. After tool execution, the system stores large output externally, includes only a reference in    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context, and retrieves full output only when the agent specifically requests it. This dramatically reduces      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context consumption while maintaining access to full data when needed.\\n\\n## Real-World Implementations\\n\\n###  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Production Systems\\n\\nManus, a production agent platform, executes workflows requiring 50+ tool calls per run   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [2]. It employs aggressive pruning of tool outputs after acknowledgment, uses rolling summarization at workflow <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> phase boundaries, and offloads detailed results to structured storage. Without context engineering, the         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> platform would be economically unviable.\\n\\nClaude Code from Anthropic implements hierarchical summarization in <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> tool call histories [1][2]. Its auto-compact feature activates at 95% context capacity, enabling extended       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> coding sessions without coherence loss. The system preserves current file state while summarizing earlier       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> changes.\\n\\nChatGPT from OpenAI auto-generates user preferences from conversations and maintains long-term      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> memories across sessions [1]. This demonstrates both benefits and risks of context management, as unexpected    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information injection can occur if not carefully controlled.\\n\\nCursor and Windsurf development tools learn     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> coding patterns and project context over time [1]. They use AGENTS.md or similar configuration files to provide <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context-aware code suggestions that improve as they learn developer preferences.\\n\\n### AI Configuration        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Files\\n\\nResearch on 10,000 GitHub repositories found that 5% (466 repositories) had adopted AI configuration   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> files [3]. Common formats include AGENTS.md (tool-agnostic standard), CLAUDE.md (Anthropic's Claude Code),      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> copilot-instructions.md (GitHub Copilot), and GEMINI.md (Google Gemini).\\n\\nContent categories from empirical   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> analysis include conventions and best practices (50 instances), contribution guidelines (48), architecture and  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> project structure (47), build commands (40), project description (32), testing instructions (32), tech stack    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and dependencies (15), and getting started and setup (11) [3].\\n\\n## Implementation Best Practices\\n\\n###       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Design for Context Engineering from the Start\\n\\nBuild context tracking into agent architecture from the first  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> prototype [2]. Establish clear patterns for when pruning, summarization, and offloading occur. Create           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> abstractions that make context management decisions explicit and testable. Treating context engineering as an   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> afterthought leads to brittle systems that fail under production load.\\n\\n### Establish Clear Metrics\\n\\nTrack  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> token usage per interaction (average and peak), measure model performance across different context sizes,       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> monitor costs directly tied to context length, and assess user experience metrics like latency and accuracy     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [2]. These metrics provide visibility into context engineering effectiveness and guide optimization             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> efforts.\\n\\n### Implement Graceful Degradation\\n\\nNever crash or produce empty responses when hitting context   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> limits [2]. Automatically trigger aggressive summarization or pruning, reset to clean state with summary of     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> prior work, and provide explanations when context limits force interruption. Users should experience smooth     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> operation even when context management interventions occur.\\n\\n### Combine Multiple Techniques\\n\\nSuccessful    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> systems use pruning for routine cleanup, summarization for compressing important information, offloading for    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> large data, atomic tools for efficiency, sub-agents for isolation, and conservative management for reliability  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [1][2]. No single technique solves all context challenges; production systems strategically combine approaches  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> based on specific needs.\\n\\n### Comprehensive Testing\\n\\nEvaluate with minimal context, test with moderate      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> context, verify near-maximum context handling, confirm pruning and summarization preserve essential             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information, validate offloading and retrieval mechanisms, and test edge cases where summarization might        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> introduce errors [2]. Testing across different context scenarios ensures robustness in production.\\n\\n###       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Continuous Monitoring and Iteration\\n\\nAnalyze context usage patterns regularly, identify optimization          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> opportunities, A/B test different pruning thresholds, experiment with summarization frequencies, and evolve     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> approach based on real-world usage data [2]. Context engineering is not a one-time implementation but an        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ongoing optimization process.\\n\\n### Explicit Documentation\\n\\nDocument why pruning occurs at specific          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> thresholds, explain how summarization prompts were designed, clarify what information gets offloaded versus     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> kept in context, and prevent well-intentioned changes from breaking tuned systems [2]. Documentation ensures    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> team members understand context management decisions and maintain system integrity.\\n\\n### Version Control for  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> AI Configuration\\n\\nTreat AI configuration files as maintained software artifacts [3]. Version, review, and     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> quality-assure like source code. Track evolution and co-evolution with source code. Enable team-wide            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> consistency in AI behavior. Configuration files should undergo the same rigor as application code.\\n\\n##        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Performance Gains and Impact\\n\\nTeams implementing proper context engineering report substantial improvements   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [2]. They achieve 10x reduction in token usage through pruning and summarization alone, 50-70% latency          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> improvements from keeping contexts lean and focused, similar magnitude cost reductions making previously        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> impractical workflows viable, and dramatic accuracy and reliability improvements when models work within        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> effective context windows.\\n\\nContext engineering transforms AI agent economics. Production systems like Manus  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> would be economically unviable without it [2]. Multi-agent systems can cost 15x more tokens than single-agent   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> chat without proper management [1]. Strategic context management makes complex, long-running workflows          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> practical at scale.\\n\\n## Future Directions\\n\\nEmerging areas include automated context optimization with       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> feedback loops that update configuration files based on observed results, automated testing of how content,     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> structure, and style affect agent behavior, and machine learning approaches to optimize context selection       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> [3].\\n\\nCo-evolution studies examine the relationship between source code and AI configuration files, similar   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> to studies on source code and comment co-evolution [3]. Understanding how context requirements change with code <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> will inform better practices for maintaining configuration files.\\n\\nStandardization efforts explore whether    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> standard schemas could improve interoperability, the trade-offs between centralized versus module-level         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> configuration files, and approaches for coordinating instructions for multiple agents [3].\\n\\nOpen questions    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> remain about how tone and phrasing in configuration files influence agent adherence [3], the optimal balance    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> between context comprehensiveness and focus, how to better measure and predict context rot, and best practices  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> for context management in multi-modal agents.\\n\\n## Conclusion\\n\\nContext engineering has evolved from an       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> esoteric concern to a fundamental discipline in AI systems engineering. As one researcher noted, \\\"context      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> engineering is effectively the #1 job of engineers building AI agents\\\" [1]. The difference between naive demos <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and magical products lies not in the underlying model, but in the quality of context provided.\\n\\nKey takeaways <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> include that context engineering is system architecture, not just prompt writing - it encompasses the entire    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> information pipeline before LLM calls. Multiple techniques work together, as successful systems combine         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> pruning, summarization, offloading, atomic tools, context isolation, and conservative management. Performance   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and cost are directly impacted, with proper context engineering delivering 10x token reductions, 50-70% latency <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> improvements, and dramatic cost savings. Real-world adoption is growing, with 5% of surveyed open-source        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> projects having adopted AI configuration files, though conventions are still evolving [3]. Best practices are   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> emerging around designing for context management from the start, establishing clear metrics, testing            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> comprehensively, and documenting explicitly.\\n\\nFor teams building AI agents, strategic recommendations include <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> investing in context engineering infrastructure early in development, treating AI configuration files as        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> first-class software artifacts requiring version control and maintenance, monitoring context usage continuously <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> and optimizing based on real data, combining multiple context engineering techniques rather than relying on     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> single approaches, and testing across different context scenarios to ensure robustness.\\n\\nThe teams that       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> master context engineering will build AI agents that don't merely work in demos but thrive in production,       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> delivering reliable, cost-effective, and exceptional user experiences. Context engineering represents the       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> invisible discipline that separates successful production AI systems from failed experiments.\\n\\n##             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Sources\\n\\n[1] What is Context Engineering for AI Agents? - Adaline Labs:                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://labs.adaline.ai/p/what-is-context-engineering-for-ai\\n\\n[2] Context Engineering: The Invisible          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Discipline Keeping AI Agents from Drowning in Their Own Memory - Juan C Olamendy, Medium:                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowning <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> -in-their-own-memory-c0283ca6a954\\n\\n[3] Context Engineering for AI Agents in Open-Source Software - arXiv:     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://arxiv.org/html/2510.21413v1\\n\\n[4] Top RAG Techniques You Should Know (Wang et al., 2024) - Louis       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Bouchard: https://www.louisbouchard.ai/top-rag-techniques/\\n\\n[5] Context Engineering: The Dynamic Context      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Construction Technique for AI Agents - AWS Builder Center:                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://builder.aws.com/content/3064TwnFXzSYe6r2EpN6Ye2Q2u1/context-engineering-the-dynamic-context-constructio <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> n-technique-for-ai-agents\\n\\n[6] Reducing Multi-Turn Confusion with LlamaIndex Memory - LlamaIndex              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Documentation: https://developers.llamaindex.ai/python/examples/memory/custom_multi_turn_memory/\\n\\n[7] What is <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Retrieval-Augmented Generation (RAG)? - Vectorize Documentation:                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://docs.vectorize.io/welcome/core-concepts/retrieval-augmented-generation/\\n\\n[8] A Comprehensive Guide to <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Using Function Calling with LangChain - Cohorte Blog:                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> https://www.cohorte.co/blog/a-comprehensive-guide-to-using-function-calling-with-langchain\\n\"                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01TuQpbm5ScJXrhTMfn6AN53                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m Now let me compile the comprehensive research into a final report.                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_file                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"file_path\": \"/final_report.md\",                                                                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"content\": \"# Context Engineering Approaches for Building AI Agents\\n\\n## Overview\\n\\nContext engineering has \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m emerged as a critical discipline in AI agent development, representing the strategic management, curation, and  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m control of information provided to large language models (LLMs). As Andrej Karpathy describes it, context       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m engineering is \\\"the delicate art and science of filling the context window with just the right information for \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m the next step\\\" [1]. This discipline has evolved from simple prompt engineering to sophisticated system         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m architecture that determines whether AI agents succeed or fail in production environments.\\n\\nContext           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m engineering directly impacts three fundamental aspects of AI systems: performance and reliability, cost         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m efficiency, and user experience [1][2]. Research shows that models perform optimally only in the first          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 50,000-100,000 tokens, even with million-token context windows, making strategic context management essential   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m rather than optional [2]. As one researcher noted, \\\"Most agent failures are context failures\\\" - the system    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m didn't provide adequate information for success [1].\\n\\n## What is Context Engineering?\\n\\nContext engineering  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m is the discipline of strategically managing, curating, and controlling the information provided to large        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m language models [1][2]. It represents an evolution from prompt engineering, which focuses on crafting           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m instructions, to context engineering, which focuses on architecting the entire information pipeline before the  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m LLM call.\\n\\nWhile prompt engineering concentrated on writing clever, concise instructions for simple tasks,    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context engineering treats the entire pipeline as engineerable infrastructure [1]. This includes dynamic        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information gathering through RAG systems and API calls, memory management for both short-term conversation     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m state and long-term knowledge, tool coordination to make external functions available when needed, and output   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m structuring to define schemas and formats for consistent results.\\n\\nEarly AI development relied heavily on     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m prompting methods like chain-of-thought, ReAct, and self-consistency for complex tasks [1]. However, as         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m applications evolved into AI agents with multi-step reasoning, long-running conversations, and dynamic          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information retrieval, these approaches hit significant limitations. Context engineering emerged as the         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m solution to handle multi-step reasoning requiring tool use, long-running conversations with memory, dynamic     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information retrieval from databases, and coordination between multiple AI systems.\\n\\n## Why Context           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Engineering Matters\\n\\nContext engineering has become essential because poor context management creates         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m \\\"context rot\\\" where model quality degrades well before hitting technical token limits [2]. Models experience  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m performance degradation, increased latency, and higher costs as context windows fill up. Processing 500,000     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m tokens takes significantly longer than 5,000 tokens, and every token sent to an LLM incurs inference costs that \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m compound with repeated processing.\\n\\nProduction systems without context engineering quickly become             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m cost-prohibitive at scale. Naive approaches that append all tool results can generate hundreds of thousands of  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m tokens after just several rounds [2]. Teams implementing proper context engineering report substantial          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m improvements: 10x reduction in token usage through pruning and summarization alone, 50-70% latency improvements \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m from keeping contexts lean and focused, similar magnitude cost reductions making previously impractical         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m workflows viable, and dramatic accuracy and reliability improvements when models work within effective context  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m windows [2].\\n\\nPoor context management creates four major failure modes [1]: context poisoning where           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m hallucinations contaminate future responses, context distraction where too much information overwhelms the      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m model, context confusion where conflicting information causes errors, and context clash where disagreeing       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m sources lead to inconsistent outputs.\\n\\n## Types of Context in AI Agents\\n\\nModern AI agents require multiple  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context types working together [1][3]. Static context includes prompts with core behavior rules and examples,   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m tool definitions specifying available functions and their parameters, output schemas defining response format   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m requirements, and configuration files containing project-specific instructions like AGENTS.md or CLAUDE.md      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m files.\\n\\nDynamic context encompasses user input representing the immediate task or question, chat history      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m providing short-term conversation memory, long-term memory storing persistent preferences and past learnings,   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m retrieved knowledge from RAG results from databases or APIs, tool responses providing feedback from executed    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m functions, and workflow state containing information stored across agent steps.\\n\\nResearch on open-source      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m projects found that AI configuration files commonly include coding conventions (50 instances), contribution     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m guidelines (48), architecture descriptions (47), build commands (40), and testing instructions (32) [3]. These  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m configuration files use different writing styles: descriptive (\\\"This project uses the Linux Kernel Style       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Guideline\\\"), prescriptive (\\\"Use factories for all test data\\\"), prohibitive (\\\"Never commit directly to the   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m main branch\\\"), explanatory (\\\"Avoid hard-coded waits to prevent timing issues\\\"), and conditional (\\\"If you    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m need to use reflection, use ReflectionUtils APIs\\\") [3].\\n\\n## Core Context Engineering Strategies\\n\\n###       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Strategy 1: Writing Context (Memory Management)\\n\\nWriting context involves saving information outside the      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context window to preserve valuable token space [1]. This strategy enables two key capabilities: scratchpads    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m for temporary note-taking within a single session, and long-term memories for information retained across       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m multiple sessions.\\n\\nScratchpads provide temporary storage during agent execution. Anthropic's multi-agent     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m researcher saves initial plans to \\\"Memory\\\" to prevent loss when context exceeds 200,000 tokens [1].           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Implementation options include file-based tools or runtime state objects that persist during a session but      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m don't carry over to future interactions.\\n\\nLong-term memories enable personalization and create evolving       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m experiences that improve over time. ChatGPT auto-generates user preferences from conversations, while Cursor    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m and Windsurf learn coding patterns and project context [1]. Reflexion agents create self-generated memories     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m from task feedback, allowing them to improve performance on subsequent attempts.\\n\\n### Strategy 2: Selecting   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Context (Intelligent Retrieval)\\n\\nSelecting context means pulling only relevant information into the context   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m window [1][4]. This strategy provides fine-grained control over what information gets exposed to the LLM,       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m enabling selective exposure of specific parts from scratchpads or state objects to reduce noise and improve     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m decision-making.\\n\\nMemory selection operates across three types: episodic memories containing few-shot         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m examples showing desired behavior, procedural memories storing instructions in configuration files, and         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m semantic memories holding facts relevant to current context through embeddings and RAG [1].\\n\\nAgentic RAG      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m applies retrieval-augmented generation to tool descriptions themselves. Too many tools create \\\"model           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m confusion\\\" about which to use, but RAG-based tool selection improves accuracy by 3-fold according to recent    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m research [1]. This approach dynamically selects which tools to expose based on the current task, rather than    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m overwhelming the model with dozens of tool descriptions.\\n\\n### Strategy 3: Compressing Context                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m (Optimization)\\n\\nCompressing context retains only tokens required to perform a task [1][2]. This strategy      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m employs two primary techniques: context summarization and context trimming.\\n\\nContext summarization condenses  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information while preserving essential details. Claude Code's \\\"auto-compact\\\" feature summarizes when context  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m exceeds 95% capacity [1]. Summarization applies at multiple levels: full trajectory summarization,              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m summarization at specific points during execution, and summarization at agent boundaries in multi-agent         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m systems. Some companies use fine-tuned models specifically for summarization to ensure consistent               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m quality.\\n\\nContext trimming uses filtering or \\\"pruning\\\" approaches to remove content. Hard-coded heuristics  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m might remove older messages from lists, while learned approaches employ trained context pruners for specific    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m domains [1]. Trimming offers immediate, predictable context reduction without the computational overhead of     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m summarization, though it risks losing potentially valuable information.\\n\\n### Strategy 4: Isolating Context    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m (Structural Separation)\\n\\nIsolating context splits it across different components to reduce cognitive load     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [1][2]. This strategy manifests in two primary patterns: multi-agent architectures and                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m sandboxes.\\n\\nMulti-agent architectures split context across sub-agents, each with their own context windows,   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m tools, and instructions. This enables separation of concerns for specialized subtasks, expands total token      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m capacity across the system, and prevents context pollution between different workflow phases [1]. The challenge \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m is that multi-agent systems can increase costs up to 15x more tokens than single-agent systems without proper   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m management [1].\\n\\nSandboxes and execution environments isolate code execution from the LLM's context window.   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m They persist state across multiple responses and excel at handling token-heavy objects like images and audio    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m files [1]. Only selective results are passed back to the LLM, keeping the context window focused on high-level  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m reasoning rather than detailed execution artifacts.\\n\\n## Six Core Context Engineering Techniques\\n\\n###        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Technique 1: Pruning\\n\\nPruning systematically removes older, less relevant, or redundant information from the  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context window [2]. Implementation approaches include chronological pruning that removes oldest exchanges first \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m (the simplest approach), heuristic-based pruning that drops confirmations and casual conversation while         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m preserving instructions, priority-based pruning that assigns importance scores to different message types, and  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m semantic pruning that analyzes content to remove redundant or off-topic information.\\n\\nBest practices for      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m pruning include triggering automatically at 80-95% of maximum token size, pairing with summarization for        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m maximum effectiveness, and summarizing before dropping content to preserve essential information [2]. For       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m example, after five tool calls, keep only the most recent 2-3 turns, summarize earlier results, and drop raw    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m outputs.\\n\\n### Technique 2: Summarization\\n\\nSummarization compresses long message chains into concise         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m summaries that preserve semantic relevance [2]. Implementation patterns include hierarchical summarization that \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m breaks long contexts into chunks, summarizes each, then summarizes summaries; rolling summarization that        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m updates and re-compresses summaries over time; and trigger points that activate at 50% of available window or   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m when starting new tasks.\\n\\nEffective summarization instructions should preserve open tasks, decisions made,    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m important facts, and unresolved issues, while excluding casual conversation, confirmations, intermediate steps, \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m and acted-upon information [2]. Claude Code continuously compresses historical context during extended coding   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m sessions, preserving current file state and recent operations while summarizing earlier changes [2].\\n\\n###     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Technique 3: Offloading\\n\\nOffloading moves detailed data outside the context window into external memory       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m systems [2]. Storage options include vector databases, file systems, structured databases, and knowledge bases. \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m The implementation pattern follows a clear sequence: the agent saves detailed outputs immediately after         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m generation, maintains references (IDs or summaries) in context, queries the external store when detailed        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information is needed, and retrieves and includes relevant content in the next prompt.\\n\\nFor example, when     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m processing 1,000 emails, store full content externally with IDs, keep only summaries in context, and retrieve   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m specific emails on demand [2]. This approach enables agents to work with datasets far larger than any context   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m window could accommodate.\\n\\n### Technique 4: Atomic Tools\\n\\nThe atomic tool pattern provides general-purpose, \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m single-responsibility tools instead of dozens of specialized tools [2]. Following the Unix philosophy of doing  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m one thing well, each tool handles a specific, precisely defined task, enabling clean data flow between tools    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m and reducing prompt bloat from extensive tool descriptions.\\n\\nBenefits include reduced debugging complexity,   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m improved maintainability, enhanced orchestration flexibility, and minimized system prompt token overhead [2].   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Replit, Cursor, and LangChain use separate \\\"read_file,\\\" \\\"analyze_code,\\\" and \\\"write_file\\\" tools rather     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m than combined \\\"analyze_and_fix_code\\\" tools [2]. This atomic approach gives agents more flexibility in         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m composing operations while keeping individual tool descriptions concise.\\n\\n### Technique 5: Context Isolation  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m (Sub-Agents)\\n\\nContext isolation uses sub-agent architectures for token-heavy or logically isolated subtasks   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [2]. The main agent acts as orchestrator, spawning dedicated sub-agents for focused missions. Each sub-agent    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m receives fresh, minimal context and returns only condensed output to the main agent.\\n\\nAdvantages include      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m isolating complexity and preventing cross-task pollution, enabling parallelization of concurrent subtasks,      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m supporting specialization with different prompts or models, and expanding total system token capacity [2].      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m LangGraph and similar frameworks provide built-in support for sub-agent lifecycle management, context           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m isolation, and result aggregation.\\n\\n### Technique 6: Conservative Context Management\\n\\nConservative          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m management recognizes that technical maximum context doesn't equal optimal usage [2]. Key principles include    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m starting fresh frequently after completing major tasks, resetting when reaching 50% of available window, using  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m query-aware contextualization to include only relevant context, and breaking complex tasks into smaller         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m subtasks with fresh context.\\n\\nStrategic positioning places critical information at beginning and end of       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context to avoid the \\\"lost in the middle\\\" phenomenon where buried information gets overlooked [2]. Real-time  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m monitoring of token counts with automatic triggers at specific thresholds (40% warning, 60% action) ensures     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m proactive management before context degradation occurs.\\n\\n## Retrieval-Augmented Generation (RAG)              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Techniques\\n\\nRAG represents a central context engineering challenge, enabling agents to access external        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m knowledge dynamically [1][4]. The core RAG workflow follows this sequence: user query \\u2192 embedding \\u2192   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m vector search \\u2192 retrieve top-K documents \\u2192 augment prompt \\u2192 LLM generation \\u2192 response       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [4].\\n\\n### Query Classification and Chunking\\n\\nQuery classification determines if retrieval is needed, since  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m some queries don't require external information [4]. A binary classifier separates \\\"sufficient\\\" versus        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m \\\"insufficient\\\" queries, saving costs by avoiding unnecessary retrieval.\\n\\nOptimal chunk sizes range from     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 256-512 tokens [4]. The small2big approach starts with small chunks for search, then expands to larger chunks   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m for generation. Sliding windows overlap tokens between chunks for context preservation, ensuring important      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information isn't lost at chunk boundaries.\\n\\n### Metadata and Hybrid Search\\n\\nAdding titles, keywords, and   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m hypothetical questions to chunks improves retrieval accuracy [4]. Combining vector search (semantic matching)   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m with BM25 (keyword search) provides better balance than HyDE, which is more accurate but inefficient. This      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m hybrid approach captures both semantic similarity and exact keyword matches.\\n\\nEmbedding models should be      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m chosen appropriate for the domain. LLM-Embedder from FlagEmbedding offers good balance of performance and size, \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m while Cohere provides strong commercial options [4]. The choice of embedding model significantly impacts        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m retrieval quality and should be evaluated on domain-specific benchmarks.\\n\\n### Reranking and Document          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Repacking\\n\\nReranking reorders retrieved documents by relevance after initial retrieval [4]. monoT5 offers the \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m best balance of performance and efficiency, RankLLaMA provides best overall performance, and TILDEv2 is the     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m fastest option. Reranking significantly improves the quality of documents presented to the LLM.\\n\\nDocument     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m repacking arranges documents in ascending order of relevance using the \\\"reverse\\\" method, placing relevant     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information at start or end for better LLM processing [4]. This optimizes information presentation after        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m reranking, taking advantage of models' tendency to pay more attention to information at the beginning and end   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m of context.\\n\\n### Advanced RAG Patterns\\n\\nAgentic RAG combines multiple retrieval strategies: AST parsing for \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m code, grep searches for text, knowledge graphs for relationships, and LLM-based re-ranking for semantic         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m chunking [1]. This multi-strategy approach adapts retrieval methods to the type of information being            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m sought.\\n\\nMultimodal retrieval extends RAG beyond text. Text-to-image queries database for similar images,     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m while image-to-text matches similar images to retrieve captions [4]. This ensures groundedness with real,       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m verified information across different modalities.\\n\\nSummarization removes redundant or unnecessary information \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m before the LLM call. Tools like Recomp provide extractive and abstractive compression [4]. While this reduces   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m costs, it adds latency, so the trade-off must be evaluated based on application requirements.\\n\\n## Context     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Window Management and Optimization\\n\\nModern LLMs advertise large context windows (up to 1 million tokens), but \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m research shows that effective performance occurs within much smaller windows - typically the first              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 50,000-100,000 tokens [2]. Beyond this threshold, models experience context rot with degraded accuracy and      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m instruction-following capability, the \\\"lost in the middle\\\" phenomenon where information buried mid-context    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m gets overlooked, increased latency from processing massive contexts, and higher costs since every token incurs  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m inference costs that compound with repeated processing.\\n\\nConservative context management strategy sets        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m aggressive thresholds, triggering context management at 40-60% of maximum window rather than 80-90% [2].        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Starting fresh frequently after completing major tasks prevents accumulation of stale context. Strategic        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m positioning places critical instructions at the beginning and end of prompts where models pay most attention.   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Query-aware contextualization dynamically adjusts included context based on the specific task rather than       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m comprehensive history.\\n\\n## Long-Term Memory and State Management\\n\\nProduction systems implement hierarchical \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m memory with distinct short-term and long-term storage [2][3]. Short-term memory (active context) contains       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m recent messages and current task context. Long-term memory (external storage) holds compressed historical       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information, facts, and decisions. Working memory (external databases) stores tool outputs, intermediate        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m results, and large datasets.\\n\\nLlamaIndex provides sophisticated approaches to managing multi-turn             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m conversations with custom memory blocks [3]. Custom memory blocks can condense past messages while maintaining  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m token limits, automatically enforce token budgets by removing oldest messages, and integrate seamlessly with    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m agent workflows to prevent multi-turn confusion.\\n\\nThe multi-turn confusion problem shows that LLM performance \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m significantly degrades in multi-turn conversations without proper management [3]. Agents accumulate hundreds of \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m thousands of tokens after just several rounds of tool calls. The solution involves aggressive context flushing  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m where short-term memory always contains minimal turns and all history is condensed into long-term memory        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m blocks.\\n\\n## Tool Use and Function Calling Context Patterns\\n\\nThe atomic tools pattern provides few           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m general-purpose tools with clear, narrow scopes rather than many specialized tools that bloat system prompts    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [2]. Design principles include single responsibility where each tool does one thing well (Unix philosophy),     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m minimal ambiguity with clear input schemas and predictable outputs, composability allowing tools to be chained  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m together, and reduced prompt overhead from fewer tool descriptions in system prompt.\\n\\nReplit, Cursor, and     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m LangChain agents use highly atomic tool definitions [2]. Instead of \\\"analyze_and_fix_code\\\", they provide      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m separate \\\"read_file\\\", \\\"analyze_code\\\", and \\\"write_file\\\" tools that agents chain together. This gives       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m agents more flexibility while keeping individual tool descriptions concise.\\n\\nTool outputs can be massive and  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m quickly fill context windows [2]. The offloading pattern stores large tool outputs externally and returns       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m reference IDs. After tool execution, the system stores large output externally, includes only a reference in    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context, and retrieves full output only when the agent specifically requests it. This dramatically reduces      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context consumption while maintaining access to full data when needed.\\n\\n## Real-World Implementations\\n\\n###  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Production Systems\\n\\nManus, a production agent platform, executes workflows requiring 50+ tool calls per run   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [2]. It employs aggressive pruning of tool outputs after acknowledgment, uses rolling summarization at workflow \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m phase boundaries, and offloads detailed results to structured storage. Without context engineering, the         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m platform would be economically unviable.\\n\\nClaude Code from Anthropic implements hierarchical summarization in \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m tool call histories [1][2]. Its auto-compact feature activates at 95% context capacity, enabling extended       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m coding sessions without coherence loss. The system preserves current file state while summarizing earlier       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m changes.\\n\\nChatGPT from OpenAI auto-generates user preferences from conversations and maintains long-term      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m memories across sessions [1]. This demonstrates both benefits and risks of context management, as unexpected    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information injection can occur if not carefully controlled.\\n\\nCursor and Windsurf development tools learn     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m coding patterns and project context over time [1]. They use AGENTS.md or similar configuration files to provide \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context-aware code suggestions that improve as they learn developer preferences.\\n\\n### AI Configuration        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Files\\n\\nResearch on 10,000 GitHub repositories found that 5% (466 repositories) had adopted AI configuration   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m files [3]. Common formats include AGENTS.md (tool-agnostic standard), CLAUDE.md (Anthropic's Claude Code),      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m copilot-instructions.md (GitHub Copilot), and GEMINI.md (Google Gemini).\\n\\nContent categories from empirical   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m analysis include conventions and best practices (50 instances), contribution guidelines (48), architecture and  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m project structure (47), build commands (40), project description (32), testing instructions (32), tech stack    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m and dependencies (15), and getting started and setup (11) [3].\\n\\n## Implementation Best Practices\\n\\n###       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Design for Context Engineering from the Start\\n\\nBuild context tracking into agent architecture from the first  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m prototype [2]. Establish clear patterns for when pruning, summarization, and offloading occur. Create           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m abstractions that make context management decisions explicit and testable. Treating context engineering as an   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m afterthought leads to brittle systems that fail under production load.\\n\\n### Establish Clear Metrics\\n\\nTrack  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m token usage per interaction (average and peak), measure model performance across different context sizes,       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m monitor costs directly tied to context length, and assess user experience metrics like latency and accuracy     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [2]. These metrics provide visibility into context engineering effectiveness and guide optimization             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m efforts.\\n\\n### Implement Graceful Degradation\\n\\nNever crash or produce empty responses when hitting context   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m limits [2]. Automatically trigger aggressive summarization or pruning, reset to clean state with summary of     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m prior work, and provide explanations when context limits force interruption. Users should experience smooth     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m operation even when context management interventions occur.\\n\\n### Combine Multiple Techniques\\n\\nSuccessful    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m systems use pruning for routine cleanup, summarization for compressing important information, offloading for    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m large data, atomic tools for efficiency, sub-agents for isolation, and conservative management for reliability  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [1][2]. No single technique solves all context challenges; production systems strategically combine approaches  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m based on specific needs.\\n\\n### Comprehensive Testing\\n\\nEvaluate with minimal context, test with moderate      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m context, verify near-maximum context handling, confirm pruning and summarization preserve essential             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information, validate offloading and retrieval mechanisms, and test edge cases where summarization might        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m introduce errors [2]. Testing across different context scenarios ensures robustness in production.\\n\\n###       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Continuous Monitoring and Iteration\\n\\nAnalyze context usage patterns regularly, identify optimization          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m opportunities, A/B test different pruning thresholds, experiment with summarization frequencies, and evolve     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m approach based on real-world usage data [2]. Context engineering is not a one-time implementation but an        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m ongoing optimization process.\\n\\n### Explicit Documentation\\n\\nDocument why pruning occurs at specific          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m thresholds, explain how summarization prompts were designed, clarify what information gets offloaded versus     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m kept in context, and prevent well-intentioned changes from breaking tuned systems [2]. Documentation ensures    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m team members understand context management decisions and maintain system integrity.\\n\\n### Version Control for  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m AI Configuration\\n\\nTreat AI configuration files as maintained software artifacts [3]. Version, review, and     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m quality-assure like source code. Track evolution and co-evolution with source code. Enable team-wide            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m consistency in AI behavior. Configuration files should undergo the same rigor as application code.\\n\\n##        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Performance Gains and Impact\\n\\nTeams implementing proper context engineering report substantial improvements   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [2]. They achieve 10x reduction in token usage through pruning and summarization alone, 50-70% latency          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m improvements from keeping contexts lean and focused, similar magnitude cost reductions making previously        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m impractical workflows viable, and dramatic accuracy and reliability improvements when models work within        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m effective context windows.\\n\\nContext engineering transforms AI agent economics. Production systems like Manus  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m would be economically unviable without it [2]. Multi-agent systems can cost 15x more tokens than single-agent   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m chat without proper management [1]. Strategic context management makes complex, long-running workflows          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m practical at scale.\\n\\n## Future Directions\\n\\nEmerging areas include automated context optimization with       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m feedback loops that update configuration files based on observed results, automated testing of how content,     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m structure, and style affect agent behavior, and machine learning approaches to optimize context selection       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m [3].\\n\\nCo-evolution studies examine the relationship between source code and AI configuration files, similar   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m to studies on source code and comment co-evolution [3]. Understanding how context requirements change with code \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m will inform better practices for maintaining configuration files.\\n\\nStandardization efforts explore whether    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m standard schemas could improve interoperability, the trade-offs between centralized versus module-level         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m configuration files, and approaches for coordinating instructions for multiple agents [3].\\n\\nOpen questions    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m remain about how tone and phrasing in configuration files influence agent adherence [3], the optimal balance    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m between context comprehensiveness and focus, how to better measure and predict context rot, and best practices  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m for context management in multi-modal agents.\\n\\n## Conclusion\\n\\nContext engineering has evolved from an       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m esoteric concern to a fundamental discipline in AI systems engineering. As one researcher noted, \\\"context      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m engineering is effectively the #1 job of engineers building AI agents\\\" [1]. The difference between naive demos \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m and magical products lies not in the underlying model, but in the quality of context provided.\\n\\nKey takeaways \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m include that context engineering is system architecture, not just prompt writing - it encompasses the entire    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m information pipeline before LLM calls. Multiple techniques work together, as successful systems combine         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m pruning, summarization, offloading, atomic tools, context isolation, and conservative management. Performance   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m and cost are directly impacted, with proper context engineering delivering 10x token reductions, 50-70% latency \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m improvements, and dramatic cost savings. Real-world adoption is growing, with 5% of surveyed open-source        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m projects having adopted AI configuration files, though conventions are still evolving [3]. Best practices are   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m emerging around designing for context management from the start, establishing clear metrics, testing            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m comprehensively, and documenting explicitly.\\n\\nFor teams building AI agents, strategic recommendations include \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m investing in context engineering infrastructure early in development, treating AI configuration files as        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m first-class software artifacts requiring version control and maintenance, monitoring context usage continuously \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m and optimizing based on real data, combining multiple context engineering techniques rather than relying on     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m single approaches, and testing across different context scenarios to ensure robustness.\\n\\nThe teams that       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m master context engineering will build AI agents that don't merely work in demos but thrive in production,       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m delivering reliable, cost-effective, and exceptional user experiences. Context engineering represents the       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m invisible discipline that separates successful production AI systems from failed experiments.\\n\\n##             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Sources\\n\\n[1] What is Context Engineering for AI Agents? - Adaline Labs:                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://labs.adaline.ai/p/what-is-context-engineering-for-ai\\n\\n[2] Context Engineering: The Invisible          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Discipline Keeping AI Agents from Drowning in Their Own Memory - Juan C Olamendy, Medium:                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowning \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m -in-their-own-memory-c0283ca6a954\\n\\n[3] Context Engineering for AI Agents in Open-Source Software - arXiv:     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://arxiv.org/html/2510.21413v1\\n\\n[4] Top RAG Techniques You Should Know (Wang et al., 2024) - Louis       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Bouchard: https://www.louisbouchard.ai/top-rag-techniques/\\n\\n[5] Context Engineering: The Dynamic Context      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Construction Technique for AI Agents - AWS Builder Center:                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://builder.aws.com/content/3064TwnFXzSYe6r2EpN6Ye2Q2u1/context-engineering-the-dynamic-context-constructio \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m n-technique-for-ai-agents\\n\\n[6] Reducing Multi-Turn Confusion with LlamaIndex Memory - LlamaIndex              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Documentation: https://developers.llamaindex.ai/python/examples/memory/custom_multi_turn_memory/\\n\\n[7] What is \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Retrieval-Augmented Generation (RAG)? - Vectorize Documentation:                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://docs.vectorize.io/welcome/core-concepts/retrieval-augmented-generation/\\n\\n[8] A Comprehensive Guide to \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Using Function Calling with LangChain - Cohorte Blog:                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m https://www.cohorte.co/blog/a-comprehensive-guide-to-using-function-calling-with-langchain\\n\"                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_01TuQpbm5ScJXrhTMfn6AN53                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated file /final_report.md                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated file /final_report.md                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_todos                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"todos\": [                                                                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research specific techniques and implementation methods\",                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Write comprehensive final report to /final_report.md\",                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Verify report addresses all aspects of the original request\",                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"in_progress\"                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     }                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   ]                                                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01Qg991pm9a4gYDXFrxvrcdU                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: read_file                                                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"/research_request.md\"                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_01XzjrBU8A2dSKxQvLe59Dhi                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_todos                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"todos\": [                                                                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research specific techniques and implementation methods\",                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Write comprehensive final report to /final_report.md\",                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Verify report addresses all aspects of the original request\",                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"in_progress\"                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     }                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   ]                                                                                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_01Qg991pm9a4gYDXFrxvrcdU                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: read_file                                                                                         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"file_path\": \"/research_request.md\"                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_01XzjrBU8A2dSKxQvLe59Dhi                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> agents', 'status': 'completed'}, {'content': 'Research specific techniques and implementation methods',         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'status': 'completed'}, {'content': 'Write comprehensive final report to /final_report.md', 'status':           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'completed'}, {'content': 'Verify report addresses all aspects of the original request', 'status':              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'in_progress'}]                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m agents', 'status': 'completed'}, {'content': 'Research specific techniques and implementation methods',         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'status': 'completed'}, {'content': 'Write comprehensive final report to /final_report.md', 'status':           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'completed'}, {'content': 'Verify report addresses all aspects of the original request', 'status':              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'in_progress'}]                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      1  # Research Request                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      2                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      3  Research context engineering approaches used to build AI agents                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      4                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      5  ## Date                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      6  2024-01-XX                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      7                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      8  ## Objective                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span>      9  Investigate and document the various context engineering approaches, techniques, and methodologies used <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> in building AI agents.                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m      1  # Research Request                                                                                      \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      2                                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      3  Research context engineering approaches used to build AI agents                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      4                                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      5  ## Date                                                                                                 \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      6  2024-01-XX                                                                                              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      7                                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      8  ## Objective                                                                                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m      9  Investigate and document the various context engineering approaches, techniques, and methodologies used \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m in building AI agents.                                                                                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_todos                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"todos\": [                                                                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Research specific techniques and implementation methods\",                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Write comprehensive final report to /final_report.md\",                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     },                                                                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     {                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"content\": \"Verify report addresses all aspects of the original request\",                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>       \"status\": \"completed\"                                                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>     }                                                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   ]                                                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: toolu_019isL1uqbXubzS6xQqiXhNU                                                                           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_todos                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"todos\": [                                                                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research context engineering fundamentals and core approaches for AI agents\",                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Research specific techniques and implementation methods\",                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Write comprehensive final report to /final_report.md\",                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     },                                                                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     {                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"content\": \"Verify report addresses all aspects of the original request\",                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m       \"status\": \"completed\"                                                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m     }                                                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   ]                                                                                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: toolu_019isL1uqbXubzS6xQqiXhNU                                                                           \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> agents', 'status': 'completed'}, {'content': 'Research specific techniques and implementation methods',         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'status': 'completed'}, {'content': 'Write comprehensive final report to /final_report.md', 'status':           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'completed'}, {'content': 'Verify report addresses all aspects of the original request', 'status':              <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> 'completed'}]                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated todo list to [{'content': 'Research context engineering fundamentals and core approaches for AI         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m agents', 'status': 'completed'}, {'content': 'Research specific techniques and implementation methods',         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'status': 'completed'}, {'content': 'Write comprehensive final report to /final_report.md', 'status':           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'completed'}, {'content': 'Verify report addresses all aspects of the original request', 'status':              \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m 'completed'}]                                                                                                   \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Perfect! I've completed comprehensive research on context engineering approaches used to build AI agents.       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Here's what I found:                                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ## Summary                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Context engineering has emerged as **the critical discipline** for building production-grade AI agents. It's    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> evolved from simple prompt engineering to sophisticated system architecture that manages the entire information <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> pipeline before LLM calls.                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ### Key Findings:                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **What is Context Engineering?**                                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Strategic management of information provided to LLMs                                                          <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Encompasses memory management, retrieval strategies, compression, and structural isolation                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Determines whether AI agents succeed or fail in production                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **Four Core Strategies:**                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 1. **Writing Context** - Saving information outside context windows (scratchpads, long-term memory)             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 2. **Selecting Context** - Intelligent retrieval of only relevant information (RAG, agentic RAG)                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 3. **Compressing Context** - Summarization and pruning to reduce token usage                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 4. **Isolating Context** - Multi-agent architectures and sandboxes for separation of concerns                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **Six Essential Techniques:**                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 1. **Pruning** - Removing old/irrelevant information                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 2. **Summarization** - Compressing while preserving meaning                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 3. **Offloading** - Moving large data to external storage                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 4. **Atomic Tools** - Single-responsibility tools to reduce prompt bloat                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 5. **Context Isolation** - Sub-agents for complex workflows                                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 6. **Conservative Management** - Triggering interventions at 40-60% capacity, not 80-90%                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **Performance Impact:**                                                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - 10x reduction in token usage                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - 50-70% latency improvements                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Similar cost reductions                                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Dramatic accuracy improvements                                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **Real-World Adoption:**                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - 5% of open-source projects use AI configuration files (AGENTS.md, CLAUDE.md)                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Production systems like Manus, Claude Code, ChatGPT, and Cursor all rely heavily on context engineering       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Without it, complex workflows become economically unviable                                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> The comprehensive report has been saved to `/final_report.md` with detailed explanations, implementation        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> patterns, code examples, best practices, and 8 authoritative sources covering everything from fundamentals to   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> advanced techniques.                                                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m Perfect! I've completed comprehensive research on context engineering approaches used to build AI agents.       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Here's what I found:                                                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m ## Summary                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m Context engineering has emerged as **the critical discipline** for building production-grade AI agents. It's    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m evolved from simple prompt engineering to sophisticated system architecture that manages the entire information \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m pipeline before LLM calls.                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m ### Key Findings:                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **What is Context Engineering?**                                                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Strategic management of information provided to LLMs                                                          \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Encompasses memory management, retrieval strategies, compression, and structural isolation                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Determines whether AI agents succeed or fail in production                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **Four Core Strategies:**                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 1. **Writing Context** - Saving information outside context windows (scratchpads, long-term memory)             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 2. **Selecting Context** - Intelligent retrieval of only relevant information (RAG, agentic RAG)                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 3. **Compressing Context** - Summarization and pruning to reduce token usage                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 4. **Isolating Context** - Multi-agent architectures and sandboxes for separation of concerns                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **Six Essential Techniques:**                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 1. **Pruning** - Removing old/irrelevant information                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 2. **Summarization** - Compressing while preserving meaning                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 3. **Offloading** - Moving large data to external storage                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 4. **Atomic Tools** - Single-responsibility tools to reduce prompt bloat                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 5. **Context Isolation** - Sub-agents for complex workflows                                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 6. **Conservative Management** - Triggering interventions at 40-60% capacity, not 80-90%                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **Performance Impact:**                                                                                         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - 10x reduction in token usage                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - 50-70% latency improvements                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Similar cost reductions                                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Dramatic accuracy improvements                                                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **Real-World Adoption:**                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - 5% of open-source projects use AI configuration files (AGENTS.md, CLAUDE.md)                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Production systems like Manus, Claude Code, ChatGPT, and Cursor all rely heavily on context engineering       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Without it, complex workflows become economically unviable                                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m The comprehensive report has been saved to `/final_report.md` with detailed explanations, implementation        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m patterns, code examples, best practices, and 8 authoritative sources covering everything from fundamentals to   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m advanced techniques.                                                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"research context engineering approaches used to build AI agents\",\n",
    "            }\n",
    "        ],\n",
    "    }, \n",
    ")\n",
    "\n",
    "format_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "188b5ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  # Context Engineering Approaches for Building AI Agents                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Overview</span>                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering has emerged as a critical discipline in AI agent development, representing the strategic   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  management, curation, and control of information provided to large language models (LLMs). As Andrej Karpathy  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  describes it, context engineering is \"the delicate art and science of filling the context window with just     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  the right information for the next step\" [1]. This discipline has evolved from simple prompt engineering to    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  sophisticated system architecture that determines whether AI agents succeed or fail in production              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  environments.                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering directly impacts three fundamental aspects of AI systems: performance and reliability,     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  cost efficiency, and user experience [1][2]. Research shows that models perform optimally only in the first    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  50,000-100,000 tokens, even with million-token context windows, making strategic context management essential  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  rather than optional [2]. As one researcher noted, \"Most agent failures are context failures\" - the system     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  didn't provide adequate information for success [1].                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## What is Context Engineering?</span>                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering is the discipline of strategically managing, curating, and controlling the information     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  provided to large language models [1][2]. It represents an evolution from prompt engineering, which focuses    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  on crafting instructions, to context engineering, which focuses on architecting the entire information         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  pipeline before the LLM call.                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  While prompt engineering concentrated on writing clever, concise instructions for simple tasks, context        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  engineering treats the entire pipeline as engineerable infrastructure [1]. This includes dynamic information   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  gathering through RAG systems and API calls, memory management for both short-term conversation state and      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  long-term knowledge, tool coordination to make external functions available when needed, and output            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  structuring to define schemas and formats for consistent results.                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Early AI development relied heavily on prompting methods like chain-of-thought, ReAct, and self-consistency    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  for complex tasks [1]. However, as applications evolved into AI agents with multi-step reasoning,              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  long-running conversations, and dynamic information retrieval, these approaches hit significant limitations.   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering emerged as the solution to handle multi-step reasoning requiring tool use, long-running    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  conversations with memory, dynamic information retrieval from databases, and coordination between multiple AI  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  systems.                                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Why Context Engineering Matters</span>                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering has become essential because poor context management creates \"context rot\" where model     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  quality degrades well before hitting technical token limits [2]. Models experience performance degradation,    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  increased latency, and higher costs as context windows fill up. Processing 500,000 tokens takes significantly  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  longer than 5,000 tokens, and every token sent to an LLM incurs inference costs that compound with repeated    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  processing.                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Production systems without context engineering quickly become cost-prohibitive at scale. Naive approaches      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  that append all tool results can generate hundreds of thousands of tokens after just several rounds [2].       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Teams implementing proper context engineering report substantial improvements: 10x reduction in token usage    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  through pruning and summarization alone, 50-70% latency improvements from keeping contexts lean and focused,   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  similar magnitude cost reductions making previously impractical workflows viable, and dramatic accuracy and    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  reliability improvements when models work within effective context windows [2].                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Poor context management creates four major failure modes [1]: context poisoning where hallucinations           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  contaminate future responses, context distraction where too much information overwhelms the model, context     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  confusion where conflicting information causes errors, and context clash where disagreeing sources lead to     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  inconsistent outputs.                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Types of Context in AI Agents</span>                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Modern AI agents require multiple context types working together [1][3]. Static context includes prompts with  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  core behavior rules and examples, tool definitions specifying available functions and their parameters,        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  output schemas defining response format requirements, and configuration files containing project-specific      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  instructions like AGENTS.md or CLAUDE.md files.                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Dynamic context encompasses user input representing the immediate task or question, chat history providing     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  short-term conversation memory, long-term memory storing persistent preferences and past learnings, retrieved  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  knowledge from RAG results from databases or APIs, tool responses providing feedback from executed functions,  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and workflow state containing information stored across agent steps.                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Research on open-source projects found that AI configuration files commonly include coding conventions (50     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  instances), contribution guidelines (48), architecture descriptions (47), build commands (40), and testing     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  instructions (32) [3]. These configuration files use different writing styles: descriptive (\"This project      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  uses the Linux Kernel Style Guideline\"), prescriptive (\"Use factories for all test data\"), prohibitive         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  (\"Never commit directly to the main branch\"), explanatory (\"Avoid hard-coded waits to prevent timing           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  issues\"), and conditional (\"If you need to use reflection, use ReflectionUtils APIs\") [3].                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Core Context Engineering Strategies</span>                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Strategy 1: Writing Context (Memory Management)</span>                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Writing context involves saving information outside the context window to preserve valuable token space [1].   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This strategy enables two key capabilities: scratchpads for temporary note-taking within a single session,     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and long-term memories for information retained across multiple sessions.                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Scratchpads provide temporary storage during agent execution. Anthropic's multi-agent researcher saves         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  initial plans to \"Memory\" to prevent loss when context exceeds 200,000 tokens [1]. Implementation options      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  include file-based tools or runtime state objects that persist during a session but don't carry over to        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  future interactions.                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Long-term memories enable personalization and create evolving experiences that improve over time. ChatGPT      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  auto-generates user preferences from conversations, while Cursor and Windsurf learn coding patterns and        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  project context [1]. Reflexion agents create self-generated memories from task feedback, allowing them to      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  improve performance on subsequent attempts.                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Strategy 2: Selecting Context (Intelligent Retrieval)</span>                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Selecting context means pulling only relevant information into the context window [1][4]. This strategy        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  provides fine-grained control over what information gets exposed to the LLM, enabling selective exposure of    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  specific parts from scratchpads or state objects to reduce noise and improve decision-making.                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Memory selection operates across three types: episodic memories containing few-shot examples showing desired   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  behavior, procedural memories storing instructions in configuration files, and semantic memories holding       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  facts relevant to current context through embeddings and RAG [1].                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Agentic RAG applies retrieval-augmented generation to tool descriptions themselves. Too many tools create      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"model confusion\" about which to use, but RAG-based tool selection improves accuracy by 3-fold according to    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  recent research [1]. This approach dynamically selects which tools to expose based on the current task,        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  rather than overwhelming the model with dozens of tool descriptions.                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Strategy 3: Compressing Context (Optimization)</span>                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Compressing context retains only tokens required to perform a task [1][2]. This strategy employs two primary   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  techniques: context summarization and context trimming.                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context summarization condenses information while preserving essential details. Claude Code's \"auto-compact\"   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  feature summarizes when context exceeds 95% capacity [1]. Summarization applies at multiple levels: full       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  trajectory summarization, summarization at specific points during execution, and summarization at agent        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  boundaries in multi-agent systems. Some companies use fine-tuned models specifically for summarization to      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ensure consistent quality.                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context trimming uses filtering or \"pruning\" approaches to remove content. Hard-coded heuristics might remove  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  older messages from lists, while learned approaches employ trained context pruners for specific domains [1].   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Trimming offers immediate, predictable context reduction without the computational overhead of summarization,  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  though it risks losing potentially valuable information.                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Strategy 4: Isolating Context (Structural Separation)</span>                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Isolating context splits it across different components to reduce cognitive load [1][2]. This strategy         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  manifests in two primary patterns: multi-agent architectures and sandboxes.                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Multi-agent architectures split context across sub-agents, each with their own context windows, tools, and     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  instructions. This enables separation of concerns for specialized subtasks, expands total token capacity       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  across the system, and prevents context pollution between different workflow phases [1]. The challenge is      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  that multi-agent systems can increase costs up to 15x more tokens than single-agent systems without proper     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  management [1].                                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Sandboxes and execution environments isolate code execution from the LLM's context window. They persist state  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  across multiple responses and excel at handling token-heavy objects like images and audio files [1]. Only      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  selective results are passed back to the LLM, keeping the context window focused on high-level reasoning       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  rather than detailed execution artifacts.                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Six Core Context Engineering Techniques</span>                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Technique 1: Pruning</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Pruning systematically removes older, less relevant, or redundant information from the context window [2].     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Implementation approaches include chronological pruning that removes oldest exchanges first (the simplest      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  approach), heuristic-based pruning that drops confirmations and casual conversation while preserving           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  instructions, priority-based pruning that assigns importance scores to different message types, and semantic   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  pruning that analyzes content to remove redundant or off-topic information.                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Best practices for pruning include triggering automatically at 80-95% of maximum token size, pairing with      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  summarization for maximum effectiveness, and summarizing before dropping content to preserve essential         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  information [2]. For example, after five tool calls, keep only the most recent 2-3 turns, summarize earlier    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  results, and drop raw outputs.                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Technique 2: Summarization</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Summarization compresses long message chains into concise summaries that preserve semantic relevance [2].      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Implementation patterns include hierarchical summarization that breaks long contexts into chunks, summarizes   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  each, then summarizes summaries; rolling summarization that updates and re-compresses summaries over time;     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and trigger points that activate at 50% of available window or when starting new tasks.                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Effective summarization instructions should preserve open tasks, decisions made, important facts, and          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  unresolved issues, while excluding casual conversation, confirmations, intermediate steps, and acted-upon      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  information [2]. Claude Code continuously compresses historical context during extended coding sessions,       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  preserving current file state and recent operations while summarizing earlier changes [2].                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Technique 3: Offloading</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Offloading moves detailed data outside the context window into external memory systems [2]. Storage options    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  include vector databases, file systems, structured databases, and knowledge bases. The implementation pattern  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  follows a clear sequence: the agent saves detailed outputs immediately after generation, maintains references  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  (IDs or summaries) in context, queries the external store when detailed information is needed, and retrieves   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and includes relevant content in the next prompt.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  For example, when processing 1,000 emails, store full content externally with IDs, keep only summaries in      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  context, and retrieve specific emails on demand [2]. This approach enables agents to work with datasets far    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  larger than any context window could accommodate.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Technique 4: Atomic Tools</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  The atomic tool pattern provides general-purpose, single-responsibility tools instead of dozens of             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  specialized tools [2]. Following the Unix philosophy of doing one thing well, each tool handles a specific,    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  precisely defined task, enabling clean data flow between tools and reducing prompt bloat from extensive tool   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  descriptions.                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Benefits include reduced debugging complexity, improved maintainability, enhanced orchestration flexibility,   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and minimized system prompt token overhead [2]. Replit, Cursor, and LangChain use separate \"read_file,\"        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"analyze_code,\" and \"write_file\" tools rather than combined \"analyze_and_fix_code\" tools [2]. This atomic      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  approach gives agents more flexibility in composing operations while keeping individual tool descriptions      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  concise.                                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Technique 5: Context Isolation (Sub-Agents)</span>                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context isolation uses sub-agent architectures for token-heavy or logically isolated subtasks [2]. The main    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  agent acts as orchestrator, spawning dedicated sub-agents for focused missions. Each sub-agent receives        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  fresh, minimal context and returns only condensed output to the main agent.                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Advantages include isolating complexity and preventing cross-task pollution, enabling parallelization of       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  concurrent subtasks, supporting specialization with different prompts or models, and expanding total system    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  token capacity [2]. LangGraph and similar frameworks provide built-in support for sub-agent lifecycle          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  management, context isolation, and result aggregation.                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Technique 6: Conservative Context Management</span>                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Conservative management recognizes that technical maximum context doesn't equal optimal usage [2]. Key         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  principles include starting fresh frequently after completing major tasks, resetting when reaching 50% of      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  available window, using query-aware contextualization to include only relevant context, and breaking complex   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  tasks into smaller subtasks with fresh context.                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Strategic positioning places critical information at beginning and end of context to avoid the \"lost in the    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  middle\" phenomenon where buried information gets overlooked [2]. Real-time monitoring of token counts with     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  automatic triggers at specific thresholds (40% warning, 60% action) ensures proactive management before        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  context degradation occurs.                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Retrieval-Augmented Generation (RAG) Techniques</span>                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  RAG represents a central context engineering challenge, enabling agents to access external knowledge           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  dynamically [1][4]. The core RAG workflow follows this sequence: user query → embedding → vector search →      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  retrieve top-K documents → augment prompt → LLM generation → response [4].                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Query Classification and Chunking</span>                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Query classification determines if retrieval is needed, since some queries don't require external information  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [4]. A binary classifier separates \"sufficient\" versus \"insufficient\" queries, saving costs by avoiding        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  unnecessary retrieval.                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Optimal chunk sizes range from 256-512 tokens [4]. The small2big approach starts with small chunks for         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  search, then expands to larger chunks for generation. Sliding windows overlap tokens between chunks for        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  context preservation, ensuring important information isn't lost at chunk boundaries.                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Metadata and Hybrid Search</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Adding titles, keywords, and hypothetical questions to chunks improves retrieval accuracy [4]. Combining       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  vector search (semantic matching) with BM25 (keyword search) provides better balance than HyDE, which is more  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  accurate but inefficient. This hybrid approach captures both semantic similarity and exact keyword matches.    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Embedding models should be chosen appropriate for the domain. LLM-Embedder from FlagEmbedding offers good      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  balance of performance and size, while Cohere provides strong commercial options [4]. The choice of embedding  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  model significantly impacts retrieval quality and should be evaluated on domain-specific benchmarks.           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Reranking and Document Repacking</span>                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Reranking reorders retrieved documents by relevance after initial retrieval [4]. monoT5 offers the best        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  balance of performance and efficiency, RankLLaMA provides best overall performance, and TILDEv2 is the         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  fastest option. Reranking significantly improves the quality of documents presented to the LLM.                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Document repacking arranges documents in ascending order of relevance using the \"reverse\" method, placing      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  relevant information at start or end for better LLM processing [4]. This optimizes information presentation    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  after reranking, taking advantage of models' tendency to pay more attention to information at the beginning    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and end of context.                                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Advanced RAG Patterns</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Agentic RAG combines multiple retrieval strategies: AST parsing for code, grep searches for text, knowledge    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  graphs for relationships, and LLM-based re-ranking for semantic chunking [1]. This multi-strategy approach     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  adapts retrieval methods to the type of information being sought.                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Multimodal retrieval extends RAG beyond text. Text-to-image queries database for similar images, while         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  image-to-text matches similar images to retrieve captions [4]. This ensures groundedness with real, verified   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  information across different modalities.                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Summarization removes redundant or unnecessary information before the LLM call. Tools like Recomp provide      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  extractive and abstractive compression [4]. While this reduces costs, it adds latency, so the trade-off must   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  be evaluated based on application requirements.                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Context Window Management and Optimization</span>                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Modern LLMs advertise large context windows (up to 1 million tokens), but research shows that effective        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  performance occurs within much smaller windows - typically the first 50,000-100,000 tokens [2]. Beyond this    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  threshold, models experience context rot with degraded accuracy and instruction-following capability, the      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"lost in the middle\" phenomenon where information buried mid-context gets overlooked, increased latency from   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  processing massive contexts, and higher costs since every token incurs inference costs that compound with      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  repeated processing.                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Conservative context management strategy sets aggressive thresholds, triggering context management at 40-60%   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  of maximum window rather than 80-90% [2]. Starting fresh frequently after completing major tasks prevents      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  accumulation of stale context. Strategic positioning places critical instructions at the beginning and end of  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  prompts where models pay most attention. Query-aware contextualization dynamically adjusts included context    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  based on the specific task rather than comprehensive history.                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Long-Term Memory and State Management</span>                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Production systems implement hierarchical memory with distinct short-term and long-term storage [2][3].        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Short-term memory (active context) contains recent messages and current task context. Long-term memory         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  (external storage) holds compressed historical information, facts, and decisions. Working memory (external     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  databases) stores tool outputs, intermediate results, and large datasets.                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  LlamaIndex provides sophisticated approaches to managing multi-turn conversations with custom memory blocks    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [3]. Custom memory blocks can condense past messages while maintaining token limits, automatically enforce     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  token budgets by removing oldest messages, and integrate seamlessly with agent workflows to prevent            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  multi-turn confusion.                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  The multi-turn confusion problem shows that LLM performance significantly degrades in multi-turn               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  conversations without proper management [3]. Agents accumulate hundreds of thousands of tokens after just      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  several rounds of tool calls. The solution involves aggressive context flushing where short-term memory        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  always contains minimal turns and all history is condensed into long-term memory blocks.                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Tool Use and Function Calling Context Patterns</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  The atomic tools pattern provides few general-purpose tools with clear, narrow scopes rather than many         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  specialized tools that bloat system prompts [2]. Design principles include single responsibility where each    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  tool does one thing well (Unix philosophy), minimal ambiguity with clear input schemas and predictable         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  outputs, composability allowing tools to be chained together, and reduced prompt overhead from fewer tool      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  descriptions in system prompt.                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Replit, Cursor, and LangChain agents use highly atomic tool definitions [2]. Instead of                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  \"analyze_and_fix_code\", they provide separate \"read_file\", \"analyze_code\", and \"write_file\" tools that agents  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  chain together. This gives agents more flexibility while keeping individual tool descriptions concise.         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Tool outputs can be massive and quickly fill context windows [2]. The offloading pattern stores large tool     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  outputs externally and returns reference IDs. After tool execution, the system stores large output             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  externally, includes only a reference in context, and retrieves full output only when the agent specifically   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  requests it. This dramatically reduces context consumption while maintaining access to full data when needed.  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Real-World Implementations</span>                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Production Systems</span>                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Manus, a production agent platform, executes workflows requiring 50+ tool calls per run [2]. It employs        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  aggressive pruning of tool outputs after acknowledgment, uses rolling summarization at workflow phase          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  boundaries, and offloads detailed results to structured storage. Without context engineering, the platform     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  would be economically unviable.                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Claude Code from Anthropic implements hierarchical summarization in tool call histories [1][2]. Its            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  auto-compact feature activates at 95% context capacity, enabling extended coding sessions without coherence    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  loss. The system preserves current file state while summarizing earlier changes.                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ChatGPT from OpenAI auto-generates user preferences from conversations and maintains long-term memories        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  across sessions [1]. This demonstrates both benefits and risks of context management, as unexpected            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  information injection can occur if not carefully controlled.                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Cursor and Windsurf development tools learn coding patterns and project context over time [1]. They use        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  AGENTS.md or similar configuration files to provide context-aware code suggestions that improve as they learn  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  developer preferences.                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### AI Configuration Files</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Research on 10,000 GitHub repositories found that 5% (466 repositories) had adopted AI configuration files     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [3]. Common formats include AGENTS.md (tool-agnostic standard), CLAUDE.md (Anthropic's Claude Code),           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  copilot-instructions.md (GitHub Copilot), and GEMINI.md (Google Gemini).                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Content categories from empirical analysis include conventions and best practices (50 instances),              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  contribution guidelines (48), architecture and project structure (47), build commands (40), project            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  description (32), testing instructions (32), tech stack and dependencies (15), and getting started and setup   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  (11) [3].                                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Implementation Best Practices</span>                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Design for Context Engineering from the Start</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Build context tracking into agent architecture from the first prototype [2]. Establish clear patterns for      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  when pruning, summarization, and offloading occur. Create abstractions that make context management decisions  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  explicit and testable. Treating context engineering as an afterthought leads to brittle systems that fail      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  under production load.                                                                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Establish Clear Metrics</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Track token usage per interaction (average and peak), measure model performance across different context       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  sizes, monitor costs directly tied to context length, and assess user experience metrics like latency and      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  accuracy [2]. These metrics provide visibility into context engineering effectiveness and guide optimization   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  efforts.                                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Implement Graceful Degradation</span>                                                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Never crash or produce empty responses when hitting context limits [2]. Automatically trigger aggressive       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  summarization or pruning, reset to clean state with summary of prior work, and provide explanations when       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  context limits force interruption. Users should experience smooth operation even when context management       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  interventions occur.                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Combine Multiple Techniques</span>                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Successful systems use pruning for routine cleanup, summarization for compressing important information,       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  offloading for large data, atomic tools for efficiency, sub-agents for isolation, and conservative management  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  for reliability [1][2]. No single technique solves all context challenges; production systems strategically    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  combine approaches based on specific needs.                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Comprehensive Testing</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Evaluate with minimal context, test with moderate context, verify near-maximum context handling, confirm       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  pruning and summarization preserve essential information, validate offloading and retrieval mechanisms, and    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  test edge cases where summarization might introduce errors [2]. Testing across different context scenarios     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ensures robustness in production.                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Continuous Monitoring and Iteration</span>                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Analyze context usage patterns regularly, identify optimization opportunities, A/B test different pruning      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  thresholds, experiment with summarization frequencies, and evolve approach based on real-world usage data      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [2]. Context engineering is not a one-time implementation but an ongoing optimization process.                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Explicit Documentation</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Document why pruning occurs at specific thresholds, explain how summarization prompts were designed, clarify   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  what information gets offloaded versus kept in context, and prevent well-intentioned changes from breaking     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  tuned systems [2]. Documentation ensures team members understand context management decisions and maintain     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  system integrity.                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">### Version Control for AI Configuration</span>                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Treat AI configuration files as maintained software artifacts [3]. Version, review, and quality-assure like    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  source code. Track evolution and co-evolution with source code. Enable team-wide consistency in AI behavior.   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Configuration files should undergo the same rigor as application code.                                         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Performance Gains and Impact</span>                                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Teams implementing proper context engineering report substantial improvements [2]. They achieve 10x reduction  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  in token usage through pruning and summarization alone, 50-70% latency improvements from keeping contexts      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  lean and focused, similar magnitude cost reductions making previously impractical workflows viable, and        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  dramatic accuracy and reliability improvements when models work within effective context windows.              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering transforms AI agent economics. Production systems like Manus would be economically         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  unviable without it [2]. Multi-agent systems can cost 15x more tokens than single-agent chat without proper    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  management [1]. Strategic context management makes complex, long-running workflows practical at scale.         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Future Directions</span>                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Emerging areas include automated context optimization with feedback loops that update configuration files      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  based on observed results, automated testing of how content, structure, and style affect agent behavior, and   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  machine learning approaches to optimize context selection [3].                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Co-evolution studies examine the relationship between source code and AI configuration files, similar to       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  studies on source code and comment co-evolution [3]. Understanding how context requirements change with code   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  will inform better practices for maintaining configuration files.                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Standardization efforts explore whether standard schemas could improve interoperability, the trade-offs        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  between centralized versus module-level configuration files, and approaches for coordinating instructions for  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  multiple agents [3].                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Open questions remain about how tone and phrasing in configuration files influence agent adherence [3], the    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  optimal balance between context comprehensiveness and focus, how to better measure and predict context rot,    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and best practices for context management in multi-modal agents.                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Conclusion</span>                                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Context engineering has evolved from an esoteric concern to a fundamental discipline in AI systems             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  engineering. As one researcher noted, \"context engineering is effectively the #1 job of engineers building AI  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  agents\" [1]. The difference between naive demos and magical products lies not in the underlying model, but in  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  the quality of context provided.                                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Key takeaways include that context engineering is system architecture, not just prompt writing - it            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  encompasses the entire information pipeline before LLM calls. Multiple techniques work together, as            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  successful systems combine pruning, summarization, offloading, atomic tools, context isolation, and            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  conservative management. Performance and cost are directly impacted, with proper context engineering           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  delivering 10x token reductions, 50-70% latency improvements, and dramatic cost savings. Real-world adoption   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  is growing, with 5% of surveyed open-source projects having adopted AI configuration files, though             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  conventions are still evolving [3]. Best practices are emerging around designing for context management from   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  the start, establishing clear metrics, testing comprehensively, and documenting explicitly.                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  For teams building AI agents, strategic recommendations include investing in context engineering               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  infrastructure early in development, treating AI configuration files as first-class software artifacts         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  requiring version control and maintenance, monitoring context usage continuously and optimizing based on real  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  data, combining multiple context engineering techniques rather than relying on single approaches, and testing  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  across different context scenarios to ensure robustness.                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  The teams that master context engineering will build AI agents that don't merely work in demos but thrive in   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  production, delivering reliable, cost-effective, and exceptional user experiences. Context engineering         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  represents the invisible discipline that separates successful production AI systems from failed experiments.   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Sources</span>                                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [1] What is Context Engineering for AI Agents? - Adaline Labs:                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://labs.adaline.ai/p/what-is-context-engineering-for-ai                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [2] Context Engineering: The Invisible Discipline Keeping AI Agents from Drowning in Their Own Memory - Juan   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  C Olamendy, Medium:                                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowni  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ng-in-their-own-memory-c0283ca6a954                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [3] Context Engineering for AI Agents in Open-Source Software - arXiv: https://arxiv.org/html/2510.21413v1     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [4] Top RAG Techniques You Should Know (Wang et al., 2024) - Louis Bouchard:                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://www.louisbouchard.ai/top-rag-techniques/                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [5] Context Engineering: The Dynamic Context Construction Technique for AI Agents - AWS Builder Center:        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://builder.aws.com/content/3064TwnFXzSYe6r2EpN6Ye2Q2u1/context-engineering-the-dynamic-context-construct  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ion-technique-for-ai-agents                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [6] Reducing Multi-Turn Confusion with LlamaIndex Memory - LlamaIndex Documentation:                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://developers.llamaindex.ai/python/examples/memory/custom_multi_turn_memory/                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [7] What is Retrieval-Augmented Generation (RAG)? - Vectorize Documentation:                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://docs.vectorize.io/welcome/core-concepts/retrieval-augmented-generation/                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  [8] A Comprehensive Guide to Using Function Calling with LangChain - Cohorte Blog:                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  https://www.cohorte.co/blog/a-comprehensive-guide-to-using-function-calling-with-langchain                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  # Context Engineering Approaches for Building AI Agents                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Overview\u001b[0m                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering has emerged as a critical discipline in AI agent development, representing the strategic   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  management, curation, and control of information provided to large language models (LLMs). As Andrej Karpathy  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  describes it, context engineering is \"the delicate art and science of filling the context window with just     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  the right information for the next step\" [1]. This discipline has evolved from simple prompt engineering to    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  sophisticated system architecture that determines whether AI agents succeed or fail in production              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  environments.                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering directly impacts three fundamental aspects of AI systems: performance and reliability,     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  cost efficiency, and user experience [1][2]. Research shows that models perform optimally only in the first    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  50,000-100,000 tokens, even with million-token context windows, making strategic context management essential  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  rather than optional [2]. As one researcher noted, \"Most agent failures are context failures\" - the system     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  didn't provide adequate information for success [1].                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## What is Context Engineering?\u001b[0m                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering is the discipline of strategically managing, curating, and controlling the information     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  provided to large language models [1][2]. It represents an evolution from prompt engineering, which focuses    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  on crafting instructions, to context engineering, which focuses on architecting the entire information         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  pipeline before the LLM call.                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  While prompt engineering concentrated on writing clever, concise instructions for simple tasks, context        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  engineering treats the entire pipeline as engineerable infrastructure [1]. This includes dynamic information   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  gathering through RAG systems and API calls, memory management for both short-term conversation state and      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  long-term knowledge, tool coordination to make external functions available when needed, and output            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  structuring to define schemas and formats for consistent results.                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Early AI development relied heavily on prompting methods like chain-of-thought, ReAct, and self-consistency    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  for complex tasks [1]. However, as applications evolved into AI agents with multi-step reasoning,              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  long-running conversations, and dynamic information retrieval, these approaches hit significant limitations.   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering emerged as the solution to handle multi-step reasoning requiring tool use, long-running    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  conversations with memory, dynamic information retrieval from databases, and coordination between multiple AI  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  systems.                                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Why Context Engineering Matters\u001b[0m                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering has become essential because poor context management creates \"context rot\" where model     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  quality degrades well before hitting technical token limits [2]. Models experience performance degradation,    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  increased latency, and higher costs as context windows fill up. Processing 500,000 tokens takes significantly  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  longer than 5,000 tokens, and every token sent to an LLM incurs inference costs that compound with repeated    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  processing.                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Production systems without context engineering quickly become cost-prohibitive at scale. Naive approaches      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  that append all tool results can generate hundreds of thousands of tokens after just several rounds [2].       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Teams implementing proper context engineering report substantial improvements: 10x reduction in token usage    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  through pruning and summarization alone, 50-70% latency improvements from keeping contexts lean and focused,   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  similar magnitude cost reductions making previously impractical workflows viable, and dramatic accuracy and    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  reliability improvements when models work within effective context windows [2].                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Poor context management creates four major failure modes [1]: context poisoning where hallucinations           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  contaminate future responses, context distraction where too much information overwhelms the model, context     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  confusion where conflicting information causes errors, and context clash where disagreeing sources lead to     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  inconsistent outputs.                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Types of Context in AI Agents\u001b[0m                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Modern AI agents require multiple context types working together [1][3]. Static context includes prompts with  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  core behavior rules and examples, tool definitions specifying available functions and their parameters,        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  output schemas defining response format requirements, and configuration files containing project-specific      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  instructions like AGENTS.md or CLAUDE.md files.                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Dynamic context encompasses user input representing the immediate task or question, chat history providing     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  short-term conversation memory, long-term memory storing persistent preferences and past learnings, retrieved  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  knowledge from RAG results from databases or APIs, tool responses providing feedback from executed functions,  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and workflow state containing information stored across agent steps.                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Research on open-source projects found that AI configuration files commonly include coding conventions (50     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  instances), contribution guidelines (48), architecture descriptions (47), build commands (40), and testing     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  instructions (32) [3]. These configuration files use different writing styles: descriptive (\"This project      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  uses the Linux Kernel Style Guideline\"), prescriptive (\"Use factories for all test data\"), prohibitive         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  (\"Never commit directly to the main branch\"), explanatory (\"Avoid hard-coded waits to prevent timing           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  issues\"), and conditional (\"If you need to use reflection, use ReflectionUtils APIs\") [3].                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Core Context Engineering Strategies\u001b[0m                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Strategy 1: Writing Context (Memory Management)\u001b[0m                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Writing context involves saving information outside the context window to preserve valuable token space [1].   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This strategy enables two key capabilities: scratchpads for temporary note-taking within a single session,     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and long-term memories for information retained across multiple sessions.                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Scratchpads provide temporary storage during agent execution. Anthropic's multi-agent researcher saves         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  initial plans to \"Memory\" to prevent loss when context exceeds 200,000 tokens [1]. Implementation options      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  include file-based tools or runtime state objects that persist during a session but don't carry over to        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  future interactions.                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Long-term memories enable personalization and create evolving experiences that improve over time. ChatGPT      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  auto-generates user preferences from conversations, while Cursor and Windsurf learn coding patterns and        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  project context [1]. Reflexion agents create self-generated memories from task feedback, allowing them to      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  improve performance on subsequent attempts.                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Strategy 2: Selecting Context (Intelligent Retrieval)\u001b[0m                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Selecting context means pulling only relevant information into the context window [1][4]. This strategy        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  provides fine-grained control over what information gets exposed to the LLM, enabling selective exposure of    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  specific parts from scratchpads or state objects to reduce noise and improve decision-making.                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Memory selection operates across three types: episodic memories containing few-shot examples showing desired   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  behavior, procedural memories storing instructions in configuration files, and semantic memories holding       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  facts relevant to current context through embeddings and RAG [1].                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Agentic RAG applies retrieval-augmented generation to tool descriptions themselves. Too many tools create      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"model confusion\" about which to use, but RAG-based tool selection improves accuracy by 3-fold according to    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  recent research [1]. This approach dynamically selects which tools to expose based on the current task,        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  rather than overwhelming the model with dozens of tool descriptions.                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Strategy 3: Compressing Context (Optimization)\u001b[0m                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Compressing context retains only tokens required to perform a task [1][2]. This strategy employs two primary   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  techniques: context summarization and context trimming.                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context summarization condenses information while preserving essential details. Claude Code's \"auto-compact\"   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  feature summarizes when context exceeds 95% capacity [1]. Summarization applies at multiple levels: full       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  trajectory summarization, summarization at specific points during execution, and summarization at agent        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  boundaries in multi-agent systems. Some companies use fine-tuned models specifically for summarization to      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ensure consistent quality.                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context trimming uses filtering or \"pruning\" approaches to remove content. Hard-coded heuristics might remove  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  older messages from lists, while learned approaches employ trained context pruners for specific domains [1].   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Trimming offers immediate, predictable context reduction without the computational overhead of summarization,  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  though it risks losing potentially valuable information.                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Strategy 4: Isolating Context (Structural Separation)\u001b[0m                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Isolating context splits it across different components to reduce cognitive load [1][2]. This strategy         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  manifests in two primary patterns: multi-agent architectures and sandboxes.                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Multi-agent architectures split context across sub-agents, each with their own context windows, tools, and     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  instructions. This enables separation of concerns for specialized subtasks, expands total token capacity       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  across the system, and prevents context pollution between different workflow phases [1]. The challenge is      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  that multi-agent systems can increase costs up to 15x more tokens than single-agent systems without proper     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  management [1].                                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Sandboxes and execution environments isolate code execution from the LLM's context window. They persist state  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  across multiple responses and excel at handling token-heavy objects like images and audio files [1]. Only      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  selective results are passed back to the LLM, keeping the context window focused on high-level reasoning       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  rather than detailed execution artifacts.                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Six Core Context Engineering Techniques\u001b[0m                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Technique 1: Pruning\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Pruning systematically removes older, less relevant, or redundant information from the context window [2].     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Implementation approaches include chronological pruning that removes oldest exchanges first (the simplest      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  approach), heuristic-based pruning that drops confirmations and casual conversation while preserving           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  instructions, priority-based pruning that assigns importance scores to different message types, and semantic   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  pruning that analyzes content to remove redundant or off-topic information.                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Best practices for pruning include triggering automatically at 80-95% of maximum token size, pairing with      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  summarization for maximum effectiveness, and summarizing before dropping content to preserve essential         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  information [2]. For example, after five tool calls, keep only the most recent 2-3 turns, summarize earlier    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  results, and drop raw outputs.                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Technique 2: Summarization\u001b[0m                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Summarization compresses long message chains into concise summaries that preserve semantic relevance [2].      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Implementation patterns include hierarchical summarization that breaks long contexts into chunks, summarizes   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  each, then summarizes summaries; rolling summarization that updates and re-compresses summaries over time;     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and trigger points that activate at 50% of available window or when starting new tasks.                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Effective summarization instructions should preserve open tasks, decisions made, important facts, and          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  unresolved issues, while excluding casual conversation, confirmations, intermediate steps, and acted-upon      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  information [2]. Claude Code continuously compresses historical context during extended coding sessions,       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  preserving current file state and recent operations while summarizing earlier changes [2].                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Technique 3: Offloading\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Offloading moves detailed data outside the context window into external memory systems [2]. Storage options    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  include vector databases, file systems, structured databases, and knowledge bases. The implementation pattern  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  follows a clear sequence: the agent saves detailed outputs immediately after generation, maintains references  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  (IDs or summaries) in context, queries the external store when detailed information is needed, and retrieves   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and includes relevant content in the next prompt.                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  For example, when processing 1,000 emails, store full content externally with IDs, keep only summaries in      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  context, and retrieve specific emails on demand [2]. This approach enables agents to work with datasets far    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  larger than any context window could accommodate.                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Technique 4: Atomic Tools\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  The atomic tool pattern provides general-purpose, single-responsibility tools instead of dozens of             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  specialized tools [2]. Following the Unix philosophy of doing one thing well, each tool handles a specific,    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  precisely defined task, enabling clean data flow between tools and reducing prompt bloat from extensive tool   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  descriptions.                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Benefits include reduced debugging complexity, improved maintainability, enhanced orchestration flexibility,   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and minimized system prompt token overhead [2]. Replit, Cursor, and LangChain use separate \"read_file,\"        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"analyze_code,\" and \"write_file\" tools rather than combined \"analyze_and_fix_code\" tools [2]. This atomic      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  approach gives agents more flexibility in composing operations while keeping individual tool descriptions      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  concise.                                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Technique 5: Context Isolation (Sub-Agents)\u001b[0m                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context isolation uses sub-agent architectures for token-heavy or logically isolated subtasks [2]. The main    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  agent acts as orchestrator, spawning dedicated sub-agents for focused missions. Each sub-agent receives        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  fresh, minimal context and returns only condensed output to the main agent.                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Advantages include isolating complexity and preventing cross-task pollution, enabling parallelization of       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  concurrent subtasks, supporting specialization with different prompts or models, and expanding total system    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  token capacity [2]. LangGraph and similar frameworks provide built-in support for sub-agent lifecycle          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  management, context isolation, and result aggregation.                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Technique 6: Conservative Context Management\u001b[0m                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Conservative management recognizes that technical maximum context doesn't equal optimal usage [2]. Key         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  principles include starting fresh frequently after completing major tasks, resetting when reaching 50% of      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  available window, using query-aware contextualization to include only relevant context, and breaking complex   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  tasks into smaller subtasks with fresh context.                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Strategic positioning places critical information at beginning and end of context to avoid the \"lost in the    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  middle\" phenomenon where buried information gets overlooked [2]. Real-time monitoring of token counts with     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  automatic triggers at specific thresholds (40% warning, 60% action) ensures proactive management before        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  context degradation occurs.                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Retrieval-Augmented Generation (RAG) Techniques\u001b[0m                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  RAG represents a central context engineering challenge, enabling agents to access external knowledge           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  dynamically [1][4]. The core RAG workflow follows this sequence: user query → embedding → vector search →      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  retrieve top-K documents → augment prompt → LLM generation → response [4].                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Query Classification and Chunking\u001b[0m                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Query classification determines if retrieval is needed, since some queries don't require external information  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [4]. A binary classifier separates \"sufficient\" versus \"insufficient\" queries, saving costs by avoiding        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  unnecessary retrieval.                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Optimal chunk sizes range from 256-512 tokens [4]. The small2big approach starts with small chunks for         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  search, then expands to larger chunks for generation. Sliding windows overlap tokens between chunks for        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  context preservation, ensuring important information isn't lost at chunk boundaries.                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Metadata and Hybrid Search\u001b[0m                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Adding titles, keywords, and hypothetical questions to chunks improves retrieval accuracy [4]. Combining       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  vector search (semantic matching) with BM25 (keyword search) provides better balance than HyDE, which is more  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  accurate but inefficient. This hybrid approach captures both semantic similarity and exact keyword matches.    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Embedding models should be chosen appropriate for the domain. LLM-Embedder from FlagEmbedding offers good      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  balance of performance and size, while Cohere provides strong commercial options [4]. The choice of embedding  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  model significantly impacts retrieval quality and should be evaluated on domain-specific benchmarks.           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Reranking and Document Repacking\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Reranking reorders retrieved documents by relevance after initial retrieval [4]. monoT5 offers the best        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  balance of performance and efficiency, RankLLaMA provides best overall performance, and TILDEv2 is the         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  fastest option. Reranking significantly improves the quality of documents presented to the LLM.                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Document repacking arranges documents in ascending order of relevance using the \"reverse\" method, placing      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  relevant information at start or end for better LLM processing [4]. This optimizes information presentation    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  after reranking, taking advantage of models' tendency to pay more attention to information at the beginning    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and end of context.                                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Advanced RAG Patterns\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Agentic RAG combines multiple retrieval strategies: AST parsing for code, grep searches for text, knowledge    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  graphs for relationships, and LLM-based re-ranking for semantic chunking [1]. This multi-strategy approach     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  adapts retrieval methods to the type of information being sought.                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Multimodal retrieval extends RAG beyond text. Text-to-image queries database for similar images, while         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  image-to-text matches similar images to retrieve captions [4]. This ensures groundedness with real, verified   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  information across different modalities.                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Summarization removes redundant or unnecessary information before the LLM call. Tools like Recomp provide      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  extractive and abstractive compression [4]. While this reduces costs, it adds latency, so the trade-off must   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  be evaluated based on application requirements.                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Context Window Management and Optimization\u001b[0m                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Modern LLMs advertise large context windows (up to 1 million tokens), but research shows that effective        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  performance occurs within much smaller windows - typically the first 50,000-100,000 tokens [2]. Beyond this    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  threshold, models experience context rot with degraded accuracy and instruction-following capability, the      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"lost in the middle\" phenomenon where information buried mid-context gets overlooked, increased latency from   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  processing massive contexts, and higher costs since every token incurs inference costs that compound with      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  repeated processing.                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Conservative context management strategy sets aggressive thresholds, triggering context management at 40-60%   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  of maximum window rather than 80-90% [2]. Starting fresh frequently after completing major tasks prevents      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  accumulation of stale context. Strategic positioning places critical instructions at the beginning and end of  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  prompts where models pay most attention. Query-aware contextualization dynamically adjusts included context    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  based on the specific task rather than comprehensive history.                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Long-Term Memory and State Management\u001b[0m                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Production systems implement hierarchical memory with distinct short-term and long-term storage [2][3].        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Short-term memory (active context) contains recent messages and current task context. Long-term memory         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  (external storage) holds compressed historical information, facts, and decisions. Working memory (external     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  databases) stores tool outputs, intermediate results, and large datasets.                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  LlamaIndex provides sophisticated approaches to managing multi-turn conversations with custom memory blocks    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [3]. Custom memory blocks can condense past messages while maintaining token limits, automatically enforce     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  token budgets by removing oldest messages, and integrate seamlessly with agent workflows to prevent            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  multi-turn confusion.                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  The multi-turn confusion problem shows that LLM performance significantly degrades in multi-turn               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  conversations without proper management [3]. Agents accumulate hundreds of thousands of tokens after just      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  several rounds of tool calls. The solution involves aggressive context flushing where short-term memory        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  always contains minimal turns and all history is condensed into long-term memory blocks.                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Tool Use and Function Calling Context Patterns\u001b[0m                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  The atomic tools pattern provides few general-purpose tools with clear, narrow scopes rather than many         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  specialized tools that bloat system prompts [2]. Design principles include single responsibility where each    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  tool does one thing well (Unix philosophy), minimal ambiguity with clear input schemas and predictable         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  outputs, composability allowing tools to be chained together, and reduced prompt overhead from fewer tool      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  descriptions in system prompt.                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Replit, Cursor, and LangChain agents use highly atomic tool definitions [2]. Instead of                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \"analyze_and_fix_code\", they provide separate \"read_file\", \"analyze_code\", and \"write_file\" tools that agents  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  chain together. This gives agents more flexibility while keeping individual tool descriptions concise.         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Tool outputs can be massive and quickly fill context windows [2]. The offloading pattern stores large tool     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  outputs externally and returns reference IDs. After tool execution, the system stores large output             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  externally, includes only a reference in context, and retrieves full output only when the agent specifically   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  requests it. This dramatically reduces context consumption while maintaining access to full data when needed.  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Real-World Implementations\u001b[0m                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Production Systems\u001b[0m                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Manus, a production agent platform, executes workflows requiring 50+ tool calls per run [2]. It employs        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  aggressive pruning of tool outputs after acknowledgment, uses rolling summarization at workflow phase          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  boundaries, and offloads detailed results to structured storage. Without context engineering, the platform     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  would be economically unviable.                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Claude Code from Anthropic implements hierarchical summarization in tool call histories [1][2]. Its            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  auto-compact feature activates at 95% context capacity, enabling extended coding sessions without coherence    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  loss. The system preserves current file state while summarizing earlier changes.                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ChatGPT from OpenAI auto-generates user preferences from conversations and maintains long-term memories        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  across sessions [1]. This demonstrates both benefits and risks of context management, as unexpected            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  information injection can occur if not carefully controlled.                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Cursor and Windsurf development tools learn coding patterns and project context over time [1]. They use        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  AGENTS.md or similar configuration files to provide context-aware code suggestions that improve as they learn  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  developer preferences.                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## AI Configuration Files\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Research on 10,000 GitHub repositories found that 5% (466 repositories) had adopted AI configuration files     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [3]. Common formats include AGENTS.md (tool-agnostic standard), CLAUDE.md (Anthropic's Claude Code),           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  copilot-instructions.md (GitHub Copilot), and GEMINI.md (Google Gemini).                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Content categories from empirical analysis include conventions and best practices (50 instances),              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  contribution guidelines (48), architecture and project structure (47), build commands (40), project            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  description (32), testing instructions (32), tech stack and dependencies (15), and getting started and setup   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  (11) [3].                                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Implementation Best Practices\u001b[0m                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Design for Context Engineering from the Start\u001b[0m                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Build context tracking into agent architecture from the first prototype [2]. Establish clear patterns for      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  when pruning, summarization, and offloading occur. Create abstractions that make context management decisions  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  explicit and testable. Treating context engineering as an afterthought leads to brittle systems that fail      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  under production load.                                                                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Establish Clear Metrics\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Track token usage per interaction (average and peak), measure model performance across different context       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  sizes, monitor costs directly tied to context length, and assess user experience metrics like latency and      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  accuracy [2]. These metrics provide visibility into context engineering effectiveness and guide optimization   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  efforts.                                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Implement Graceful Degradation\u001b[0m                                                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Never crash or produce empty responses when hitting context limits [2]. Automatically trigger aggressive       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  summarization or pruning, reset to clean state with summary of prior work, and provide explanations when       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  context limits force interruption. Users should experience smooth operation even when context management       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  interventions occur.                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Combine Multiple Techniques\u001b[0m                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Successful systems use pruning for routine cleanup, summarization for compressing important information,       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  offloading for large data, atomic tools for efficiency, sub-agents for isolation, and conservative management  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  for reliability [1][2]. No single technique solves all context challenges; production systems strategically    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  combine approaches based on specific needs.                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Comprehensive Testing\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Evaluate with minimal context, test with moderate context, verify near-maximum context handling, confirm       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  pruning and summarization preserve essential information, validate offloading and retrieval mechanisms, and    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  test edge cases where summarization might introduce errors [2]. Testing across different context scenarios     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ensures robustness in production.                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Continuous Monitoring and Iteration\u001b[0m                                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Analyze context usage patterns regularly, identify optimization opportunities, A/B test different pruning      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  thresholds, experiment with summarization frequencies, and evolve approach based on real-world usage data      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [2]. Context engineering is not a one-time implementation but an ongoing optimization process.                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Explicit Documentation\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Document why pruning occurs at specific thresholds, explain how summarization prompts were designed, clarify   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  what information gets offloaded versus kept in context, and prevent well-intentioned changes from breaking     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  tuned systems [2]. Documentation ensures team members understand context management decisions and maintain     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  system integrity.                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;36m#\u001b[0m\u001b[1;36m## Version Control for AI Configuration\u001b[0m                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Treat AI configuration files as maintained software artifacts [3]. Version, review, and quality-assure like    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  source code. Track evolution and co-evolution with source code. Enable team-wide consistency in AI behavior.   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Configuration files should undergo the same rigor as application code.                                         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Performance Gains and Impact\u001b[0m                                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Teams implementing proper context engineering report substantial improvements [2]. They achieve 10x reduction  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  in token usage through pruning and summarization alone, 50-70% latency improvements from keeping contexts      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  lean and focused, similar magnitude cost reductions making previously impractical workflows viable, and        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  dramatic accuracy and reliability improvements when models work within effective context windows.              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering transforms AI agent economics. Production systems like Manus would be economically         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  unviable without it [2]. Multi-agent systems can cost 15x more tokens than single-agent chat without proper    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  management [1]. Strategic context management makes complex, long-running workflows practical at scale.         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Future Directions\u001b[0m                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Emerging areas include automated context optimization with feedback loops that update configuration files      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  based on observed results, automated testing of how content, structure, and style affect agent behavior, and   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  machine learning approaches to optimize context selection [3].                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Co-evolution studies examine the relationship between source code and AI configuration files, similar to       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  studies on source code and comment co-evolution [3]. Understanding how context requirements change with code   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  will inform better practices for maintaining configuration files.                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Standardization efforts explore whether standard schemas could improve interoperability, the trade-offs        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  between centralized versus module-level configuration files, and approaches for coordinating instructions for  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  multiple agents [3].                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Open questions remain about how tone and phrasing in configuration files influence agent adherence [3], the    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  optimal balance between context comprehensiveness and focus, how to better measure and predict context rot,    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and best practices for context management in multi-modal agents.                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Conclusion\u001b[0m                                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Context engineering has evolved from an esoteric concern to a fundamental discipline in AI systems             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  engineering. As one researcher noted, \"context engineering is effectively the #1 job of engineers building AI  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  agents\" [1]. The difference between naive demos and magical products lies not in the underlying model, but in  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  the quality of context provided.                                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Key takeaways include that context engineering is system architecture, not just prompt writing - it            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  encompasses the entire information pipeline before LLM calls. Multiple techniques work together, as            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  successful systems combine pruning, summarization, offloading, atomic tools, context isolation, and            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  conservative management. Performance and cost are directly impacted, with proper context engineering           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  delivering 10x token reductions, 50-70% latency improvements, and dramatic cost savings. Real-world adoption   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  is growing, with 5% of surveyed open-source projects having adopted AI configuration files, though             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  conventions are still evolving [3]. Best practices are emerging around designing for context management from   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  the start, establishing clear metrics, testing comprehensively, and documenting explicitly.                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  For teams building AI agents, strategic recommendations include investing in context engineering               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  infrastructure early in development, treating AI configuration files as first-class software artifacts         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  requiring version control and maintenance, monitoring context usage continuously and optimizing based on real  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  data, combining multiple context engineering techniques rather than relying on single approaches, and testing  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  across different context scenarios to ensure robustness.                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  The teams that master context engineering will build AI agents that don't merely work in demos but thrive in   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  production, delivering reliable, cost-effective, and exceptional user experiences. Context engineering         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  represents the invisible discipline that separates successful production AI systems from failed experiments.   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Sources\u001b[0m                                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [1] What is Context Engineering for AI Agents? - Adaline Labs:                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://labs.adaline.ai/p/what-is-context-engineering-for-ai                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [2] Context Engineering: The Invisible Discipline Keeping AI Agents from Drowning in Their Own Memory - Juan   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  C Olamendy, Medium:                                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://medium.com/@juanc.olamendy/context-engineering-the-invisible-discipline-keeping-ai-agents-from-drowni  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ng-in-their-own-memory-c0283ca6a954                                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [3] Context Engineering for AI Agents in Open-Source Software - arXiv: https://arxiv.org/html/2510.21413v1     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [4] Top RAG Techniques You Should Know (Wang et al., 2024) - Louis Bouchard:                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://www.louisbouchard.ai/top-rag-techniques/                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [5] Context Engineering: The Dynamic Context Construction Technique for AI Agents - AWS Builder Center:        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://builder.aws.com/content/3064TwnFXzSYe6r2EpN6Ye2Q2u1/context-engineering-the-dynamic-context-construct  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ion-technique-for-ai-agents                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [6] Reducing Multi-Turn Confusion with LlamaIndex Memory - LlamaIndex Documentation:                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://developers.llamaindex.ai/python/examples/memory/custom_multi_turn_memory/                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [7] What is Retrieval-Augmented Generation (RAG)? - Vectorize Documentation:                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://docs.vectorize.io/welcome/core-concepts/retrieval-augmented-generation/                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  [8] A Comprehensive Guide to Using Function Calling with LangChain - Cohorte Blog:                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  https://www.cohorte.co/blog/a-comprehensive-guide-to-using-function-calling-with-langchain                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepagents.backends.utils import file_data_to_string\n",
    "\n",
    "# Convert a specific file to string\n",
    "file_content = file_data_to_string(result[\"files\"]['/final_report.md'])\n",
    "show_prompt(file_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc6784",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/cd2262de-08b1-4e0d-86d3-f9ed3b957921/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73925c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
